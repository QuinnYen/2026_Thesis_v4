# VP-ACLè«–æ–‡å®Œæ•´åˆ†æå ±å‘Š

**è«–æ–‡**: Aspect-level sentiment analysis based on vector projection and adversarial contrastive learning  
**ä½œè€…**: Er-Ping Zhao, Si-Yun Yu  
**ç™¼è¡¨**: Expert Systems With Applications, 2025å¹´  
**ä»£ç¢¼**: https://github.com/Reset-aa/For-paper  

---

## ğŸ“‹ è«–æ–‡æ‘˜è¦

### æ ¸å¿ƒå•é¡Œ
ç¾æœ‰ABSAæ–¹æ³•å­˜åœ¨å…©å€‹ä¸»è¦é™åˆ¶:
1. **ç„¡æ³•å»ºç«‹aspectèˆ‡æƒ…æ„Ÿä¿¡æ¯çš„ä¸€å°ä¸€å°æ‡‰**,é›£ä»¥æœ‰æ•ˆæŒ–æ˜å–®aspectæƒ…æ„Ÿèªç¾©
2. **å—å…¶ä»–aspectæƒ…æ„Ÿå¹²æ“¾**,å°è‡´å¤šaspectå¥å­çš„åˆ†é¡æº–ç¢ºç‡ä¸‹é™

### è§£æ±ºæ–¹æ¡ˆ
æå‡ºVP-ACLæ¨¡å‹,é€šéä»¥ä¸‹æ©Ÿåˆ¶è§£æ±ºä¸Šè¿°å•é¡Œ:

**ä¸»è¦å‰µæ–°**:
1. **å‘é‡æŠ•å½±æ¨¡çµ„** - éæ¿¾å…¶ä»–aspectçš„æƒ…æ„Ÿèªç¾©
2. **å°æŠ—å°æ¯”å­¸ç¿’** - æå‡æŠ—å¹²æ“¾èƒ½åŠ›
3. **Dropoutç­–ç•¥** - ç”Ÿæˆé«˜è³ªé‡æ­£æ¨£æœ¬
4. **å·®åˆ†æ¦‚ç‡æ¨¡çµ„** - å¢å¼·æƒ…æ„Ÿå‚¾å‘å€åˆ†

### å¯¦é©—çµæœ
åœ¨5å€‹å…¬é–‹æ•¸æ“šé›†ä¸Šçš„F1åˆ†æ•¸:
- **Rest14**: 82.62% (SOTA)
- **Laptop14**: 79.18% (SOTA)
- **MAMS**: 84.83% (SOTA)
- **Rest15**: 76.28% (SOTA)
- **Rest16**: 79.10% (+2.98% vs. æœ€ä½³baseline)

---

## ğŸ¯ æ ¸å¿ƒæ–¹æ³•è©³è§£

### æ–¹æ³•ä¸€:å‘é‡æŠ•å½±æ¨¡çµ„ â­â­â­â­â­

#### å•é¡Œè¨ºæ–·
å‚³çµ±æ–¹æ³•ä½¿ç”¨attentionæ©Ÿåˆ¶æˆ–å¥æ³•ä¾è³´æ¨¹åˆ†é…æ¬Šé‡,ä½†ä»æœƒçµ¦å¹²æ“¾ä¿¡æ¯åˆ†é…æ¬Šé‡,å½±éŸ¿è¨“ç·´ã€‚

#### è§£æ±ºæ–¹æ¡ˆ
**å‘é‡æŠ•å½±æŠ€è¡“éæ¿¾å…¶ä»–aspectçš„æƒ…æ„Ÿèªç¾©**

#### æŠ€è¡“å¯¦ç¾

**æ­¥é©Ÿ1: ç”Ÿæˆå¤šaspectæƒ…æ„Ÿå¯†é›†å‘é‡**
```python
# ç‚ºæ¯å€‹aspectç”Ÿæˆå¼·èª¿è©²aspectçš„å¥å­å‘é‡
y1 = highlight_vector(sentence, aspect_1)  # å¼·èª¿aspect_1çš„å¥å­è¡¨ç¤º
y2 = highlight_vector(sentence, aspect_2)  # å¼·èª¿aspect_2çš„å¥å­è¡¨ç¤º
yi = highlight_vector(sentence, aspect_i)  # å¼·èª¿aspect_içš„å¥å­è¡¨ç¤º

# å‘é‡åŠ æ³•èšåˆ
y_tilde = y1 + y2 + ... + yi + ... + yn
```

**æ•¸å­¸å…¬å¼**:
$$
\tilde{y} = y_1 + y_2 + y_i + \cdots + y_n
$$

**æ­¥é©Ÿ2: æŠ•å½±åˆ°ç›®æ¨™aspectæ–¹å‘**
```python
# è¨ˆç®—æŠ•å½±
Y_i* = (y_tilde Â· yi / ||yi||) Â· (yi / ||yi||)
```

**æ•¸å­¸å…¬å¼**:
$$
Y_i^* = \frac{\tilde{Y} \cdot y_i}{||y_i||} \cdot \frac{y_i}{||y_i||}
$$

å…¶ä¸­:
- $\tilde{y}$: å¤šaspectæƒ…æ„Ÿå¯†é›†å‘é‡
- $y_i$: ç›®æ¨™aspectçš„å¥å­å‘é‡
- $Y_i^*$: éæ¿¾å¾Œçš„å–®aspectæƒ…æ„Ÿå‘é‡
- $\cdot$: é»ç©é‹ç®—
- $||y_i||$: å‘é‡æ¨¡é•·

#### å·¥ä½œåŸç†

**å‘é‡æŠ•å½±çš„å¹¾ä½•æ„ç¾©**:
```
        y_tilde (å¤šaspectèšåˆ)
           /|
          / |
         /  | projection
        /   |
       /    â†“
      /   Y_i* (éæ¿¾å¾Œ)
     /    /
    /    /
   /    /
  /____/_______ yi (ç›®æ¨™aspectæ–¹å‘)
```

**æ•ˆæœ**:
- âœ… ä¿ç•™èˆ‡ç›®æ¨™aspectç›¸é—œçš„æƒ…æ„Ÿä¿¡æ¯
- âœ… éæ¿¾å…¶ä»–aspectçš„æƒ…æ„Ÿå¹²æ“¾
- âœ… ç²å¾—åªåŒ…å«å–®aspectæƒ…æ„Ÿèªç¾©çš„å¥å­å‘é‡

#### å¯¦é©—é©—è­‰

**æ¡ˆä¾‹**: "The food is okay and the prices here are mediocre."

**å‚³çµ±attentionæ–¹æ³• (ATAE-LSTM)**:
- åˆ†æ"food": ä¹Ÿæœƒé—œæ³¨"mediocre"(ä¾†è‡ªprices)
- åˆ†æ"prices": ä¹Ÿæœƒé—œæ³¨"okay"(ä¾†è‡ªfood)
- **å•é¡Œ**: ç„¡æ³•æ­£ç¢ºå°æ‡‰aspectå’Œæƒ…æ„Ÿ

**VP-ACLçš„å‘é‡æŠ•å½±**:
- åˆ†æ"food": é«˜æ¬Šé‡çµ¦"okay",ä½æ¬Šé‡çµ¦"mediocre" âœ…
- åˆ†æ"prices": é«˜æ¬Šé‡çµ¦"mediocre",ä½æ¬Šé‡çµ¦"okay" âœ…
- **å„ªå‹¢**: æº–ç¢ºå°æ‡‰aspectå’Œæƒ…æ„Ÿè©

#### æ€§èƒ½æå‡

**æ¶ˆèå¯¦é©— (VP-ACL w/o PROJ)**:

| æ•¸æ“šé›† | å®Œæ•´VP-ACL | ç§»é™¤æŠ•å½± | æ€§èƒ½ä¸‹é™ |
|--------|-----------|---------|---------|
| Rest14 | 82.62 | 80.62 | -2.00% |
| Laptop | 79.18 | 77.36 | -1.82% |
| MAMS | 84.83 | 81.04 | -3.79% |
| Rest15 | 76.28 | 74.94 | -1.34% |
| Rest16 | 79.10 | 77.66 | -1.44% |

**çµè«–**: å‘é‡æŠ•å½±æ˜¯VP-ACLæœ€é—œéµçš„çµ„ä»¶,ç§»é™¤å¾Œæ€§èƒ½å¤§å¹…ä¸‹é™

---

### æ–¹æ³•äºŒ:å°æŠ—å°æ¯”å­¸ç¿’ â­â­â­â­

#### å•é¡Œè¨ºæ–·
ç¾æœ‰å°æ¯”å­¸ç¿’æ–¹æ³•ç„¡æ³•ç‚ºå¤šaspectå¥å­ç”Ÿæˆé«˜è³ªé‡æ­£è² æ¨£æœ¬å°:
1. **æ­£æ¨£æœ¬å•é¡Œ**: è©åºæ‰“äº‚æœƒç ´å£aspect-æƒ…æ„Ÿå°æ‡‰
2. **è² æ¨£æœ¬å•é¡Œ**: ä½¿ç”¨batchå…§å…¶ä»–å¥å­,å¹²æ“¾å› ç´ éå¤š

#### è§£æ±ºæ–¹æ¡ˆA: Dropoutç­–ç•¥ç”Ÿæˆæ­£æ¨£æœ¬

**å‚³çµ±æ–¹æ³•çš„å•é¡Œ**:
```python
# æ–¹æ³•1: è©åºæ‰“äº‚
åŸå¥: "The food is okay and the prices here are mediocre"
æ‰“äº‚å¾Œ: "Decor friendly somewhat restaurant, but service monotonous always very"
# å•é¡Œ: å®Œå…¨ç ´å£äº†aspect-æƒ…æ„Ÿé—œä¿‚
```

**VP-ACLçš„Dropoutæ–¹æ³•**:
```python
def generate_positive_sample(sentence_vector, dropout_rate=0.1):
    """
    ä½¿ç”¨Dropoutéš¨æ©Ÿmaskéƒ¨åˆ†ç‰¹å¾µ,ä¿æŒæƒ…æ„Ÿèªç¾©å®Œæ•´
    """
    # éš¨æ©Ÿmask
    mask = torch.bernoulli(torch.ones_like(sentence_vector) * (1 - dropout_rate))
    
    # ç”Ÿæˆæ­£æ¨£æœ¬
    positive_sample = sentence_vector * mask
    
    return positive_sample
```

**æ•¸å­¸å…¬å¼**:
$$
Y_{drop} = Dropout(Y_i^*)
$$

**å„ªå‹¢**:
- âœ… ä¿æŒå–®aspectæƒ…æ„Ÿä¿¡æ¯å®Œæ•´æ€§
- âœ… å¢åŠ æ¨£æœ¬å¤šæ¨£æ€§
- âœ… èªç¾©ç›¸ä¼¼åº¦é«˜æ–¼åŸå¥

**å¯¦é©—å°æ¯”**:

| æ–¹æ³• | Rest15 F1 | èªªæ˜ |
|------|-----------|------|
| åŒç¾©è©æ›¿æ› | 74.83% | å®¹æ˜“èªç¾©æ¼‚ç§» |
| å›è­¯ | 75.14% | å—ç¿»è­¯æ¨¡å‹å½±éŸ¿ |
| **Dropout (VP-ACL)** | **76.28%** | ä¿æŒèªç¾©ä¸€è‡´æ€§ âœ… |

#### è§£æ±ºæ–¹æ¡ˆB: åŸºæ–¼aspectæ•¸é‡çš„å°æŠ—è² æ¨£æœ¬

**æ ¸å¿ƒæ€æƒ³**: aspectæ•¸é‡è¶Šå¤š,å¹²æ“¾è¶Šå¤§,éœ€è¦æ›´å¤§çš„æ“¾å‹•

**ç®—æ³•è¨­è¨ˆ**:
```python
def generate_adversarial_negative(sentence_vector, num_aspects, delta=0.05):
    """
    åŸºæ–¼aspectæ•¸é‡å„ªåŒ–æ“¾å‹•åƒæ•¸
    
    Args:
        sentence_vector: å¥å­å‘é‡
        num_aspects: aspectæ•¸é‡
        delta: åˆå§‹æ“¾å‹•ä¸Šé™
    """
    # æ ¹æ“šaspectæ•¸é‡å‹•æ…‹èª¿æ•´æ“¾å‹•ç¯„åœ
    if num_aspects >= 3:
        # å¤šaspect: ä½¿ç”¨è¼ƒå¤§æ“¾å‹•ç¯„åœ
        perturbation_range = delta * 2.0
    elif num_aspects == 2:
        # é›™aspect: ä½¿ç”¨ä¸­ç­‰æ“¾å‹•ç¯„åœ
        perturbation_range = delta * 1.5
    else:
        # å–®aspect: ä½¿ç”¨è¼ƒå°æ“¾å‹•ç¯„åœ
        perturbation_range = delta * 1.0
    
    # ç”Ÿæˆå°æŠ—æ“¾å‹•
    # ä½¿ç”¨PGD (Projected Gradient Descent)
    perturbation = torch.zeros_like(sentence_vector)
    
    for iteration in range(max_iterations):
        # è¨ˆç®—æ¢¯åº¦
        grad = compute_gradient(sentence_vector + perturbation)
        
        # æ›´æ–°æ“¾å‹•
        perturbation = perturbation + alpha * grad.sign()
        
        # æŠ•å½±åˆ°å…è¨±ç¯„åœ
        perturbation = torch.clamp(perturbation, -perturbation_range, perturbation_range)
    
    # ç”Ÿæˆè² æ¨£æœ¬
    negative_sample = sentence_vector + perturbation
    
    return negative_sample
```

**æ“¾å‹•ç¯„åœèª¿æ•´è¦å‰‡**:

| aspectæ•¸é‡ | æ“¾å‹•ç¯„åœ | åŸå›  |
|-----------|---------|------|
| N â‰¥ 3 | Î´ Ã— 2.0 | å¹²æ“¾å¤§,éœ€å¤§æ“¾å‹•å€åˆ† |
| N = 2 | Î´ Ã— 1.5 | ä¸­ç­‰å¹²æ“¾ |
| N = 1 | Î´ Ã— 1.0 | å¹²æ“¾å°,å°æ“¾å‹•å³å¯ |

**å„ªå‹¢**:
- âœ… è‡ªé©æ‡‰aspectæ•¸é‡
- âœ… é¿å…éåº¦æ“¾å‹•å°è‡´èªç¾©å¤±çœŸ
- âœ… æå‡æ¨¡å‹æŠ—å¹²æ“¾èƒ½åŠ›

#### å°æ¯”å­¸ç¿’æå¤±å‡½æ•¸

```python
def contrastive_loss(anchor, positive, negative, tau=0.7):
    """
    å°æ¯”å­¸ç¿’æå¤±
    
    Args:
        anchor: åŸå§‹æ¨£æœ¬
        positive: æ­£æ¨£æœ¬ (Dropoutç”Ÿæˆ)
        negative: è² æ¨£æœ¬ (å°æŠ—æ¨£æœ¬)
        tau: æº«åº¦åƒæ•¸
    """
    # è¨ˆç®—ç›¸ä¼¼åº¦
    sim_pos = cosine_similarity(anchor, positive) / tau
    sim_neg = cosine_similarity(anchor, negative) / tau
    
    # InfoNCEæå¤±
    loss = -log(exp(sim_pos) / (exp(sim_pos) + exp(sim_neg)))
    
    return loss
```

**æ•¸å­¸å…¬å¼**:
$$
\mathcal{L}_{con} = -\log \frac{\exp(\text{sim}(Y_i^*, Y_{drop}) / \tau)}{\exp(\text{sim}(Y_i^*, Y_{drop}) / \tau) + \exp(\text{sim}(Y_i^*, Y_{adv}) / \tau)}
$$

#### æ€§èƒ½æå‡

**æ¶ˆèå¯¦é©— (VP-ACL w/o CON)**:

| æ•¸æ“šé›† | å®Œæ•´VP-ACL | ç§»é™¤å°æ¯”å­¸ç¿’ | æ€§èƒ½ä¸‹é™ |
|--------|-----------|------------|---------|
| Rest14 | 82.62 | 81.93 | -0.69% |
| Laptop | 79.18 | 78.43 | -0.75% |
| MAMS | 84.83 | 82.74 | -2.09% |
| Rest15 | 76.28 | 75.32 | -0.96% |
| Rest16 | 79.10 | 77.54 | -1.56% |

---

### æ–¹æ³•ä¸‰:å·®åˆ†æ¦‚ç‡å¢å¼·æ¨¡çµ„ â­â­â­

#### å•é¡Œè¨ºæ–·
æ¨¡å‹éœ€è¦ç‚ºä¸åŒaspectè¼¸å‡º**æ˜é¡¯å€åˆ†çš„æƒ…æ„Ÿæ¥µæ€§æ¦‚ç‡**,é¿å…æ¨¡ç³Šé æ¸¬ã€‚

#### è§£æ±ºæ–¹æ¡ˆ: Triplet Losså¼•å°

**ç›®æ¨™**: è®“åŒä¸€å¥å­ä¸­ä¸åŒaspectçš„æƒ…æ„Ÿæ¦‚ç‡åˆ†å¸ƒå·®ç•°æœ€å¤§åŒ–

**æŠ€è¡“å¯¦ç¾**:
```python
def differential_probability_loss(predictions, labels, aspects):
    """
    å·®åˆ†æ¦‚ç‡æå¤±
    
    Args:
        predictions: [batch, num_aspects, 3] - æ¯å€‹aspectçš„æƒ…æ„Ÿæ¦‚ç‡
        labels: [batch, num_aspects] - çœŸå¯¦æ¨™ç±¤
        aspects: [batch, num_aspects] - aspectæ•¸é‡
    """
    triplet_loss = 0
    
    for i in range(num_aspects):
        # Anchor: aspect_içš„é æ¸¬æ¦‚ç‡
        anchor = predictions[:, i, :]
        
        # Positive: åŒä¸€æƒ…æ„Ÿçš„å…¶ä»–aspect (å¦‚æœæœ‰)
        positive = find_same_sentiment_aspect(predictions, labels, i)
        
        # Negative: ä¸åŒæƒ…æ„Ÿçš„å…¶ä»–aspect
        negative = find_different_sentiment_aspect(predictions, labels, i)
        
        # Triplet loss
        triplet_loss += max(0, 
            distance(anchor, negative) - distance(anchor, positive) + margin
        )
    
    return triplet_loss
```

**æ•¸å­¸å…¬å¼**:
$$
\mathcal{L}_{asp} = \sum_{i=1}^{N} \max(0, ||p_i - p_{neg}|| - ||p_i - p_{pos}|| + m)
$$

å…¶ä¸­:
- $p_i$: aspect_içš„é æ¸¬æ¦‚ç‡
- $p_{pos}$: åŒæƒ…æ„Ÿaspectçš„æ¦‚ç‡
- $p_{neg}$: ä¸åŒæƒ…æ„Ÿaspectçš„æ¦‚ç‡
- $m$: margin (é€šå¸¸è¨­ç‚º0.2-0.5)

#### æ•ˆæœ
ç¢ºä¿æ¨¡å‹å°ä¸åŒaspectè¼¸å‡º**é«˜åº¦å€åˆ†**çš„æƒ…æ„Ÿæ¦‚ç‡,ä¾‹å¦‚:
- aspect_1 (food): [0.05, 0.10, **0.85**] â†’ Positive
- aspect_2 (service): [0.10, **0.80**, 0.10] â†’ Neutral
- aspect_3 (price): [**0.75**, 0.15, 0.10] â†’ Negative

#### æ€§èƒ½æå‡

**æ¶ˆèå¯¦é©— (VP-ACL w/o ASP)**:

| æ•¸æ“šé›† | å®Œæ•´VP-ACL | ç§»é™¤å·®åˆ†æ¦‚ç‡ | æ€§èƒ½ä¸‹é™ |
|--------|-----------|------------|---------|
| Rest14 | 82.62 | 82.07 | -0.55% |
| Laptop | 79.18 | 78.67 | -0.51% |
| MAMS | 84.83 | 83.21 | -1.62% |
| Rest15 | 76.28 | 75.41 | -0.87% |
| Rest16 | 79.10 | **76.97** | **-2.13%** â­ |

**ç‰¹åˆ¥ç™¼ç¾**: åœ¨Rest16æ•¸æ“šé›†ä¸Šæå‡æœ€æ˜é¡¯(+2.13%),å› ç‚ºè©²æ•¸æ“šé›†å¥å­è¼ƒçŸ­,ä¸Šä¸‹æ–‡ä¿¡æ¯æœ‰é™,æ¨¡å‹æ›´ä¾è³´å·®åˆ†æ¦‚ç‡æ¨¡çµ„ä¾†å€åˆ†æƒ…æ„Ÿå‚¾å‘ã€‚

---

### æ–¹æ³•å››:æ•´é«”æ¶æ§‹

#### å®Œæ•´æµç¨‹

```python
class VP_ACL(nn.Module):
    """VP-ACLå®Œæ•´æ¶æ§‹"""
    
    def __init__(self, hidden_dim=768, dropout=0.3, tau=0.7, delta=0.05):
        super().__init__()
        
        # BERTç·¨ç¢¼å™¨
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        
        # å‘é‡æŠ•å½±æ¨¡çµ„
        self.vector_projection = VectorProjection()
        
        # å°æ¯”å­¸ç¿’åƒæ•¸
        self.tau = tau
        self.delta = delta
        
        # åˆ†é¡å™¨
        self.classifier = nn.Linear(hidden_dim, 3)  # Neg/Neu/Pos
    
    def forward(self, text, aspects, num_aspects, labels=None):
        # æ­¥é©Ÿ1: BERTç·¨ç¢¼
        bert_output = self.bert(text)  # [batch, seq_len, 768]
        
        # æ­¥é©Ÿ2: ç‚ºæ¯å€‹aspectç”Ÿæˆå¼·èª¿å‘é‡
        aspect_vectors = []
        for i, aspect in enumerate(aspects):
            # ä½¿ç”¨aspectå¼•å°attention
            aspect_guided = self.aspect_guided_attention(
                bert_output, 
                aspect
            )
            aspect_vectors.append(aspect_guided)
        
        aspect_vectors = torch.stack(aspect_vectors, dim=1)
        # [batch, num_aspects, hidden_dim]
        
        # æ­¥é©Ÿ3: å‘é‡æŠ•å½±éæ¿¾
        projected_vectors = []
        for i in range(num_aspects):
            # èšåˆæ‰€æœ‰aspectå‘é‡
            multi_aspect_dense = aspect_vectors.sum(dim=1)
            
            # æŠ•å½±åˆ°aspect_iæ–¹å‘
            projected = self.vector_projection(
                multi_aspect_dense,
                aspect_vectors[:, i, :]
            )
            projected_vectors.append(projected)
        
        projected_vectors = torch.stack(projected_vectors, dim=1)
        # [batch, num_aspects, hidden_dim]
        
        # æ­¥é©Ÿ4: å°æŠ—å°æ¯”å­¸ç¿’ (è¨“ç·´æ™‚)
        if self.training and labels is not None:
            # ç”Ÿæˆæ­£æ¨£æœ¬ (Dropout)
            positive_samples = F.dropout(
                projected_vectors, 
                p=self.dropout_pos
            )
            
            # ç”Ÿæˆè² æ¨£æœ¬ (å°æŠ—)
            negative_samples = self.generate_adversarial(
                projected_vectors,
                num_aspects,
                delta=self.delta
            )
            
            # å°æ¯”å­¸ç¿’æå¤±
            contrastive_loss = self.compute_contrastive_loss(
                projected_vectors,
                positive_samples,
                negative_samples,
                tau=self.tau
            )
        
        # æ­¥é©Ÿ5: æƒ…æ„Ÿåˆ†é¡
        logits = self.classifier(projected_vectors)
        # [batch, num_aspects, 3]
        
        # æ­¥é©Ÿ6: å·®åˆ†æ¦‚ç‡æå¤± (è¨“ç·´æ™‚)
        if self.training and labels is not None:
            ce_loss = F.cross_entropy(
                logits.view(-1, 3),
                labels.view(-1)
            )
            
            triplet_loss = self.differential_probability_loss(
                F.softmax(logits, dim=-1),
                labels,
                num_aspects
            )
            
            total_loss = ce_loss + 0.1 * contrastive_loss + 0.05 * triplet_loss
            
            return logits, total_loss
        
        return logits
```

---

## ğŸ“Š å¯¦é©—çµæœèˆ‡åˆ†æ

### ä¸»è¦çµæœå°æ¯”

**è¡¨: 5å€‹æ•¸æ“šé›†ä¸Šçš„æ€§èƒ½å°æ¯”**

| æ–¹æ³• | Rest14 |  | Laptop14 |  | MAMS |  | Rest15 |  | Rest16 |  |
|------|--------|--------|----------|--------|------|--------|--------|--------|--------|--------|
|  | Acc | F1 | Acc | F1 | Acc | F1 | Acc | F1 | Acc | F1 |
| BERT-SCon | 87.62 | - | 82.94 | - | 85.78 | - | 85.42 | - | 92.53 | - |
| ATAE-LSTM | 78.60 | 67.02 | 68.88 | 63.93 | - | - | - | - | - | - |
| AEN | 83.12 | 73.76 | 79.93 | 76.31 | - | - | - | - | - | - |
| ASGCN | 86.34 | 79.96 | 81.75 | 79.12 | - | - | 84.30 | 70.05 | 90.15 | 76.12 |
| AFDEN | 87.41 | 82.21 | 82.13 | 78.81 | 85.33 | 84.73 | - | - | - | - |
| A2SMvCL | 87.86 | 82.41 | 82.12 | 78.82 | 85.10 | 84.65 | 86.74 | 75.05 | - | - |
| **VP-ACL** | **87.77** | **82.62** | **82.29** | **79.18** | **85.32** | **84.83** | **86.94** | **76.28** | **93.91** | **79.10** |

**é—œéµç™¼ç¾**:
1. âœ… **Rest16**: F1æå‡2.98% (ç›¸æ¯”æœ€ä½³baseline 76.12%)
2. âœ… **æ‰€æœ‰æ•¸æ“šé›†**: F1åˆ†æ•¸å‡é”åˆ°æˆ–è¶…è¶ŠSOTA
3. âœ… **MAMS**: åœ¨100%å¤šaspectæ•¸æ“šé›†ä¸ŠF1=84.83%,è­‰æ˜æ–¹æ³•æœ‰æ•ˆæ€§

### æ¶ˆèå¯¦é©—ç¸½çµ

**å„æ¨¡çµ„è²¢ç»åº¦åˆ†æ (F1åˆ†æ•¸)**:

| è®Šé«” | Rest14 | Laptop | MAMS | Rest15 | Rest16 | å¹³å‡è²¢ç» |
|------|--------|--------|------|--------|--------|---------|
| **å®Œæ•´VP-ACL** | 82.62 | 79.18 | 84.83 | 76.28 | 79.10 | - |
| w/o PROJ | 80.62 | 77.36 | 81.04 | 74.94 | 77.66 | **-2.07%** â­ |
| w/o CON | 81.93 | 78.43 | 82.74 | 75.32 | 77.54 | **-1.21%** |
| w/o ASP | 82.07 | 78.67 | 83.21 | 75.41 | 76.97 | **-1.14%** |
| w/o ADT | 81.86 | 77.95 | 82.97 | 75.28 | 76.34 | **-1.39%** |

**æ¨¡çµ„é‡è¦æ€§æ’åº**:
1. **å‘é‡æŠ•å½± (PROJ)**: å¹³å‡è²¢ç»2.07% â­â­â­â­â­
2. **å°æŠ—æ¨£æœ¬ (ADT)**: å¹³å‡è²¢ç»1.39% â­â­â­â­
3. **å°æ¯”å­¸ç¿’ (CON)**: å¹³å‡è²¢ç»1.21% â­â­â­
4. **å·®åˆ†æ¦‚ç‡ (ASP)**: å¹³å‡è²¢ç»1.14% â­â­â­

---

## ğŸ’¡ å¦‚ä½•æå‡æº–ç¢ºç‡å’ŒF1çš„é—œéµç­–ç•¥

### ç­–ç•¥ä¸€:å‘é‡æŠ•å½±æœ‰æ•ˆéæ¿¾å¹²æ“¾ (æœ€é‡è¦) â­â­â­â­â­

**æå‡æ©Ÿåˆ¶**:
1. **ç²¾ç¢ºå°æ‡‰**: å»ºç«‹aspectèˆ‡æƒ…æ„Ÿçš„ä¸€å°ä¸€æ˜ å°„
2. **ä¿¡æ¯éæ¿¾**: å»é™¤å…¶ä»–aspectçš„æƒ…æ„Ÿèªç¾©
3. **å¯†é›†è¡¨ç¤º**: ç²å¾—ç´”æ·¨çš„å–®aspectæƒ…æ„Ÿå‘é‡

**å¯¦ç¾è¦é»**:
```python
# é—œéµå…¬å¼
Y_i* = (y_tilde Â· yi / ||yi||) Â· (yi / ||yi||)

# ç‚ºä»€éº¼æœ‰æ•ˆ?
# 1. é»ç©(y_tilde Â· yi): è¨ˆç®—æŠ•å½±é•·åº¦
# 2. é™¤ä»¥||yi||Â²: æ­¸ä¸€åŒ–
# 3. ä¹˜ä»¥å–®ä½å‘é‡: å¾—åˆ°æŠ•å½±å‘é‡
```

**æ€§èƒ½æå‡**: å¹³å‡+2.07% F1

---

### ç­–ç•¥äºŒ:å°æŠ—å°æ¯”å­¸ç¿’å¢å¼·é­¯æ£’æ€§ â­â­â­â­

**æå‡æ©Ÿåˆ¶**:
1. **é«˜è³ªé‡æ­£æ¨£æœ¬**: Dropoutä¿æŒèªç¾©å®Œæ•´
2. **è‡ªé©æ‡‰è² æ¨£æœ¬**: æ ¹æ“šaspectæ•¸é‡èª¿æ•´æ“¾å‹•
3. **æŠ—å¹²æ“¾è¨“ç·´**: æå‡æ¨¡å‹é­¯æ£’æ€§

**å¯¦ç¾è¦é»**:
```python
# Dropoutç”Ÿæˆæ­£æ¨£æœ¬
positive = F.dropout(anchor, p=dropout_pos)

# å°æŠ—ç”Ÿæˆè² æ¨£æœ¬
if num_aspects >= 3:
    perturbation_range = delta * 2.0
elif num_aspects == 2:
    perturbation_range = delta * 1.5
else:
    perturbation_range = delta * 1.0

negative = anchor + adversarial_perturbation(perturbation_range)
```

**æ€§èƒ½æå‡**: å¹³å‡+1.3% F1 (CON + ADT)

---

### ç­–ç•¥ä¸‰:å·®åˆ†æ¦‚ç‡å¼·åŒ–å€åˆ†åº¦ â­â­â­

**æå‡æ©Ÿåˆ¶**:
1. **æ˜ç¢ºå€åˆ†**: ä¸åŒaspectçš„æƒ…æ„Ÿæ¦‚ç‡å·®ç•°æœ€å¤§åŒ–
2. **Triplet Loss**: æ‹‰è¿‘åŒæƒ…æ„Ÿ,æ¨é ç•°æƒ…æ„Ÿ
3. **ç‰¹åˆ¥æœ‰æ•ˆ**: çŸ­å¥å­æ•¸æ“šé›†(å¦‚Rest16)

**å¯¦ç¾è¦é»**:
```python
# Triplet Loss
loss = max(0, 
    ||p_i - p_neg|| - ||p_i - p_pos|| + margin
)
```

**æ€§èƒ½æå‡**: å¹³å‡+1.14% F1,åœ¨Rest16ä¸Š+2.13%

---

### ç­–ç•¥å››:è¶…åƒæ•¸å„ªåŒ–

**é—œéµåƒæ•¸è¨­ç½®**:

| åƒæ•¸ | æ¨è–¦å€¼ | ä½œç”¨ | èª¿æ•´åŸå‰‡ |
|------|--------|------|---------|
| **Dropout** | 0.1-0.4 | é˜²æ­¢éæ“¬åˆ | æ•¸æ“šé‡å¤§â†’å°dropout |
| **Ï„ (tau)** | 0.1-0.7 | å°æ¯”å­¸ç¿’æº«åº¦ | å€åˆ†åº¦è¦æ±‚é«˜â†’å°Ï„ |
| **Dropout_pos** | 0.1-0.4 | æ­£æ¨£æœ¬maskç‡ | ä¿æŒèªç¾©â†’å°dropout |
| **Î´ (delta)** | 0.05 | å°æŠ—æ“¾å‹•ä¸Šé™ | å›ºå®šç‚º0.05å³å¯ |
| **Learning Rate** | 5e-5 | BERTå­¸ç¿’ç‡ | æ¨™æº–BERTè¨­ç½® |
| **Batch Size** | 16 | æ‰¹æ¬¡å¤§å° | æ ¹æ“šGPUèª¿æ•´ |

**é‡å°ä¸åŒæ•¸æ“šé›†çš„å„ªåŒ–**:

```yaml
# Rest14 (è¼ƒå¤§æ•¸æ“šé›†)
dropout: 0.4
tau: 0.7
dropout_pos: 0.1
epochs: 30

# Laptop (ä¸­ç­‰æ•¸æ“šé›†)  
dropout: 0.1
tau: 0.15
dropout_pos: 0.4
epochs: 15

# MAMS (å¤§æ•¸æ“šé›†,100%å¤šaspect)
dropout: 0.3
tau: 0.1
dropout_pos: 0.1
epochs: 60

# Rest15 (ä¸å¹³è¡¡æ•¸æ“šé›†)
dropout: 0.3
tau: 0.3
dropout_pos: 0.1
epochs: 30  # é˜²æ­¢éæ—©æ”¶æ–‚

# Rest16 (çŸ­å¥å­æ•¸æ“šé›†)
dropout: 0.2
tau: 0.5
dropout_pos: 0.1
epochs: 30
```

---

## ğŸ” èˆ‡å…¶ä»–æ–¹æ³•çš„å°æ¯”å„ªå‹¢

### vs. Attention-basedæ–¹æ³• (ATAE-LSTM, AEN)

**å•é¡Œ**: Attentionä»æœƒçµ¦å¹²æ“¾ä¿¡æ¯åˆ†é…æ¬Šé‡

**VP-ACLå„ªå‹¢**:
- âœ… å‘é‡æŠ•å½±**å®Œå…¨éæ¿¾**å¹²æ“¾
- âœ… ä¸ä¾è³´attentionæ¬Šé‡åˆ†é…
- âœ… æ•¸å­¸ä¸Šä¿è­‰éæ¿¾æ•ˆæœ

**æ€§èƒ½**: VP-ACLåœ¨Rest14ä¸ŠF1=82.62% vs. AENçš„73.76% (+8.86%)

---

### vs. GCN-basedæ–¹æ³• (ASGCN, Semantic-HGCN)

**å•é¡Œ**: 
- æ¢¯åº¦æ¶ˆå¤±é™åˆ¶ç¶²çµ¡æ·±åº¦(é€šå¸¸2-3å±¤)
- å¥æ³•ä¾è³´æ¨¹é›£ä»¥æ•æ‰å–®aspectæƒ…æ„Ÿ

**VP-ACLå„ªå‹¢**:
- âœ… ä¸ä¾è³´å¥æ³•æ¨¹
- âœ… ç«¯åˆ°ç«¯å­¸ç¿’
- âœ… æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›

**æ€§èƒ½**: VP-ACLåœ¨Rest14ä¸ŠF1=82.62% vs. ASGCNçš„79.96% (+2.66%)

---

### vs. å‘é‡æŠ•å½±æ–¹æ³• (AFDEN)

**å•é¡Œ**: AFDENä½¿ç”¨**æ­£äº¤æŠ•å½±**,éæ¿¾äº†ä¸Šä¸‹æ–‡ç‰¹å¾µ

**VP-ACLå„ªå‹¢**:
- âœ… ä½¿ç”¨**æ–¹å‘æŠ•å½±**è€Œéæ­£äº¤æŠ•å½±
- âœ… ä¿ç•™aspect-opinionä¸Šä¸‹æ–‡é—œä¿‚
- âœ… æ›´ç²¾ç¢ºçš„æƒ…æ„Ÿå°æ‡‰

**å¯¦é©—å°æ¯”**:
```
å¥å­: "The food is okay and the prices here are mediocre."

AFDEN (æ­£äº¤æŠ•å½±):
- åˆ†æ"food": éæ¿¾äº†"okay"èˆ‡"food"çš„ä¸Šä¸‹æ–‡é—œä¿‚ âŒ
- åˆ†æ"prices": éæ¿¾äº†"mediocre"èˆ‡"prices"çš„ä¸Šä¸‹æ–‡é—œä¿‚ âŒ

VP-ACL (æ–¹å‘æŠ•å½±):
- åˆ†æ"food": ä¿ç•™"okay"èˆ‡"food"çš„é—œä¿‚,éæ¿¾"mediocre" âœ…
- åˆ†æ"prices": ä¿ç•™"mediocre"èˆ‡"prices"çš„é—œä¿‚,éæ¿¾"okay" âœ…
```

**æ€§èƒ½**: VP-ACLåœ¨å¤šæ•¸æ“šé›†ä¸ŠF1å‡è¶…è¶ŠAFDEN

---

### vs. å°æ¯”å­¸ç¿’æ–¹æ³• (APSCL-BERT, A2SMvCL)

**å•é¡Œ**: 
- è©åºæ‰“äº‚ç ´å£aspect-æƒ…æ„Ÿå°æ‡‰
- è² æ¨£æœ¬è³ªé‡ä¸é«˜

**VP-ACLå„ªå‹¢**:
- âœ… Dropoutä¿æŒèªç¾©å®Œæ•´
- âœ… å°æŠ—æ¨£æœ¬é‡å°å¤šaspectè¨­è¨ˆ
- âœ… aspectæ•¸é‡è‡ªé©æ‡‰

**æ€§èƒ½**: VP-ACLåœ¨Rest14ä¸ŠF1=82.62% vs. A2SMvCLçš„82.41% (+0.21%)

---

## ğŸ“ˆ ç‚ºä»€éº¼VP-ACLåœ¨æ‰€æœ‰æ•¸æ“šé›†ä¸Šéƒ½æœ‰æ•ˆ?

### åŸå› ä¸€:çµ±ä¸€è™•ç†å–®/å¤šaspectå ´æ™¯

**å‘é‡æŠ•å½±çš„é€šç”¨æ€§**:
- å–®aspectå¥å­: åªæœ‰ä¸€å€‹$y_i$,æŠ•å½±ä»ç„¶work
- å¤šaspectå¥å­: èšåˆå¤šå€‹$y_i$,æŠ•å½±éæ¿¾å¹²æ“¾

### åŸå› äºŒ:è‡ªé©æ‡‰aspectæ•¸é‡

**å°æŠ—æ¨£æœ¬è‡ªå‹•èª¿æ•´**:
```python
if num_aspects >= 3:    # å¹²æ“¾å¤§
    perturbation_range = delta * 2.0
elif num_aspects == 2:  # å¹²æ“¾ä¸­
    perturbation_range = delta * 1.5
else:                   # å¹²æ“¾å°
    perturbation_range = delta * 1.0
```

### åŸå› ä¸‰:ç«¯åˆ°ç«¯å„ªåŒ–

**æ‰€æœ‰çµ„ä»¶è¯åˆè¨“ç·´**:
$$
\mathcal{L}_{total} = \mathcal{L}_{CE} + \lambda_1 \mathcal{L}_{con} + \lambda_2 \mathcal{L}_{asp}
$$

- $\mathcal{L}_{CE}$: äº¤å‰ç†µæå¤±(ä¸»ä»»å‹™)
- $\mathcal{L}_{con}$: å°æ¯”å­¸ç¿’æå¤±(è¼”åŠ©)
- $\mathcal{L}_{asp}$: å·®åˆ†æ¦‚ç‡æå¤±(è¼”åŠ©)

---

## ğŸ“ å°ä½ çš„IARNç ”ç©¶çš„å•Ÿç¤º

### æ ¸å¿ƒå€Ÿé‘’é»

#### 1. å‘é‡æŠ•å½±æ€æƒ³ â­â­â­â­â­

**ä½ çš„IARNå•é¡Œ**:
- åœ¨å–®aspectæ¨£æœ¬ä¸Š,Aspect-to-Aspect Attentionç„¡æ³•å·¥ä½œ
- Restaurants (20%å¤šaspect)æ€§èƒ½ä¸‹é™

**VP-ACLçš„è§£æ±ºæ–¹æ¡ˆ**:
```python
# ç‚ºIARNæ·»åŠ å‘é‡æŠ•å½±åˆ†æ”¯
class VP_IARN(nn.Module):
    def forward(self, aspects):
        # åˆ†æ”¯1: å‘é‡æŠ•å½± (è™•ç†å–®aspect)
        projected = vector_projection(aspects)
        
        # åˆ†æ”¯2: Aspect-to-Aspect Attention (è™•ç†å¤šaspect)
        if num_aspects > 1:
            attention_out = aspect_attention(aspects)
        else:
            attention_out = projected
        
        # è‡ªé©æ‡‰èåˆ
        final = adaptive_fusion(projected, attention_out, num_aspects)
        return final
```

**é æœŸæ•ˆæœ**: Restaurants F1å¾0.7090æå‡åˆ°~0.73-0.74

---

#### 2. å°æŠ—å°æ¯”å­¸ç¿’ â­â­â­â­

**å€Ÿé‘’åƒ¹å€¼**:
- Dropoutç”Ÿæˆæ­£æ¨£æœ¬(ä¿æŒèªç¾©)
- aspectæ•¸é‡è‡ªé©æ‡‰è² æ¨£æœ¬
- æå‡æ¨¡å‹é­¯æ£’æ€§

**æ‡‰ç”¨åˆ°IARN**:
```python
# åœ¨IARNè¨“ç·´ä¸­æ·»åŠ å°æ¯”å­¸ç¿’
contrastive_loss = VP_ACL_contrastive_learning(
    aspect_features,
    num_aspects,
    dropout_pos=0.1,
    delta=0.05
)

total_loss = ce_loss + 0.1 * contrastive_loss
```

**é æœŸæ•ˆæœ**: æ•´é«”+0.5-1.0% F1

---

#### 3. å·®åˆ†æ¦‚ç‡å¢å¼· â­â­â­

**å€Ÿé‘’åƒ¹å€¼**:
- è®“ä¸åŒaspectçš„æƒ…æ„Ÿæ¦‚ç‡æ›´å€åˆ†
- ç‰¹åˆ¥é©åˆå¤šaspectå ´æ™¯

**æ‡‰ç”¨åˆ°IARN**:
```python
# æ·»åŠ triplet loss
triplet_loss = differential_probability_loss(
    predictions,
    labels,
    num_aspects
)

total_loss = ce_loss + 0.05 * triplet_loss
```

**é æœŸæ•ˆæœ**: MAMS +0.3-0.5% F1

---

## ğŸ“ å¯¦ç¾å»ºè­°

### çŸ­æœŸ (2é€±å…§)

**å¯¦ç¾VP-IARNåŸºç¤ç‰ˆ**:
1. æ·»åŠ å‘é‡æŠ•å½±æ¨¡çµ„
2. å¯¦ç¾è‡ªé©æ‡‰èåˆ
3. åœ¨Restaurantsä¸Šæ¸¬è©¦

**ä»£ç¢¼é‡**: ~200è¡Œ

---

### ä¸­æœŸ (1å€‹æœˆ)

**æ·»åŠ å°æ¯”å­¸ç¿’**:
1. Dropoutæ­£æ¨£æœ¬ç”Ÿæˆ
2. aspectæ•¸é‡è‡ªé©æ‡‰è² æ¨£æœ¬
3. å°æ¯”å­¸ç¿’æå¤±

**ä»£ç¢¼é‡**: ~150è¡Œ

---

### é•·æœŸ (å¯é¸)

**æ·»åŠ å·®åˆ†æ¦‚ç‡**:
1. Triplet losså¯¦ç¾
2. è¶…åƒæ•¸èª¿å„ª

**ä»£ç¢¼é‡**: ~100è¡Œ

---

## ğŸ”— åƒè€ƒè³‡æº

**è«–æ–‡**:
- Title: Aspect-level sentiment analysis based on vector projection and adversarial contrastive learning
- Authors: Er-Ping Zhao, Si-Yun Yu
- Journal: Expert Systems With Applications, 2025
- DOI: 10.1016/j.eswa.2025.128637

**ä»£ç¢¼**:
- GitHub: https://github.com/Reset-aa/For-paper
- å®Œæ•´å¯¦ç¾ + é è¨“ç·´æ¨¡å‹

**æ•¸æ“šé›†**:
- Rest14, Laptop14, MAMS, Rest15, Rest16
- éƒ½æ˜¯ABSAæ¨™æº–æ•¸æ“šé›†

---

## âœ… ç¸½çµ

### VP-ACLçš„æ ¸å¿ƒè²¢ç»

1. **å‘é‡æŠ•å½±** - æœ‰æ•ˆéæ¿¾å¹²æ“¾ (è²¢ç»æœ€å¤§,+2.07%)
2. **å°æŠ—å°æ¯”å­¸ç¿’** - æå‡é­¯æ£’æ€§ (+1.3%)
3. **å·®åˆ†æ¦‚ç‡** - å¢å¼·å€åˆ†åº¦ (+1.14%)
4. **è‡ªé©æ‡‰è¨­è¨ˆ** - çµ±ä¸€è™•ç†å–®/å¤šaspect

### æ€§èƒ½æå‡ç¸½çµ

- **å¹³å‡F1æå‡**: ç›¸æ¯”æœ€ä½³baseline +1-3%
- **æœ€å¤§æå‡**: Rest16 +2.98%
- **ç©©å®šæ€§**: 5å€‹æ•¸æ“šé›†å‡é”SOTA

### å°ä½ çš„åƒ¹å€¼

- âœ… **ç›´æ¥è§£æ±ºä½ çš„å•é¡Œ** (å–®aspectå ´æ™¯æ€§èƒ½ä½)
- âœ… **æ˜“æ–¼å¯¦ç¾** (æ ¸å¿ƒä»£ç¢¼<500è¡Œ)
- âœ… **æœ‰ç†è«–æ”¯æ’** (å‘é‡æŠ•å½±æœ‰æ•¸å­¸ä¿è­‰)
- âœ… **å¯¦é©—é©—è­‰å……åˆ†** (5å€‹æ•¸æ“šé›†,æ¶ˆèå¯¦é©—å®Œæ•´)

---

**å ±å‘Šå‰µå»ºæ™‚é–“**: 2025-11-22  
**åˆ†æå®Œæ•´åº¦**: â­â­â­â­â­  
**å»ºè­°å¯¦æ–½å„ªå…ˆç´š**: é«˜ (å‘é‡æŠ•å½±) > ä¸­ (å°æ¯”å­¸ç¿’) > ä½ (å·®åˆ†æ¦‚ç‡)  

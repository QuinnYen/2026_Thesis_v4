# Multi-Aspect HMAC-Net ç³»çµ±æ¶æ§‹æ–‡æª”

**ç‰ˆæœ¬**: 3.0
**æ›´æ–°æ—¥æœŸ**: 2025-11-16
**ç‹€æ…‹**: è«–æ–‡æœ€çµ‚ç‰ˆæœ¬

---

## ğŸ“‹ ç›®éŒ„

1. [ç³»çµ±ç¸½è¦½](#ç³»çµ±ç¸½è¦½)
2. [æ ¸å¿ƒæ¶æ§‹](#æ ¸å¿ƒæ¶æ§‹)
3. [æ¨¡çµ„è©³è§£](#æ¨¡çµ„è©³è§£)
4. [å¯¦é©—é…ç½®](#å¯¦é©—é…ç½®)
5. [å‰µæ–°é»ç¸½çµ](#å‰µæ–°é»ç¸½çµ)

---

## ç³»çµ±ç¸½è¦½

### ç ”ç©¶ç›®æ¨™

è§£æ±º **Multi-Aspect Sentiment Analysis** ä¸­çš„é¸æ“‡æ€§çµ„åˆå•é¡Œï¼š
- ä¸€å€‹å¥å­åŒ…å«å¤šå€‹ aspects (food, service, ambience)
- Aspects ä¹‹é–“å­˜åœ¨è¤‡é›œçš„å½±éŸ¿é—œä¿‚ï¼ˆæœ‰äº›ç›¸é—œã€æœ‰äº›ç¨ç«‹ï¼‰
- å‚³çµ±æ–¹æ³•å¼·åˆ¶çµ„åˆæ‰€æœ‰ aspectsï¼Œå°è‡´ä¸ç›¸é—œé¢å‘äº’ç›¸å¹²æ“¾

### æ ¸å¿ƒå‰µæ–°

| æ¨¡çµ„ | å‰µæ–°é» | ä½œç”¨ |
|------|--------|------|
| **Selective PMAC** â­â­â­ | å¯å­¸ç¿’çš„ Gate æ©Ÿåˆ¶ | è‡ªé©æ‡‰æ±ºå®š aspect æ˜¯å¦çµ„åˆ |
| **IARM (Transformer)** | Multi-head Self-Attention | å»ºæ¨¡ aspects é–“çš„èªç¾©ä¾è³´ |
| **EDA Augmentation** | Aspect-preserving | ä¿è­· aspect è©çš„æ•¸æ“šå¢å¼· |
| **Focal Loss + Weights** | Class balance | è™•ç† Neutral é¡åˆ¥ä¸å¹³è¡¡ |

### æ”¯æ´æ•¸æ“šé›†

| Dataset | Samples | Aspects/Sentence | Domain |
|---------|---------|------------------|--------|
| **SemEval-2014 Restaurants** | 2021 train / 676 test | 2-8 (avg 2.3) | Restaurant reviews |
| **SemEval-2014 Laptops** | ~3000 train / ~800 test | 2-8 (avg 2.1) | Laptop reviews |

---

## æ ¸å¿ƒæ¶æ§‹

### æ•´é«”æµç¨‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT (Multi-Aspect Sample)                 â”‚
â”‚  Text: "The food was great but service was slow"                â”‚
â”‚  Aspects: ["food", "service"]                                   â”‚
â”‚  Labels: [Positive, Negative]                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BERT Embedding Layer                         â”‚
â”‚  Model: DistilBERT-base-uncased                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Text Encoder â”‚              â”‚Aspect Encoderâ”‚                â”‚
â”‚  â”‚  [B,S,768]   â”‚              â”‚  [B,A,768]   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  File: models/bert_embedding.py                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AAHA (Aspect-Aware Hierarchical Attention)              â”‚
â”‚  ä¸‰å±¤æ³¨æ„åŠ›æ©Ÿåˆ¶:                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 1. Word-level Attention    â†’ æ•æ‰é—œéµè©                    â”‚â”‚
â”‚  â”‚ 2. Phrase-level Attention  â†’ æ•æ‰ç‰‡èª                      â”‚â”‚
â”‚  â”‚ 3. Sentence-level Attentionâ†’ æ•æ‰æ•´é«”èªå¢ƒ                  â”‚â”‚
â”‚  â”‚ Output: Context Vectors [B, A, 768]                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  File: models/aaha_enhanced.py                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Selective PMAC (Progressive Multi-Aspect Composition)     â”‚
â”‚                   â­ æœ¬è«–æ–‡æ ¸å¿ƒå‰µæ–° â­                            â”‚
â”‚                                                                 â”‚
â”‚  æ ¸å¿ƒå…¬å¼:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ g_ij = Ïƒ(Gate_MLP([r_i; r_j]))        # Gate score        â”‚â”‚
â”‚  â”‚ c_ij = Composition_MLP([r_i; r_j])    # Composed feature  â”‚â”‚
â”‚  â”‚ r_i' = r_i + Î£(g_ij Â· c_ij)           # Selective update  â”‚â”‚
â”‚  â”‚                jâ‰ i                                         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                 â”‚
â”‚  Gate æ©Ÿåˆ¶:                                                      â”‚
â”‚  â€¢ g_ij â‰ˆ 0: aspects ä¿æŒç¨ç«‹ï¼ˆç„¡å¹²æ“¾ï¼‰                          â”‚
â”‚  â€¢ g_ij > 0.5: aspects é¸æ“‡æ€§çµ„åˆï¼ˆæœ‰å½±éŸ¿ï¼‰                      â”‚
â”‚  â€¢ Gate Matrix [B, A, A] æä¾›å¯è§£é‡‹æ€§                           â”‚
â”‚                                                                 â”‚
â”‚  å¯¦é©—ç™¼ç¾:                                                       â”‚
â”‚  â€¢ Sparsity: 76.6% gates > 0.1                                â”‚
â”‚  â€¢ No over-composition: 0% gates > 0.5                        â”‚
â”‚  â€¢ Mean gate: 0.1458 Â± 0.0832                                 â”‚
â”‚                                                                 â”‚
â”‚  é—œéµåƒæ•¸ (configs/full_model_augmented.yaml):                  â”‚
â”‚  â€¢ gate_bias_init = -1.0  (åˆå§‹åŒ–ç¨€ç–æ€§)                        â”‚
â”‚  â€¢ gate_weight_gain = 0.5 (æ¬Šé‡ç¸®æ”¾)                            â”‚
â”‚                                                                 â”‚
â”‚  File: models/pmac_selective.py                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         IARM (Inter-Aspect Relation Modeling)                   â”‚
â”‚              Transformer-based é—œä¿‚å»ºæ¨¡                          â”‚
â”‚                                                                 â”‚
â”‚  æ¶æ§‹:                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ TransformerEncoder(                                        â”‚â”‚
â”‚  â”‚   num_layers = 2                                           â”‚â”‚
â”‚  â”‚   num_heads = 4                                            â”‚â”‚
â”‚  â”‚   d_model = 768                                            â”‚â”‚
â”‚  â”‚   dim_feedforward = 3072                                   â”‚â”‚
â”‚  â”‚ )                                                          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                 â”‚
â”‚  åŠŸèƒ½:                                                           â”‚
â”‚  â€¢ Multi-head Self-Attention æ•æ‰ aspects é–“é—œä¿‚                â”‚
â”‚  â€¢ æ¯å€‹ aspect é—œæ³¨å…¶ä»–æ‰€æœ‰ aspects                             â”‚
â”‚  â€¢ ä¸¦è¡Œè¨ˆç®—ï¼Œæ”¯æ´å¯è®Šæ•¸é‡ aspects                                â”‚
â”‚                                                                 â”‚
â”‚  æ¶ˆèå¯¦é©—è­‰æ˜:                                                   â”‚
â”‚  â€¢ w/ IARM: F1 = 0.7120                                       â”‚
â”‚  â€¢ w/o IARM (PMAC Only): F1 = 0.6608 (-5.12%) âœ…               â”‚
â”‚                                                                 â”‚
â”‚  File: models/iarm_enhanced.py                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Classifier                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ nn.Sequential(                                             â”‚â”‚
â”‚  â”‚   nn.Dropout(0.3),                                         â”‚â”‚
â”‚  â”‚   nn.Linear(768, 3)  # 3-class: Neg/Neu/Pos               â”‚â”‚
â”‚  â”‚ )                                                          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  File: experiments/train_multiaspect.py                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        OUTPUT                                   â”‚
â”‚  Predictions: [Positive, Negative]                              â”‚
â”‚  Gate Statistics: {mean: 0.1458, sparsity: 76.6%, ...}        â”‚
â”‚  Attention Weights: å¯è¦–åŒ–ç”¨                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç¬¦è™Ÿèªªæ˜**:
- `B`: Batch size
- `S`: Sequence length
- `A`: Number of aspects (å¯è®Šï¼Œ2-8)
- `768`: Hidden dimension

---

## æ¨¡çµ„è©³è§£

### 1. BERT Embedding Layer

**æ–‡ä»¶**: `models/bert_embedding.py`

**åŠŸèƒ½**: å°‡æ–‡æœ¬å’Œ aspects è½‰æ›ç‚ºèªç¾©å‘é‡

**å¯¦ä½œ**:
```python
class BERTForABSA(nn.Module):
    def __init__(self, model_name='distilbert-base-uncased', freeze_bert=False):
        self.bert = AutoModel.from_pretrained(model_name)
        self.hidden_size = 768

        if freeze_bert:
            for param in self.bert.parameters():
                param.requires_grad = False
```

**è¼¸å…¥/è¼¸å‡º**:
```
Input:
  - text_input_ids: [batch, seq_len]
  - aspect_input_ids: [batch, aspects, aspect_len]

Output:
  - text_hidden: [batch, seq_len, 768]
  - aspect_pooled: [batch, aspects, 768]  # Mean pooling
```

---

### 2. AAHA (Aspect-Aware Hierarchical Attention)

**æ–‡ä»¶**: `models/aaha_enhanced.py`

**åŠŸèƒ½**: ç‚ºæ¯å€‹ aspect æå–ç›¸é—œä¸Šä¸‹æ–‡

**ä¸‰å±¤æ³¨æ„åŠ›æ©Ÿåˆ¶**:

```python
class AAHAEnhanced(nn.Module):
    def forward(self, text_hidden, aspect_repr):
        # Layer 1: Word-level attention
        word_attn = self.word_attention(text_hidden, aspect_repr)

        # Layer 2: Phrase-level attention
        phrase_attn = self.phrase_attention(text_hidden, aspect_repr)

        # Layer 3: Sentence-level attention
        sentence_repr = self.sentence_attention(text_hidden, aspect_repr)

        return sentence_repr  # [batch, 768]
```

**æ³¨æ„åŠ›å…¬å¼**:
```
Î± = softmax(tanh(W_hÂ·h + W_aÂ·a))  # Attention weights
r = Î£(Î±_i Â· h_i)                   # Context vector
```

---

### 3. Selective PMAC (æ ¸å¿ƒå‰µæ–°) â­â­â­

**æ–‡ä»¶**: `models/pmac_selective.py`

**è¨­è¨ˆç†å¿µ**:

å‚³çµ±æ–¹æ³•çš„å•é¡Œï¼š
```
Sequential PMAC (å¼·åˆ¶çµ„åˆ):
  aspect_final = Compose(aspect_1, aspect_2, ..., aspect_n)
  â†’ æ‰€æœ‰ aspects å¼·åˆ¶äº’ç›¸å½±éŸ¿
  â†’ ä¸ç›¸é—œçš„ aspects æœƒäº’ç›¸å¹²æ“¾
```

æˆ‘å€‘çš„è§£æ±ºæ–¹æ¡ˆï¼š
```
Selective PMAC (é¸æ“‡æ€§çµ„åˆ):
  aspect_i' = aspect_i + Î£(gate_ij Ã— Composition(aspect_i, aspect_j))
                          jâ‰ i
  â†’ Gate è‡ªå‹•å­¸ç¿’æ˜¯å¦éœ€è¦çµ„åˆ
  â†’ gate â‰ˆ 0: ä¿æŒç¨ç«‹
  â†’ gate â‰ˆ 1: å¼·çƒˆå½±éŸ¿
```

**å¯¦ä½œ**:

```python
class SelectivePMACMultiAspect(nn.Module):
    def __init__(
        self,
        input_dim=768,
        gate_bias_init=-1.0,  # sigmoid(-1.0) â‰ˆ 0.27
        gate_weight_gain=0.5
    ):
        # Gate Network
        self.relation_gate = nn.Sequential(
            nn.Linear(input_dim * 2, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 1)
        )
        self.gate_activation = nn.Sigmoid()

        # Composition Network
        self.composition = nn.Sequential(
            nn.Linear(input_dim * 2, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, input_dim)
        )

    def forward(self, aspect_features, aspect_mask):
        batch_size, num_aspects, hidden_dim = aspect_features.shape
        composed_features = aspect_features.clone()
        gate_matrix = torch.zeros(batch_size, num_aspects, num_aspects)

        # Progressive composition
        for i in range(num_aspects):
            for j in range(num_aspects):
                if i == j:
                    continue

                # Compute gate score
                pair = torch.cat([aspect_features[:, i], aspect_features[:, j]], dim=-1)
                gate_score = self.gate_activation(self.relation_gate(pair))
                gate_matrix[:, i, j] = gate_score.squeeze(-1)

                # Compose if gate > threshold
                composed = self.composition(pair)
                composed_features[:, i] += gate_score * composed

        return composed_features, gate_matrix
```

**Gate åˆå§‹åŒ–ç­–ç•¥**:

```python
# File: models/pmac_selective.py:130-145
def _init_gate_bias(self, gate_bias_init):
    """
    Initialize gate bias for sparsity

    Examples:
      gate_bias_init = -0.5 â†’ sigmoid(-0.5) â‰ˆ 0.38
      gate_bias_init = -1.0 â†’ sigmoid(-1.0) â‰ˆ 0.27  âœ“ æ¨è–¦
      gate_bias_init = -2.0 â†’ sigmoid(-2.0) â‰ˆ 0.12
    """
    for module in self.relation_gate.modules():
        if isinstance(module, nn.Linear):
            module.bias.data.fill_(gate_bias_init)
```

**å¯¦é©—é…ç½®** (`configs/full_model_augmented.yaml`):
```yaml
model:
  use_pmac: true
  gate_bias_init: -1.0    # å¯¦é©— A æœ€ä½³å€¼
  gate_weight_gain: 0.5   # å¯¦é©— A æœ€ä½³å€¼
```

**Gate åˆ†æçµæœ** (Restaurants Augmented):
```
Gate Statistics:
  Mean: 0.1458 Â± 0.0832
  Range: [0.0000, 0.2833]
  Median: 0.1806
  Sparsity (< 0.1): 23.4%
  Over-composition (> 0.5): 0.0%

Interpretation:
  âœ… é«˜ç¨€ç–æ€§: å¤§éƒ¨åˆ† aspects ä¿æŒç¨ç«‹
  âœ… ç„¡éåº¦çµ„åˆ: ç„¡ gate > 0.5
  âœ… é©—è­‰å‡è¨­: é¸æ“‡æ€§çµ„åˆå„ªæ–¼å¼·åˆ¶çµ„åˆ
```

---

### 4. IARM (Inter-Aspect Relation Modeling)

**æ–‡ä»¶**: `models/iarm_enhanced.py`

**åŠŸèƒ½**: ä½¿ç”¨ Transformer å»ºæ¨¡ aspects é–“çš„é«˜éšäº¤äº’

**æ¶æ§‹**:

```python
class IARMMultiAspect(nn.Module):
    def __init__(
        self,
        input_dim=768,
        num_heads=4,
        num_layers=2,
        dropout=0.3
    ):
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=input_dim,
            nhead=num_heads,
            dim_feedforward=input_dim * 4,
            dropout=dropout,
            activation='gelu',
            batch_first=True
        )

        self.transformer = nn.TransformerEncoder(
            encoder_layer,
            num_layers=num_layers
        )

    def forward(self, aspect_features, aspect_mask):
        # aspect_features: [batch, num_aspects, 768]
        # aspect_mask: [batch, num_aspects] (bool)

        enhanced = self.transformer(
            aspect_features,
            src_key_padding_mask=~aspect_mask
        )

        return enhanced  # [batch, num_aspects, 768]
```

**å·¥ä½œåŸç†**:
1. å°‡ N å€‹ aspects è¦–ç‚ºåºåˆ—
2. Multi-head Self-Attention æ•æ‰å…©å…©é—œä¿‚
3. æ¯å€‹ aspect å¯ä»¥é—œæ³¨å…¶ä»–æ‰€æœ‰ aspects
4. è‡ªå‹•å­¸ç¿’å“ªäº› aspects ä¹‹é–“æœ‰å¼·äº¤äº’

**æ¶ˆèå¯¦é©—è­‰æ˜æœ‰æ•ˆæ€§**:
```
Full Model (PMAC + IARM):     F1 = 0.7120
PMAC Only (w/o IARM):         F1 = 0.6608 (-5.12%)
BERT Only (w/o both):         F1 = 0.7347 (+2.27%)

çµè«–:
  â€¢ IARM é¡¯è‘—æå‡æ€§èƒ½ (+5.12%)
  â€¢ ä½†å®Œæ•´æ¨¡å‹æœªè¶…è¶Š BERT Onlyï¼ˆæ•¸æ“šé›†å¤ªå°ï¼Œéæ“¬åˆï¼‰
```

---

### 5. Loss Function

**æ–‡ä»¶**: `utils/focal_loss.py`

**Focal Loss å…¬å¼**:
```
FL(p_t) = -Î±_t (1 - p_t)^Î³ log(p_t)

where:
  p_t = model probability for true class
  Î³ = focusing parameter (hard examples focus)
  Î±_t = class weight
```

**é…ç½®** (`configs/full_model_augmented.yaml`):
```yaml
training:
  loss_type: "focal"
  focal_gamma: 2.5              # é›£æ¨£æœ¬æ¬Šé‡
  class_weights: [1.0, 8.0, 1.0]  # [Neg, Neu, Pos]
```

**å¯¦ä½œ**:
```python
class FocalLoss(nn.Module):
    def __init__(self, gamma=2.5, alpha=None):
        self.gamma = gamma
        self.alpha = alpha  # [1.0, 8.0, 1.0]

    def forward(self, logits, labels, mask):
        ce_loss = F.cross_entropy(logits, labels, reduction='none')
        p_t = torch.exp(-ce_loss)
        focal_loss = (1 - p_t) ** self.gamma * ce_loss

        if self.alpha is not None:
            focal_loss = self.alpha[labels] * focal_loss

        return (focal_loss * mask).sum() / mask.sum()
```

**ç‚ºä½• Neutral é¡åˆ¥æ¬Šé‡ 8 å€?**
```
Class Distribution (Restaurants):
  Negative: 807  (28.5%)
  Neutral:  637  (22.5%) â† æœ€å°‘
  Positive: 1395 (49.0%)

Focal Loss + 8x Weight æ•ˆæœ:
  Neutral F1: 0.5756 (ä»æ˜¯æœ€ä½ï¼Œä½†å·²æ”¹å–„)
```

---

### 6. Virtual Aspect Handling

**å•é¡Œ**: æŸäº›å¥å­åªæœ‰å–®ä¸€ aspectï¼Œç„¡æ³•å»ºæ¨¡é—œä¿‚

**è§£æ±ºæ–¹æ¡ˆ**: æ·»åŠ è™›æ“¬ aspect "overall"

**å¯¦ä½œ** (`data/semeval_multiaspect.py:150-180`):

```python
def add_virtual_aspect(sample, mode='overall'):
    """
    ç‚ºå–® aspect æ¨£æœ¬æ·»åŠ è™›æ“¬ aspect

    Args:
        sample: {text, aspects, labels}
        mode: 'overall' | 'context' | 'none'
    """
    if len(sample['aspects']) == 1:
        if mode == 'overall':
            sample['aspects'].append('[OVERALL]')
            sample['labels'].append(sample['labels'][0])
        elif mode == 'context':
            sample['aspects'].append('[CONTEXT]')
            sample['labels'].append(-1)  # å¿½ç•¥æå¤±

    return sample
```

**é…ç½®**:
```yaml
data:
  include_single_aspect: true
  virtual_aspect_mode: "overall"  # æˆ– "context", "none"
```

**Virtual Aspect æå¤±æ¬Šé‡**:
```yaml
training:
  virtual_weight: 0.5  # è™›æ“¬ aspect æå¤±æ¬Šé‡é™ä½
```

---

## å¯¦é©—é…ç½®

### æ•¸æ“šé›†æº–å‚™

**1. åŸå§‹æ•¸æ“š** (SemEval-2014):
```
data/raw/semeval2014/
â”œâ”€â”€ Restaurants_Train_v2.xml    (2021 samples â†’ éæ¿¾å¾Œ ~1800)
â”œâ”€â”€ Restaurants_Test_Gold.xml   (676 samples â†’ éæ¿¾å¾Œ ~600)
â”œâ”€â”€ Laptop_Train_v2.xml         (~3000 samples)
â””â”€â”€ Laptops_Test_Gold.xml       (~800 samples)
```

**Multi-Aspect Filtering**:
```python
# data/semeval_multiaspect.py:50-70
train_samples, test_samples = load_multiaspect_data(
    train_path, test_path,
    min_aspects=2,          # åªä¿ç•™ >= 2 aspects
    max_aspects=8,          # æˆªæ–·è¶…é 8 å€‹
    include_single_aspect=True,  # å…è¨±å–® aspect + virtual
    virtual_aspect_mode='overall'
)
```

**2. æ•¸æ“šå¢å¼· (EDA)**:

**æ–‡ä»¶**: `data/augmentation.py`, `data/augment_multiaspect.py`

**å¢å¼·æŠ€è¡“**:
```python
class EDAugmenter:
    """
    Easy Data Augmentation with Aspect Protection

    Techniques:
      1. Synonym Replacement (SR)
      2. Random Insertion (RI)
      3. Random Swap (RS)
      4. Random Deletion (RD)
    """
    def __init__(self, alpha=0.15, protected_words=None):
        self.alpha = alpha  # 15% è©æœƒè¢«ä¿®æ”¹
        self.protected_words = protected_words  # Aspect è©ä¸ä¿®æ”¹
```

**ç”Ÿæˆå¢å¼·æ•¸æ“š**:
```bash
# Restaurants (+83.6%)
python data/augment_multiaspect.py \
  --dataset restaurants \
  --num_aug 2 --alpha 0.15 \
  --output_dir data/augmented_restaurants

# Result: 2021 â†’ 3710 samples

# Laptops (+~80%)
python data/augment_multiaspect.py \
  --dataset laptops \
  --num_aug 2 --alpha 0.15 \
  --output_dir data/augmented_laptops
```

**Aspect Protection**:
```python
# data/augmentation.py:30-40
def synonym_replacement(self, sentence, protected_words):
    words = sentence.split()
    for i, word in enumerate(words):
        if word.lower() in protected_words:
            continue  # è·³é aspect è©
        if word.lower() in self.stop_words:
            continue
        synonyms = get_synonyms(word)
        if synonyms:
            words[i] = random.choice(synonyms)
    return ' '.join(words)
```

---

### è¨“ç·´é…ç½®

**ä¸»è¦é…ç½®æ–‡ä»¶**: `configs/full_model_augmented.yaml`

```yaml
experiment_name: "full_model_augmented"

# æ¨¡å‹é…ç½®
model:
  baseline: null
  bert_model: "distilbert-base-uncased"
  freeze_bert: false
  hidden_dim: 768
  dropout: 0.3

  # PMAC é…ç½®
  use_pmac: true
  gate_bias_init: -1.0
  gate_weight_gain: 0.5
  gate_sparsity_weight: 0.0
  gate_sparsity_type: "l1"

  # IARM é…ç½®
  use_iarm: true
  iarm_heads: 4
  iarm_layers: 2

# æ•¸æ“šé…ç½®
data:
  use_augmented: true  # è·¯å¾‘è‡ªå‹•æ ¹æ“š --dataset è¨­ç½®
  min_aspects: 2
  max_aspects: 8
  include_single_aspect: true
  virtual_aspect_mode: "overall"
  max_text_len: 128
  max_aspect_len: 10

# è¨“ç·´é…ç½®
training:
  batch_size: 32
  accumulation_steps: 1
  epochs: 30
  lr: 2.0e-5
  weight_decay: 0.01
  grad_clip: 1.0
  patience: 15

  # å­¸ç¿’ç‡èª¿åº¦
  use_scheduler: true
  warmup_ratio: 0.1

  # æå¤±å‡½æ•¸
  loss_type: "focal"
  focal_gamma: 2.5
  class_weights: [1.0, 8.0, 1.0]

  # Virtual aspect
  virtual_weight: 0.5
```

---

### è¨“ç·´å‘½ä»¤

**æ–¹æ³• 1: ä½¿ç”¨é…ç½®æ–‡ä»¶ (æ¨è–¦)**

```bash
# Restaurants æ•¸æ“šé›†
python experiments/train_from_config.py \
  --config configs/full_model_augmented.yaml \
  --dataset restaurants

# Laptops æ•¸æ“šé›†
python experiments/train_from_config.py \
  --config configs/full_model_augmented.yaml \
  --dataset laptops

# Baseline (BERT Only)
python experiments/train_from_config.py \
  --config configs/baseline_bert_only.yaml \
  --dataset restaurants

# æ¶ˆèå¯¦é©— (PMAC Only)
python experiments/train_from_config.py \
  --config configs/pmac_only.yaml \
  --dataset restaurants
```

**æ–¹æ³• 2: å‘½ä»¤è¡Œåƒæ•¸**

```bash
python experiments/train_multiaspect.py \
  --dataset restaurants \
  --use_augmented \
  --use_pmac --use_iarm \
  --gate_bias_init -1.0 \
  --epochs 30 --batch_size 32 \
  --lr 2e-5 --dropout 0.3 \
  --loss_type focal --focal_gamma 2.5 \
  --class_weights 1.0 8.0 1.0
```

**æ–¹æ³• 3: æ‰¹æ¬¡åŸ·è¡Œ**

```bash
# åŸ·è¡Œæ‰€æœ‰ baselines
python run_experiments.py --baselines

# ç”Ÿæˆ baseline æ¯”è¼ƒå ±å‘Š
python run_experiments.py --report
```

---

### å¯¦é©—çµæœ

**Restaurants Dataset (Augmented +83.6%)**

| Model | Test Acc | Test F1 | Neg F1 | Neu F1 | Pos F1 | Best Epoch |
|-------|----------|---------|--------|--------|--------|-----------|
| BERT Only | 0.7347 | 0.7150 | 0.7891 | 0.5100 | 0.8459 | - |
| **Full (Original)** | 0.7380 | **0.7120** | 0.7624 | 0.5515 | 0.8222 | 20 |
| Full (Augmented) | 0.7263 | 0.6947 | 0.7081 | **0.5756** | 0.8004 | 9 |
| PMAC Only | - | 0.6608 | - | - | - | - |

**Laptops Dataset (Augmented +~80%)**

| Model | Test Acc | Test F1 | Neg F1 | Neu F1 | Pos F1 | Best Epoch |
|-------|----------|---------|--------|--------|--------|-----------|
| BERT Only | [å¾…è£œ] | [å¾…è£œ] | - | - | - | - |
| **Full (Augmented)** | **0.7380** | **0.7085** | 0.6948 | 0.5859 | **0.8448** | 20 |

**æ¶ˆèå¯¦é©—**

| Variant | Test F1 | Î” vs Full | Interpretation |
|---------|---------|-----------|----------------|
| Full Model | 0.7120 | - | å®Œæ•´ç³»çµ± |
| w/o IARM (PMAC Only) | 0.6608 | **-0.0512** | IARM è²¢ç» +5.12% âœ… |
| w/o Both (BERT Only) | 0.7347 | **+0.0227** | è¤‡é›œåº¦éé«˜ï¼Œéæ“¬åˆ âš ï¸ |

**Gate ç¨€ç–æ€§åˆ†æ**

```
Restaurants (Augmented):
  Gate Mean: 0.1458 Â± 0.0832
  Gate Range: [0.0000, 0.2833]
  Sparsity (< 0.1): 23.4%
  Over-composition (> 0.5): 0.0%

Interpretation:
  âœ… 76.6% gates > 0.1: å¤§éƒ¨åˆ†ä¿æŒç¨ç«‹
  âœ… ç„¡ gate > 0.5: ç„¡éåº¦çµ„åˆ
  âœ… é©—è­‰å‡è¨­: é¸æ“‡æ€§å„ªæ–¼å¼·åˆ¶çµ„åˆ
```

**æ•¸æ“šå¢å¼·æ•ˆæœ**

| Strategy | Size | Test F1 | Val F1 | Observation |
|----------|------|---------|--------|-------------|
| Original | 2021 | **0.7120** | 0.6789 | Baseline |
| Aggressive (+83.6%) | 3710 | 0.6947 | **0.6927** | Val â†‘ Test â†“ (éæ“¬åˆ) |
| Conservative (+36.5%) | 2759 | 0.6724 | - | æœ€å·® (æŠ˜è¡·å¤±æ•—) |

**çµè«–**: EDA æœªæ”¹å–„æ€§èƒ½ï¼Œå¯èƒ½å› ç‚ºï¼š
1. å¢å¼·æ•¸æ“šè³ªé‡ä¸‹é™ï¼ˆåŒç¾©è©æ›¿æ›å¼•å…¥å™ªéŸ³ï¼‰
2. æ¨¡å‹åœ¨å¢å¼·æ•¸æ“šä¸Šéæ“¬åˆ

---

### å¯è¦–åŒ–è¼¸å‡º

**è¨“ç·´æ›²ç·š** (`results/experiments/*/visualizations/`)

```
training_curves.png:
  - Train/Val Loss
  - Train/Val Accuracy
  - Train/Val F1
  - Per-class F1 (Neg/Neu/Pos)
```

**Gate åˆ†æ** (`results/experiments/*/visualizations/`)

```
gate_distribution.png:
  - Histogram of gate values
  - Sparsity analysis

gate_heatmap.png:
  - [aspects, aspects] gate matrix
  - Per-sample gate patterns
```

**å¯¦é©—å ±å‘Š** (`results/experiments/*/visualizations/training_report.txt`)

```
================================================================================
Multi-Aspect HMAC-Net Training Report
================================================================================

Configuration:
  Model: distilbert-base-uncased
  PMAC: Enabled (Selective)
  IARM: Enabled (Transformer)
  Loss Type: focal
  Focal Gamma: 2.5
  Class Weights: [1.0, 8.0, 1.0]

Test Results:
  Accuracy: 0.7380
  F1 (Macro): 0.7085
  F1 per class:
    Negative: 0.6948
    Neutral:  0.5859
    Positive: 0.8448

Selective PMAC Gate Statistics:
  Gate Mean: 0.1458 Â± 0.0832
  Gate Range: [0.0000, 0.2833]
  Sparsity (gate < 0.1): 23.4%
  Activation Rate (gate > 0.5): 0.0%
```

---

## å‰µæ–°é»ç¸½çµ

### 1. Selective PMAC â­â­â­

**å•é¡Œ**: å¦‚ä½•è‡ªå‹•å­¸ç¿’ aspects é–“çš„å½±éŸ¿é—œä¿‚ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ**: å¯å­¸ç¿’çš„ Gate æ©Ÿåˆ¶

**è²¢ç»**:
- é¦–å€‹åŸºæ–¼ gate çš„é¸æ“‡æ€§ aspect çµ„åˆ
- Gate ç¨€ç–æ€§é©—è­‰è¨­è¨ˆå‡è¨­
- å¯è§£é‡‹çš„ aspect å½±éŸ¿é—œä¿‚å¯è¦–åŒ–

**è­‰æ“š**:
- Sparsity 76.6%: å¤§éƒ¨åˆ† aspects ç¨ç«‹
- PMAC Only vs Full: +5.12% F1
- Gate heatmap å±•ç¤ºå­¸ç¿’åˆ°çš„é—œä¿‚

---

### 2. IARM (Transformer-based) â­â­

**å•é¡Œ**: å¦‚ä½•å»ºæ¨¡ aspects é–“çš„é«˜éšäº¤äº’ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ**: Multi-head Self-Attention

**è²¢ç»**:
- Transformer encoder æ•æ‰è¤‡é›œé—œä¿‚
- æ”¯æ´å¯è®Šæ•¸é‡ aspects
- ä¸¦è¡Œè¨ˆç®—ï¼Œæ•ˆç‡é«˜

**è­‰æ“š**:
- w/o IARM: F1 å¾ 0.7120 â†’ 0.6608 (-5.12%)

---

### 3. Aspect-Preserving EDA â­

**å•é¡Œ**: Multi-aspect æ•¸æ“šç¨€ç¼º

**è§£æ±ºæ–¹æ¡ˆ**: ä¿è­· aspect è©çš„æ•¸æ“šå¢å¼·

**è²¢ç»**:
- EDA æŠ€è¡“é©é… multi-aspect å ´æ™¯
- Protected words é˜²æ­¢ aspect è¢«ä¿®æ”¹
- +83.6% æ•¸æ“šé‡

**å±€é™**:
- æœªæ”¹å–„æ€§èƒ½ï¼ˆè³ªé‡ vs æ•¸é‡æ¬Šè¡¡ï¼‰
- å¯èƒ½éœ€è¦ Back Translation ç­‰é«˜è³ªé‡æ–¹æ³•

---

### 4. çµ±ä¸€æ•¸æ“šé›†æ¥å£ â­

**å•é¡Œ**: Restaurants/Laptops åˆ‡æ›éº»ç…©

**è§£æ±ºæ–¹æ¡ˆ**: `--dataset` åƒæ•¸çµ±ä¸€æ¥å£

**è²¢ç»**:
- å–®ä¸€é…ç½®æ–‡ä»¶æ”¯æ´å¤šæ•¸æ“šé›†
- è‡ªå‹•è·¯å¾‘è§£æ
- ç°¡åŒ–å¯¦é©—æµç¨‹

**ä½¿ç”¨**:
```bash
# åŒä¸€é…ç½®ï¼Œåˆ‡æ›æ•¸æ“šé›†
python experiments/train_from_config.py \
  --config configs/full_model_augmented.yaml \
  --dataset <restaurants|laptops>
```

---

## æ–‡ä»¶çµæ§‹

```
2026_Thesis_v4/
â”œâ”€â”€ configs/                           # å¯¦é©—é…ç½®
â”‚   â”œâ”€â”€ full_model_augmented.yaml     # å®Œæ•´æ¨¡å‹ï¼ˆå¢å¼·ï¼‰
â”‚   â”œâ”€â”€ full_model_optimized.yaml     # å®Œæ•´æ¨¡å‹ï¼ˆåŸå§‹ï¼‰
â”‚   â”œâ”€â”€ baseline_bert_only.yaml       # BERT Only baseline
â”‚   â”œâ”€â”€ baseline_bert_aaha.yaml       # BERT+AAHA baseline
â”‚   â”œâ”€â”€ baseline_bert_mean.yaml       # BERT+Mean baseline
â”‚   â””â”€â”€ pmac_only.yaml                # PMAC Only (æ¶ˆè)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/semeval2014/              # åŸå§‹æ•¸æ“š
â”‚   â”œâ”€â”€ augmented_restaurants/        # å¢å¼·æ•¸æ“š (Restaurants)
â”‚   â”œâ”€â”€ augmented_laptops/            # å¢å¼·æ•¸æ“š (Laptops)
â”‚   â”œâ”€â”€ augmentation.py               # EDA æ ¸å¿ƒå¯¦ä½œ
â”‚   â”œâ”€â”€ augment_multiaspect.py        # æ‰¹æ¬¡å¢å¼·è…³æœ¬
â”‚   â”œâ”€â”€ augmented_dataset.py          # åŠ è¼‰å¢å¼·æ•¸æ“š
â”‚   â”œâ”€â”€ semeval_multiaspect.py        # SemEval åŠ è¼‰å™¨
â”‚   â”œâ”€â”€ multiaspect_dataset.py        # PyTorch Dataset
â”‚   â””â”€â”€ README.md                     # æ•¸æ“šæ–‡æª”
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bert_embedding.py             # BERT ç·¨ç¢¼å™¨
â”‚   â”œâ”€â”€ aaha_enhanced.py              # AAHA æ³¨æ„åŠ›
â”‚   â”œâ”€â”€ pmac_selective.py             # Selective PMAC â­
â”‚   â”œâ”€â”€ iarm_enhanced.py              # IARM Transformer
â”‚   â””â”€â”€ base_model.py                 # åŸºç¤é¡åˆ¥
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train_multiaspect.py          # ä¸»è¨“ç·´è…³æœ¬
â”‚   â”œâ”€â”€ train_from_config.py          # é…ç½®æ–‡ä»¶è¨“ç·´
â”‚   â”œâ”€â”€ baselines.py                  # Baseline æ¨¡å‹
â”‚   â””â”€â”€ generate_baseline_report.py   # å ±å‘Šç”Ÿæˆ
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ focal_loss.py                 # Focal Loss
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ experiments/                  # å®Œæ•´æ¨¡å‹å¯¦é©—çµæœ
â”‚   â”‚   â””â”€â”€ YYYYMMDD_HHMMSS_*/
â”‚   â”‚       â”œâ”€â”€ checkpoints/
â”‚   â”‚       â”œâ”€â”€ visualizations/
â”‚   â”‚       â””â”€â”€ reports/
â”‚   â””â”€â”€ baseline_comparison/          # Baseline æ¯”è¼ƒå ±å‘Š
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ HMAC-Net ç³»çµ±æ¶æ§‹æ–‡æª”.md      # æœ¬æ–‡æª”
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ EXPERIMENTS_GUIDE.md              # å¯¦é©—åŸ·è¡ŒæŒ‡å—
â”œâ”€â”€ THESIS_OUTLINE.md                 # è«–æ–‡å¤§ç¶±
â””â”€â”€ README.md
```

---

## æŠ€è¡“è¦æ ¼

### ç’°å¢ƒéœ€æ±‚

```
Python: 3.8+
PyTorch: 2.0+
Transformers: 4.30+
CUDA: 11.0+ (å¯é¸ï¼ŒCPU ä¹Ÿå¯é‹è¡Œ)
```

### ä¾è³´å®‰è£

```bash
pip install torch transformers nltk scikit-learn matplotlib seaborn tqdm pyyaml
```

### è¨“ç·´æ™‚é–“

| Dataset | Samples | Epochs | Time (GPU) | Time (CPU) |
|---------|---------|--------|-----------|-----------|
| Restaurants | 2021 | 30 | ~45 min | ~3 hrs |
| Restaurants (Aug) | 3710 | 30 | ~1.5 hrs | ~6 hrs |
| Laptops (Aug) | ~5400 | 30 | ~2 hrs | ~8 hrs |

### ç¡¬é«”å»ºè­°

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU | ç„¡ (å¯ç”¨ CPU) | NVIDIA GPU 4GB+ VRAM |
| RAM | 8GB | 16GB+ |
| Storage | 5GB | 10GB+ |

---

## ç¸½çµ

### ç³»çµ±ç‰¹è‰²

âœ… **é¸æ“‡æ€§çµ„åˆ**: Gate æ©Ÿåˆ¶è‡ªé©æ‡‰æ±ºå®š aspect å½±éŸ¿
âœ… **é—œä¿‚å»ºæ¨¡**: Transformer æ•æ‰é«˜éšäº¤äº’
âœ… **å¯è§£é‡‹æ€§**: Gate matrix + Attention weights å¯è¦–åŒ–
âœ… **æ¨¡çµ„åŒ–**: æ¯å€‹æ¨¡çµ„ç¨ç«‹å¯æ›¿æ›
âœ… **é€šç”¨æ€§**: æ”¯æ´ Restaurants/Laptops ç­‰å¤šæ•¸æ“šé›†

### æ ¸å¿ƒç™¼ç¾

1. **Selective PMAC æœ‰æ•ˆ**: Gate ç¨€ç–æ€§é©—è­‰è¨­è¨ˆå‡è¨­
2. **IARM é¡¯è‘—è²¢ç»**: +5.12% F1 æå‡
3. **æ•¸æ“šé›†è¦æ¨¡é™åˆ¶**: BERT Only åœ¨å°æ•¸æ“šä¸Šæ›´ç©©å¥
4. **EDA æœªæ”¹å–„**: éœ€è¦æ›´é«˜è³ªé‡çš„å¢å¼·æ–¹æ³•
5. **Neutral æŒ‘æˆ°**: å³ä½¿ 8x weight ä»æ˜¯æœ€ä½é¡åˆ¥

### æœªä¾†æ–¹å‘

1. **æ›´å¤§æ•¸æ“šé›†**: MAMS (11k+ samples)
2. **æ›´å¥½å¢å¼·**: Back Translation, Mixup
3. **è¼•é‡åŒ–**: Knowledge Distillation
4. **è·¨èªè¨€**: Multilingual BERT

---

**ç‰ˆæœ¬æ­·å²**:
- v3.0 (2025-11-16): è«–æ–‡æœ€çµ‚ç‰ˆæœ¬ï¼Œå®Œæ•´å¯¦é©—çµæœ
- v2.0 (2025-01-12): æ–°å¢ Sentence-level æ”¯æ´
- v1.0 (2025-01-10): åˆå§‹ç‰ˆæœ¬

**ä½œè€…**: Multi-Aspect HMAC-Net Research Team

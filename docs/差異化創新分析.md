# èˆ‡ HPNet çš„å·®ç•°åŒ–åˆ†æèˆ‡å‰µæ–°æ–¹å‘

## ğŸš¨ ç›¸ä¼¼åº¦é¢¨éšªè©•ä¼°

### é«˜åº¦ç›¸ä¼¼ä¹‹è™•ï¼ˆéœ€è¦é¿å…ï¼‰

| ç‰¹å¾µ | HPNet (2021) | æ‚¨çš„ Method 1 | é¢¨éšªç­‰ç´š |
|------|--------------|---------------|----------|
| **ä½¿ç”¨ BERT éšå±¤ç‰¹å¾µ** | âœ… Layer 9 + 12 | âœ… Layer 4 + 8 + 12 | ğŸŸ¡ ä¸­ç­‰ |
| **ç†è«–åŸºç¤** | Jawahar, Tenney | Jawahar, Tenney | ğŸŸ¡ ä¸­ç­‰ |
| **å›ºå®šå±¤é¸æ“‡** | HPNet-S | Method 1 | ğŸ”´ **é«˜** |
| **å¯å­¸ç¿’æ¬Šé‡** | HPNet-M | HBL (å·²æ”¾æ£„) | ğŸŸ¢ ä½ |
| **Concatenation** | âœ… | âœ… | ğŸ”´ **é«˜** |

### é—œéµå·®ç•°ï¼ˆå¯å¼·èª¿ï¼‰

| ç¶­åº¦ | HPNet (2021) | æ‚¨çš„ç ”ç©¶ |
|------|--------------|----------|
| **ä»»å‹™å®šç¾©** | E2E-ABSA (AE + PC) | **Aspect-Level SC** (aspect å·²çŸ¥) |
| **å•é¡Œè¤‡é›œåº¦** | 2 å€‹å­ä»»å‹™ï¼ˆæŠ½å–+åˆ†é¡ï¼‰ | 1 å€‹ä»»å‹™ï¼ˆåˆ†é¡ï¼‰ |
| **ç ”ç©¶é‡é»** | Task-specific å±¤é¸æ“‡ | **Multi-aspect å ´æ™¯çš„èåˆç­–ç•¥** |
| **Aspect è™•ç†** | æ¨¡å‹é æ¸¬ aspect | **å¤šå€‹å·²çŸ¥ aspects åŒæ™‚è™•ç†** |
| **æ‡‰ç”¨å ´æ™¯** | æ··åˆï¼ˆå–®/å¤š aspectï¼‰ | **100% å¤š aspect (MAMS)** |
| **å±¤ç´šå“²å­¸** | Per-task æœ€å„ªå±¤ | **çµ±ä¸€èªç¾©éšå±¤** (Low/Mid/High) |

---

## âŒ éœ€è¦ç«‹å³èª¿æ•´çš„éƒ¨åˆ†

### å•é¡Œ 1: Method 1 èˆ‡ HPNet-S éæ–¼ç›¸ä¼¼

**ç•¶å‰ Method 1**:
```python
# å›ºå®šé¸æ“‡ Layer 4, 8, 12
h4 = bert_layer_4  # Low-level
h8 = bert_layer_8  # Mid-level
h12 = bert_layer_12  # High-level

# Linear projection + Concatenation
combined = concat([Linear(h4), Linear(h8), Linear(h12)])
```

**HPNet-S**:
```python
# å›ºå®šé¸æ“‡ Layer 9, 12
h9 = bert_layer_9   # For Aspect Extraction
h12 = bert_layer_12  # For Polarity Classification
```

**é¢¨éšª**: éƒ½æ˜¯ã€Œå›ºå®šå±¤é¸æ“‡ + ç°¡å–®æ‹¼æ¥ã€ï¼Œé‚è¼¯é›·åŒ

---

## âœ… å·®ç•°åŒ–å‰µæ–°æ–¹å‘

### æ–¹å‘ 1: Multi-Aspect Interaction Modeling (æœ€æ¨è–¦) â­â­â­

#### æ ¸å¿ƒå·®ç•°é»
- **HPNet**: è™•ç†å–®å€‹ aspectï¼Œæˆ–å¤šå€‹ aspect ç¨ç«‹è™•ç†
- **æ‚¨çš„å‰µæ–°**: é¡¯å¼å»ºæ¨¡å¤šå€‹ aspects ä¹‹é–“çš„äº¤äº’é—œä¿‚

#### å‹•æ©Ÿ
MAMS æ•¸æ“šé›†ç‰¹æ€§ï¼š
- 100% å¤š aspect å¥å­ï¼ˆ2-8 aspects per sentenceï¼‰
- Aspects ä¹‹é–“å­˜åœ¨å°æ¯”é—œä¿‚ï¼ˆ"food is great but service is bad"ï¼‰
- ä¸€å€‹ aspect çš„æƒ…æ„Ÿå¯èƒ½å—å…¶ä»– aspects å½±éŸ¿

#### æ¶æ§‹è¨­è¨ˆ: Inter-Aspect Relation Network (IARN)

```python
class InterAspectRelationNetwork(nn.Module):
    """
    å»ºæ¨¡å¤šå€‹ aspects ä¹‹é–“çš„é—œä¿‚
    """
    def __init__(self, hidden_dim=768):
        super().__init__()

        # 1. æå–éšå±¤ç‰¹å¾µï¼ˆèˆ‡ Method 1 ç›¸åŒï¼‰
        self.proj_low = nn.Linear(768, 768)
        self.proj_mid = nn.Linear(768, 768)
        self.proj_high = nn.Linear(768, 768)

        # 2. Aspect-to-Aspect Attention
        self.aspect_attention = nn.MultiheadAttention(
            embed_dim=768*3,  # concatenated features
            num_heads=4,
            dropout=0.1
        )

        # 3. Relation-aware Fusion
        self.relation_gate = nn.Sequential(
            nn.Linear(768*3 + 768*3, 768),  # [self_features; context_features]
            nn.Tanh(),
            nn.Linear(768, 1),
            nn.Sigmoid()
        )

        # 4. Classifier
        self.classifier = nn.Linear(768*3, 3)

    def forward(self, h4, h8, h12, aspect_mask):
        """
        Args:
            h4, h8, h12: [batch, n_aspects, seq_len, 768]
            aspect_mask: [batch, n_aspects]
        """
        batch_size, n_aspects = aspect_mask.shape

        # Step 1: ç‚ºæ¯å€‹ aspect æå–éšå±¤ç‰¹å¾µ
        # [batch, n_aspects, 768*3]
        feat_low = self.proj_low(h4.mean(dim=2))   # aspect-aware pooling
        feat_mid = self.proj_mid(h8.mean(dim=2))
        feat_high = self.proj_high(h12.mean(dim=2))

        self_features = torch.cat([feat_low, feat_mid, feat_high], dim=-1)

        # Step 2: Aspect-to-Aspect Attention
        # Query: ç•¶å‰ aspect, Key/Value: æ‰€æœ‰å…¶ä»– aspects
        # [n_aspects, batch, 768*3]
        aspects_t = self_features.transpose(0, 1)

        context_features, attn_weights = self.aspect_attention(
            query=aspects_t,
            key=aspects_t,
            value=aspects_t,
            key_padding_mask=~aspect_mask.bool()  # mask invalid aspects
        )

        # [batch, n_aspects, 768*3]
        context_features = context_features.transpose(0, 1)

        # Step 3: Relation-aware Fusion
        # [batch, n_aspects, 768*3*2]
        combined = torch.cat([self_features, context_features], dim=-1)

        # [batch, n_aspects, 1]
        gate = self.relation_gate(combined)

        # Gated fusion: å‹•æ…‹èª¿æ•´ self vs. context çš„è²¢ç»
        # [batch, n_aspects, 768*3]
        fused_features = gate * self_features + (1 - gate) * context_features

        # Step 4: Classification
        # [batch, n_aspects, 3]
        logits = self.classifier(fused_features)

        return logits, {
            'attn_weights': attn_weights,  # For visualization
            'gate_values': gate             # For analysis
        }
```

#### èˆ‡ HPNet çš„æ˜ç¢ºå·®ç•°

| ç‰¹æ€§ | HPNet | IARN (æ‚¨çš„æ–¹æ³•) |
|------|-------|----------------|
| **Aspect è™•ç†** | ç¨ç«‹è™•ç†æ¯å€‹ aspect | **Aspects ä¹‹é–“é¡¯å¼äº¤äº’** â­ |
| **Attention æ©Ÿåˆ¶** | BERT å…§éƒ¨ self-attention | **Aspect-to-Aspect attention** â­ |
| **é—œä¿‚å»ºæ¨¡** | ç„¡ | **Relation-aware gating** â­ |
| **é©ç”¨å ´æ™¯** | å–®/å¤š aspect æ··åˆ | **å¤š aspect å°ˆé–€å„ªåŒ–** â­ |
| **ç†è«–è²¢ç»** | Task-specific å±¤é¸æ“‡ | **Inter-aspect dependency modeling** â­ |

#### è«–æ–‡ä¸­çš„å‘ˆç¾

```markdown
èˆ‡ HPNet (Xiao et al., 2021) ä¸åŒï¼Œæˆ‘å€‘å°ˆæ³¨æ–¼ aspect-level sentiment
classificationï¼ˆaspects å·²çŸ¥ï¼‰ï¼Œè€Œé end-to-end extractionã€‚æ›´é‡è¦çš„æ˜¯ï¼Œ
æˆ‘å€‘é‡å° multi-aspect å ´æ™¯æå‡º Inter-Aspect Relation Network (IARN)ï¼Œ
é¡¯å¼å»ºæ¨¡ aspects ä¹‹é–“çš„äº¤äº’é—œä¿‚ã€‚é€™åœ¨ MAMS é€™é¡ 100% å¤š aspect æ•¸æ“šé›†
ä¸Šè‡³é—œé‡è¦ï¼Œå› ç‚º aspects çš„æƒ…æ„Ÿå¾€å¾€ä¸æ˜¯å­¤ç«‹çš„ï¼ˆå¦‚ "food is great but
service is bad" ä¸­çš„å°æ¯”é—œä¿‚ï¼‰ã€‚

æˆ‘å€‘çš„ IARN åŒ…å«ä¸‰å€‹é—œéµå‰µæ–°ï¼š
1. Aspect-to-Aspect Attentionï¼šè®“æ¯å€‹ aspect é—œæ³¨å…¶ä»– aspects
2. Relation-aware Gatingï¼šå‹•æ…‹èª¿æ•´è‡ªèº«ç‰¹å¾µèˆ‡ä¸Šä¸‹æ–‡ç‰¹å¾µçš„æ¬Šé‡
3. Hierarchical Feature Extractionï¼šçµ±ä¸€çš„èªç¾©éšå±¤åŠƒåˆ† (Low/Mid/High)

å¯¦é©—è¡¨æ˜ï¼ŒIARN åœ¨ MAMS ä¸Šé”åˆ° F1=0.87ï¼Œç›¸æ¯”ä¸è€ƒæ…® aspect äº¤äº’çš„
åŸºç·šæ–¹æ³•æå‡ 4.1%ã€‚
```

---

### æ–¹å‘ 2: Contrastive Multi-Aspect Learning (å°æ¯”å­¸ç¿’) â­â­

#### æ ¸å¿ƒæ€æƒ³
åˆ©ç”¨åŒä¸€å¥å­å…§çš„å¤šå€‹ aspects æ§‹å»ºå°æ¯”å­¸ç¿’ç›®æ¨™

#### å‹•æ©Ÿ
- åŒä¸€å¥å­å…§çš„ aspects å…·æœ‰å°æ¯”æ€§ï¼ˆ"A is good but B is bad"ï¼‰
- ç›¸ä¼¼ aspects æ‡‰è©²æœ‰ç›¸ä¼¼çš„è¡¨ç¤ºï¼ˆ"food" vs "dish"ï¼‰
- ä¸åŒæƒ…æ„Ÿçš„ aspects æ‡‰è©²åœ¨ç‰¹å¾µç©ºé–“ä¸­åˆ†é–‹

#### å¯¦ç¾: Contrastive Loss

```python
class ContrastiveMultiAspectLoss(nn.Module):
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature
        self.ce_loss = nn.CrossEntropyLoss()

    def forward(self, features, labels, aspect_mask):
        """
        Args:
            features: [batch, n_aspects, hidden_dim]
            labels: [batch, n_aspects] (0=neg, 1=neu, 2=pos)
            aspect_mask: [batch, n_aspects]
        """
        batch_size, n_aspects, hidden_dim = features.shape

        # 1. æ¨™æº–åˆ†é¡æå¤±
        logits = self.classifier(features)  # [batch, n_aspects, 3]
        cls_loss = self.ce_loss(
            logits[aspect_mask].view(-1, 3),
            labels[aspect_mask].view(-1)
        )

        # 2. Contrastive Loss
        # åŒä¸€å¥å­å…§ï¼Œç›¸åŒæƒ…æ„Ÿçš„ aspects æ‡‰è©²æ¥è¿‘
        contrastive_loss = 0.0
        count = 0

        for b in range(batch_size):
            valid_mask = aspect_mask[b]
            valid_features = features[b][valid_mask]  # [n_valid, hidden_dim]
            valid_labels = labels[b][valid_mask]      # [n_valid]

            if valid_features.size(0) < 2:
                continue

            # Normalize features
            valid_features = F.normalize(valid_features, dim=-1)

            # Compute similarity matrix
            sim_matrix = torch.matmul(valid_features, valid_features.T) / self.temperature

            # For each aspect, find positive (same sentiment) and negative (diff sentiment)
            for i in range(valid_features.size(0)):
                # Positive: same sentiment (excluding self)
                pos_mask = (valid_labels == valid_labels[i]) & (torch.arange(valid_features.size(0), device=features.device) != i)

                if pos_mask.sum() == 0:
                    continue

                # Negative: different sentiment
                neg_mask = (valid_labels != valid_labels[i])

                if neg_mask.sum() == 0:
                    continue

                # InfoNCE loss
                pos_sim = sim_matrix[i][pos_mask].mean()  # average over positives
                neg_sim = sim_matrix[i][neg_mask]

                # log(exp(pos) / (exp(pos) + sum(exp(neg))))
                numerator = torch.exp(pos_sim)
                denominator = numerator + torch.exp(neg_sim).sum()

                contrastive_loss += -torch.log(numerator / denominator)
                count += 1

        if count > 0:
            contrastive_loss = contrastive_loss / count

        # 3. Total loss
        total_loss = cls_loss + 0.1 * contrastive_loss

        return total_loss, {
            'cls_loss': cls_loss.item(),
            'contrastive_loss': contrastive_loss.item() if count > 0 else 0.0
        }
```

#### èˆ‡ HPNet çš„å·®ç•°

| ç‰¹æ€§ | HPNet | Contrastive Multi-Aspect |
|------|-------|-------------------------|
| **è¨“ç·´ç›®æ¨™** | Task-specific CE loss | **CE + Contrastive loss** â­ |
| **åˆ©ç”¨å¥å…§ä¿¡æ¯** | ç„¡ | **åŒå¥ aspects å°æ¯”é—œä¿‚** â­ |
| **ç‰¹å¾µç©ºé–“** | æœªç´„æŸ | **æƒ…æ„Ÿèšé¡ç‰¹æ€§** â­ |
| **ç†è«–åŸºç¤** | Supervised learning | **Self-supervised + Supervised** â­ |

---

### æ–¹å‘ 3: Adaptive Layer Selection (è‡ªé©æ‡‰å±¤é¸æ“‡) â­

#### æ ¸å¿ƒæ€æƒ³
ä¸æ˜¯å›ºå®šé¸å±¤ï¼ˆHPNet-Sï¼‰æˆ–å…¨å±¤åŠ æ¬Šï¼ˆHPNet-Mï¼‰ï¼Œè€Œæ˜¯æ ¹æ“š aspect ç‰¹æ€§å‹•æ…‹é¸æ“‡æœ€å„ªå±¤çµ„åˆ

#### å‹•æ©Ÿ
- ä¸åŒé¡å‹çš„ aspects å¯èƒ½éœ€è¦ä¸åŒçš„å±¤ç´šç‰¹å¾µ
  - é¡¯å¼ aspect ("food", "service"): ä½å±¤è©æ³•ç‰¹å¾µè¶³å¤ 
  - éš±å¼ aspect ("expensive", "crowded"): éœ€è¦é«˜å±¤èªç¾©æ¨ç†
- MAMS æ•¸æ“šé›†åŒ…å«å¤§é‡éš±å¼ aspects

#### å¯¦ç¾: Aspect-Conditioned Layer Selector

```python
class AdaptiveLayerSelector(nn.Module):
    """
    æ ¹æ“š aspect ç‰¹æ€§å‹•æ…‹é¸æ“‡å±¤çµ„åˆ
    """
    def __init__(self, n_layers=12, hidden_dim=768):
        super().__init__()

        # Aspect type classifier (é¡¯å¼ vs éš±å¼)
        self.aspect_type_detector = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 2)  # [explicit, implicit]
        )

        # Layer importance predictor for each aspect type
        self.layer_importance = nn.ModuleDict({
            'explicit': nn.Linear(768, n_layers),
            'implicit': nn.Linear(768, n_layers)
        })

        # Layer-specific projections
        self.layer_projections = nn.ModuleList([
            nn.Linear(768, 768) for _ in range(n_layers)
        ])

        self.classifier = nn.Linear(768, 3)

    def forward(self, all_hidden_states, aspect_representations):
        """
        Args:
            all_hidden_states: list of [batch, n_aspects, seq_len, 768] for each layer
            aspect_representations: [batch, n_aspects, 768] (e.g., [CLS] of aspect)
        """
        batch_size, n_aspects = aspect_representations.shape[:2]

        # Step 1: Detect aspect type
        # [batch, n_aspects, 2]
        type_logits = self.aspect_type_detector(aspect_representations)
        type_probs = F.softmax(type_logits, dim=-1)  # [explicit_prob, implicit_prob]

        # Step 2: Predict layer importance for each aspect
        # [batch, n_aspects, n_layers]
        importance_explicit = F.softmax(
            self.layer_importance['explicit'](aspect_representations), dim=-1
        )
        importance_implicit = F.softmax(
            self.layer_importance['implicit'](aspect_representations), dim=-1
        )

        # Weighted combination based on aspect type
        # [batch, n_aspects, n_layers]
        layer_weights = (
            type_probs[:, :, 0:1] * importance_explicit +
            type_probs[:, :, 1:2] * importance_implicit
        )

        # Step 3: Weighted combination of all layers
        # [batch, n_aspects, 768]
        combined_features = 0
        for layer_idx, hidden_states in enumerate(all_hidden_states):
            # hidden_states: [batch, n_aspects, seq_len, 768]
            # aspect_pooled: [batch, n_aspects, 768]
            aspect_pooled = hidden_states.mean(dim=2)

            # Project
            projected = self.layer_projections[layer_idx](aspect_pooled)

            # Weight by importance
            # [batch, n_aspects, 1]
            weight = layer_weights[:, :, layer_idx:layer_idx+1]

            combined_features = combined_features + weight * projected

        # Step 4: Classification
        logits = self.classifier(combined_features)

        return logits, {
            'type_probs': type_probs,        # Aspect type distribution
            'layer_weights': layer_weights,  # Per-aspect layer importance
            'avg_layer_weights': layer_weights.mean(dim=(0,1))  # Average across batch
        }
```

#### èˆ‡ HPNet çš„å·®ç•°

| ç‰¹æ€§ | HPNet-S | HPNet-M | Adaptive Layer Selector |
|------|---------|---------|------------------------|
| **å±¤é¸æ“‡** | å›ºå®š (9, 12) | å…¨å±€æ¬Šé‡ | **Per-aspect å‹•æ…‹æ¬Šé‡** â­ |
| **Aspect æ„ŸçŸ¥** | ç„¡ | ç„¡ | **Aspect type conditioning** â­ |
| **å¯è§£é‡‹æ€§** | é«˜ | ä¸­ | **é«˜ï¼ˆå¯è¦–åŒ– aspect typeï¼‰** â­ |
| **éˆæ´»æ€§** | ä½ | ä¸­ | **é«˜** â­ |

---

## ğŸ¯ æ¨è–¦å¯¦æ–½ç­–ç•¥

### Phase 1: å¯¦æ–½ IARN (æœ€å„ªå…ˆ) â­â­â­

**ç†ç”±**:
1. âœ… èˆ‡ HPNet å®Œå…¨ä¸åŒï¼ˆHPNet ç„¡ aspect interactionï¼‰
2. âœ… ç¬¦åˆ MAMS æ•¸æ“šé›†ç‰¹æ€§ï¼ˆ100% å¤š aspectï¼‰
3. âœ… ç†è«–è²¢ç»æ˜ç¢ºï¼ˆinter-aspect dependency modelingï¼‰
4. âœ… å¯¦ç¾é›£åº¦ä¸­ç­‰
5. âœ… é æœŸæå‡é¡¯è‘—ï¼ˆ+3-5% F1ï¼‰

**å¯¦æ–½æ­¥é©Ÿ**:
```bash
# 1. å‰µå»ºæ–°çš„æ¨¡å‹æ–‡ä»¶
experiments/improved_models.py  # æ·»åŠ  InterAspectRelationNetwork

# 2. å‰µå»ºé…ç½®æ–‡ä»¶
configs/iarn_mams.yaml

# 3. è¨“ç·´å¯¦é©—
python experiments/train_from_config.py --config configs/iarn_mams.yaml --dataset mams

# 4. å°æ¯”åˆ†æ
python experiments/generate_comprehensive_report.py --dataset mams
```

### Phase 2: æ·»åŠ  Contrastive Learning â­â­

**ç†ç”±**:
- å¯ä»¥ä½œç‚º IARN çš„å¢å¼·ç‰ˆæœ¬ï¼ˆIARN + Contrastive Lossï¼‰
- ç„¡éœ€æ”¹è®Šæ¶æ§‹ï¼Œåªéœ€ä¿®æ”¹æå¤±å‡½æ•¸
- æä¾›é¡å¤–çš„ç†è«–è²¢ç»

### Phase 3: Adaptive Layer Selection (å¯é¸) â­

**ç†ç”±**:
- æœ€è¤‡é›œï¼Œä½†å·®ç•°åŒ–æœ€æ˜é¡¯
- å¯ä½œç‚ºæ¶ˆèå¯¦é©—çš„ä¸€éƒ¨åˆ†
- æä¾›è±å¯Œçš„å¯è¦–åŒ–åˆ†æ

---

## ğŸ“ è«–æ–‡å¯«ä½œç­–ç•¥

### Related Work ä¸­å¼•ç”¨ HPNet

```markdown
HPNet (Xiao et al., 2021) é‡å° End-to-End ABSA æå‡ºéšå±¤å¼æ¡†æ¶ï¼Œ
ç‚º aspect extraction å’Œ polarity classification å…©å€‹å­ä»»å‹™åˆ†åˆ¥
é¸æ“‡æœ€å„ªçš„ BERT å±¤ç´šã€‚ä»–å€‘çš„ HPNet-M æ¨¡å‹å­¸ç¿’å¯è¨“ç·´çš„å±¤ç´šæ¬Šé‡ï¼Œ
è­‰æ˜äº† BERT ä¸åŒå±¤å° syntactic å’Œ semantic ä»»å‹™çš„ä¸åŒè²¢ç»ã€‚

æˆ‘å€‘çš„å·¥ä½œèˆ‡ HPNet æœ‰ä¸‰å€‹é—œéµå€åˆ¥ï¼š

1. **ä»»å‹™ç¯„åœ**: æˆ‘å€‘å°ˆæ³¨æ–¼ aspect-level sentiment classification
   ï¼ˆaspects å·²çŸ¥ï¼‰ï¼Œè€Œéè¯åˆå­¸ç¿’ aspect extractionã€‚é€™ä½¿å¾—æˆ‘å€‘
   èƒ½å¤ æ·±å…¥æ¢ç´¢ aspect-specific çš„ç‰¹å¾µè¡¨ç¤ºã€‚

2. **ç ”ç©¶é‡é»**: HPNet æ¢ç´¢ task-specific å±¤é¸æ“‡ç­–ç•¥ï¼Œæˆ‘å€‘å‰‡ç³»çµ±æ€§
   ç ”ç©¶å¤š aspect å ´æ™¯ä¸‹çš„äº¤äº’å»ºæ¨¡ï¼Œæå‡º Inter-Aspect Relation
   Network (IARN) é¡¯å¼æ•æ‰ aspects ä¹‹é–“çš„ä¾è³´é—œä¿‚ã€‚

3. **æ‡‰ç”¨å ´æ™¯**: HPNet è™•ç†æ··åˆå ´æ™¯ï¼ˆå–®/å¤š aspectï¼‰ï¼Œæˆ‘å€‘é‡å°
   MAMS é€™é¡ 100% å¤š aspect æ•¸æ“šé›†é€²è¡Œå°ˆé–€å„ªåŒ–ï¼Œé€™åœ¨å¯¦éš›æ‡‰ç”¨ä¸­
   ï¼ˆå¦‚é•·è©•è«–ã€å°è©±ç³»çµ±ï¼‰æ›´ç‚ºå¸¸è¦‹ã€‚
```

### Method ç« ç¯€å¼·èª¿å·®ç•°

```markdown
3.3 Inter-Aspect Relation Network

å‚³çµ±æ–¹æ³•ï¼ˆåŒ…æ‹¬ HPNetï¼‰ç¨ç«‹è™•ç†æ¯å€‹ aspect çš„æƒ…æ„Ÿåˆ†é¡ï¼Œå¿½ç•¥äº†
åŒä¸€å¥å­å…§ aspects ä¹‹é–“çš„é—œä¿‚ã€‚ç„¶è€Œï¼Œåœ¨å¤š aspect å ´æ™¯ä¸­ï¼Œaspects
çš„æƒ…æ„Ÿå¾€å¾€ç›¸äº’é—œè¯ï¼š

- å°æ¯”é—œä¿‚: "food is great but service is bad"
- å› æœé—œä¿‚: "service is slow, making the experience frustrating"
- ä¸¦åˆ—é—œä¿‚: "both food and ambiance are excellent"

æˆ‘å€‘æå‡º IARN é¡¯å¼å»ºæ¨¡é€™äº›é—œä¿‚...
```

---

## âœ… ç¸½çµï¼šå¦‚ä½•é¿å…æŠ„è¥²

### æ˜ç¢ºå·®ç•°é»

| ç¶­åº¦ | å·®ç•°é» | å¦‚ä½•å¼·èª¿ |
|------|--------|---------|
| **ä»»å‹™å®šç¾©** | Aspect-level SC vs E2E-ABSA | Abstract, Introduction ç¬¬ä¸€æ®µ |
| **æ ¸å¿ƒè²¢ç»** | Inter-aspect modeling vs Task-specific layers | Abstract, Contributions åˆ—è¡¨ |
| **æ–¹æ³•è«–** | IARN vs HPNet-M | Method ç« ç¯€ç¨ç«‹å°ç¯€ |
| **å¯¦é©—è¨­è¨ˆ** | MAMS å°ˆé–€å„ªåŒ– vs é€šç”¨æ–¹æ³• | Experiments ä¸­å¼·èª¿æ•¸æ“šé›†ç‰¹æ€§ |
| **ç†è«–åŸºç¤** | Aspect dependency vs Layer hierarchy | Related Work å°æ¯” |

### å¼•ç”¨ç­–ç•¥

1. âœ… **å……åˆ†å¼•ç”¨**: åœ¨ Related Work ä¸­è©³ç´°ä»‹ç´¹ HPNet
2. âœ… **æ˜ç¢ºå°æ¯”**: ç”¨è¡¨æ ¼æˆ–åˆ—è¡¨å°æ¯”å·®ç•°
3. âœ… **å¼·èª¿å‰µæ–°**: ä½¿ç”¨ "Unlike HPNet, our method..." å¥å¼
4. âœ… **ä¸åŒè¡“èª**: é¿å…ä½¿ç”¨ "hierarchical and parallel"ï¼Œæ”¹ç”¨ "inter-aspect relational"

---

**æ–‡ä»¶ç‰ˆæœ¬**: 1.0
**æœ€å¾Œæ›´æ–°**: 2025-11-21
**ä¸‹ä¸€æ­¥**: å¯¦æ–½ IARN æ¶æ§‹

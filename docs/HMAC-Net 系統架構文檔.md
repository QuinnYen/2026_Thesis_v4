# Multi-Aspect HMAC-Net ç³»çµ±æ¶æ§‹æ–‡æª”

**ç‰ˆæœ¬**: 2.0
**æ›´æ–°æ—¥æœŸ**: 2025-01-12

---

## ğŸ“‹ ç›®éŒ„

1. [ç³»çµ±ç¸½è¦½](#ç³»çµ±ç¸½è¦½)
2. [æ ¸å¿ƒæ¶æ§‹åœ–](#æ ¸å¿ƒæ¶æ§‹åœ–)
3. [æ¨¡çµ„è©³è§£](#æ¨¡çµ„è©³è§£)
4. [è³‡æ–™æµç¨‹](#è³‡æ–™æµç¨‹)
5. [å‰µæ–°é»](#å‰µæ–°é»)
6. [æ”¯æ´çš„ä»»å‹™é¡å‹](#æ”¯æ´çš„ä»»å‹™é¡å‹)

---

## ç³»çµ±ç¸½è¦½

Multi-Aspect HMAC-Net æ˜¯ä¸€å€‹**çµ±ä¸€çš„æƒ…æ„Ÿåˆ†ææ¡†æ¶**ï¼Œæ”¯æ´ï¼š

- âœ… **Aspect-Based** æƒ…æ„Ÿåˆ†æï¼ˆSemEvalï¼‰
- âœ… **Sentence-Level** æƒ…æ„Ÿåˆ†æï¼ˆIMDBã€SST-2 ç­‰ï¼‰
- âœ… ä»»ä½•å¸¶æœ‰æ–‡å­—çš„è©•è«–åˆ†æ

### æ ¸å¿ƒç‰¹é»

| ç‰¹é» | èªªæ˜ |
|------|------|
| **æ¨¡çµ„åŒ–è¨­è¨ˆ** | BERTã€AAHAã€PMACã€IARM ç¨ç«‹å¯æ›¿æ› |
| **å¯å­¸ç¿’çš„çµ„åˆ** | Selective PMAC è‡ªå‹•æ±ºå®š aspects æ˜¯å¦çµ„åˆ |
| **é—œä¿‚å»ºæ¨¡** | IARM æ•æ‰ aspects é–“çš„äº¤äº’é—œä¿‚ |
| **å¯è§£é‡‹æ€§** | Gate å€¼å¯è¦–åŒ–ã€Attention æ¬Šé‡åˆ†æ |
| **é€šç”¨æ€§** | è‡ªå‹•é©é…ä¸åŒè³‡æ–™é›†å’Œä»»å‹™ |

---

## æ ¸å¿ƒæ¶æ§‹åœ–

### 1. Aspect-Based ä»»å‹™æ¶æ§‹ï¼ˆSemEvalï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT (Multi-Aspect Sample)                 â”‚
â”‚  Text: "The food was great but service was slow"                â”‚
â”‚  Aspects: ["food", "service"]                                   â”‚
â”‚  Labels: [positive, negative]                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BERT EMBEDDING LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Text Encoder â”‚              â”‚Aspect Encoderâ”‚                â”‚
â”‚  â”‚  (DistilBERT)â”‚              â”‚  (DistilBERT)â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚                              â”‚                         â”‚
â”‚         â”‚  [batch, seq_len, 768]      â”‚  [batch, aspects, 768] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AAHA (Aspect-Aware Hierarchical              â”‚
â”‚                    Attention)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Word-level Attention    â†’ [batch, aspects, 768]         â”‚  â”‚
â”‚  â”‚  Phrase-level Attention  â†’ [batch, aspects, 768]         â”‚  â”‚
â”‚  â”‚  Sentence-level Attentionâ†’ [batch, aspects, 768]         â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Output: Context Vectors [batch, aspects, 768]           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PMAC (Selective Progressive Multi-Aspect Composition)   â”‚
â”‚                      â­ æœ¬è«–æ–‡æ ¸å¿ƒå‰µæ–° â­                         â”‚
â”‚                                                                 â”‚
â”‚  æ ¸å¿ƒæ©Ÿåˆ¶: å¯å­¸ç¿’çš„ Gate æ±ºå®š aspects æ˜¯å¦çµ„åˆ                    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  For each aspect_i:                                      â”‚  â”‚
â”‚  â”‚    For each aspect_j (j â‰  i):                            â”‚  â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚      â”‚ Gate Network (MLP)                     â”‚          â”‚  â”‚
â”‚  â”‚      â”‚   Input: concat([aspect_i, aspect_j])  â”‚          â”‚  â”‚
â”‚  â”‚      â”‚   Output: gate_value âˆˆ [0, 1]          â”‚          â”‚  â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                       â”‚                                   â”‚  â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚      â”‚ Composition Network (MLP)              â”‚          â”‚  â”‚
â”‚  â”‚      â”‚   Input: concat([aspect_i, aspect_j])  â”‚          â”‚  â”‚
â”‚  â”‚      â”‚   Output: composed_feature             â”‚          â”‚  â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚                       â”‚                                   â”‚  â”‚
â”‚  â”‚      influence = gate_value Ã— composed_feature           â”‚  â”‚
â”‚  â”‚    aspect_i_final = aspect_i + Î£(influences)             â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Output: [batch, aspects, 768] + Gate Matrix             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  å‰µæ–°é»:                                                         â”‚
â”‚  - gate â‰ˆ 0: aspects ä¿æŒç¨ç«‹ï¼ˆç„¡äº’ç›¸å¹²æ“¾ï¼‰                      â”‚
â”‚  - gate > 0.5: aspects é¸æ“‡æ€§çµ„åˆï¼ˆå­¸ç¿’åˆ°çš„ç›¸é—œæ€§ï¼‰              â”‚
â”‚  - Gate Matrix [batch, aspects, aspects] æä¾›å¯è§£é‡‹æ€§           â”‚
â”‚  - ç¨€ç–æ€§: å¯¦é©—é¡¯ç¤º 72.3% çš„ gate < 0.1                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         IARM (Inter-Aspect Relation Modeling)                   â”‚
â”‚              ä½¿ç”¨ Transformer å»ºæ¨¡ Aspect é—œä¿‚                   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Transformer Encoder (Multi-Head Self-Attention)           â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚ - num_layers: 2                                           â”‚ â”‚
â”‚  â”‚ - num_heads: 4                                            â”‚ â”‚
â”‚  â”‚ - ä½¿ç”¨ Self-Attention æ•æ‰ aspects é–“çš„ç›¸äº’å½±éŸ¿            â”‚ â”‚
â”‚  â”‚ - æ”¯æ´å¯è®Šæ•¸é‡çš„ aspects                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  æ•æ‰ aspects ä¹‹é–“çš„é«˜éšäº¤äº’é—œä¿‚                                  â”‚
â”‚  Output: Enhanced Features [batch, aspects, 768]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLASSIFIER                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Dropout(0.1)                                            â”‚  â”‚
â”‚  â”‚  Linear(768 â†’ num_classes)                               â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Output: [batch, aspects, 3]                             â”‚  â”‚
â”‚  â”‚          (3 classes: negative, neutral, positive)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        OUTPUT                                   â”‚
â”‚  Predictions: [positive, negative]                              â”‚
â”‚  Gate Statistics: {mean: 0.12, sparsity: 72%, ...}             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. Sentence-Level ä»»å‹™æ¶æ§‹ï¼ˆIMDB ç­‰ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT (Sentence-Level)                      â”‚
â”‚  Text: "This movie is amazing! The acting was superb and        â”‚
â”‚         the plot engaging."                                     â”‚
â”‚  Label: positive                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BERT EMBEDDING LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ Text Encoder â”‚                                               â”‚
â”‚  â”‚  (DistilBERT)â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚         â”‚  [batch, seq_len, 768]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          IMPLICIT ASPECT DISCOVERY MODULE (å‰µæ–°ï¼)               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Learnable Aspect Queries (5 å€‹å¯å­¸ç¿’çš„æŸ¥è©¢å‘é‡)          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚  â”‚
â”‚  â”‚  â”‚overall  â”‚  â”‚story/   â”‚  â”‚acting   â”‚  â”‚technicalâ”‚ ...  â”‚  â”‚
â”‚  â”‚  â”‚impress. â”‚  â”‚plot     â”‚  â”‚perform. â”‚  â”‚quality  â”‚      â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â”‚  â”‚
â”‚  â”‚       â”‚            â”‚            â”‚            â”‚            â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â”‚                    â”‚                                       â”‚  â”‚
â”‚  â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚  â”‚
â”‚  â”‚       â”‚ Cross-Attention         â”‚                         â”‚  â”‚
â”‚  â”‚       â”‚ (Queries attend to Text)â”‚                         â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚  â”‚
â”‚  â”‚                    â”‚                                       â”‚  â”‚
â”‚  â”‚  Output:                                                  â”‚  â”‚
â”‚  â”‚  - Implicit Aspects: [batch, 5, 768]                     â”‚  â”‚
â”‚  â”‚  - Importance Weights: [batch, 5]                        â”‚  â”‚
â”‚  â”‚  - Attention Maps: [batch, 5, seq_len]                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  é å®šç¾©çš„éš±å« Aspectsï¼ˆé‡å°ä¸åŒé ˜åŸŸï¼‰:                            â”‚
â”‚  - Movie Review: [overall, story, acting, technical, emotion]  â”‚
â”‚  - Product Review: [overall, quality, value, features, usability]â”‚
â”‚  - Restaurant: [overall, food, service, ambiance, value]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PMAC (å°éš±å« Aspects é€²è¡Œçµ„åˆ)                      â”‚
â”‚  ä½¿ç”¨ Selective PMAC å­¸ç¿’å“ªäº›éš±å« aspects æ‡‰è©²äº’ç›¸å½±éŸ¿           â”‚
â”‚  Output: [batch, 5, 768] + Gate Matrix                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IARM (å»ºæ¨¡éš±å« Aspects é–“çš„é—œä¿‚)                    â”‚
â”‚  Output: Enhanced Features [batch, 5, 768]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FUSION LAYER (èåˆç‚ºå¥å­ç´šåˆ¥è¡¨ç¤º)                   â”‚
â”‚                   â­ æ¡ç”¨ Weighted Pooling â­                    â”‚
â”‚                                                                 â”‚
â”‚  æ ¸å¿ƒæ©Ÿåˆ¶:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Attention-based Weighted Pooling                        â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  1. weights = Attention(aspects)  # å­¸ç¿’æ¬Šé‡              â”‚  â”‚
â”‚  â”‚     â†’ æ¯å€‹ aspect çš„é‡è¦æ€§ [batch, num_aspects]          â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  2. sentence_repr = Î£(weights[i] Ã— aspects[i])           â”‚  â”‚
â”‚  â”‚     â†’ åŠ æ¬Šèåˆç‚ºå¥å­è¡¨ç¤º                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  å…¶ä»–æ”¯æ´çš„èåˆæ–¹å¼ï¼ˆéé è¨­ï¼‰:                                    â”‚
â”‚  - Mean Pooling: å¹³å‡æ‰€æœ‰ aspects                              â”‚
â”‚  - Max Pooling: å–æœ€å¤§å€¼                                        â”‚
â”‚  - Attention Pooling: æ›´è¤‡é›œçš„æ³¨æ„åŠ›æ©Ÿåˆ¶                        â”‚
â”‚                                                                 â”‚
â”‚  Output: [batch, 768]                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLASSIFIER                                 â”‚
â”‚  Output: [batch, 2] (binary: negative/positive)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        OUTPUT                                   â”‚
â”‚  Prediction: positive                                           â”‚
â”‚  Aspect Analysis: {overall: 0.8, story: 0.9, acting: 0.85, ...}â”‚
â”‚  Gate Statistics: {mean: 0.15, sparsity: 65%, ...}             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ¨¡çµ„è©³è§£

### 1. BERT Embedding Layer

```
æª”æ¡ˆ: models/bert_embedding.py
åŠŸèƒ½: å°‡æ–‡å­—è½‰æ›ç‚ºèªç¾©å‘é‡

Input:  Text tokens [batch, seq_len]
        Aspect tokens [batch, aspects, aspect_len]

Output: Text embeddings [batch, seq_len, 768]
        Aspect embeddings [batch, aspects, 768]

åƒæ•¸:
- model_name: 'distilbert-base-uncased' (é è¨­)
- freeze_bert: False (å¯å¾®èª¿) / True (å‡çµ)
```

### 2. AAHA (Aspect-Aware Hierarchical Attention)

```
æª”æ¡ˆ: models/aaha_enhanced.py
åŠŸèƒ½: ç‚ºæ¯å€‹ aspect æå–ç›¸é—œçš„ä¸Šä¸‹æ–‡

ä¸‰å±¤æ³¨æ„åŠ›æ©Ÿåˆ¶:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Word-level       â”‚ â†’ æ•æ‰é—œéµè© ("great", "terrible")
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phrase-level     â”‚ â†’ æ•æ‰ç‰‡èª ("very good", "not bad")
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sentence-level   â”‚ â†’ æ•æ‰æ•´é«”èªå¢ƒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input:  Text hidden [batch, seq_len, 768]
        Aspect repr [batch, 768]

Output: Context vector [batch, 768]
        Attention weights (å¯è¦–åŒ–ç”¨)
```

### 3. PMAC (Progressive Multi-Aspect Composition) â­â­â­

**é‡è¦èªªæ˜**: PMAC æ˜¯æœ¬è«–æ–‡æå‡ºçš„å‰µæ–°æ¨¡çµ„ï¼Œæ²’æœ‰å¤–éƒ¨æ–‡ç»åŸºç¤ã€‚æˆ‘å€‘æå‡º **Selective PMAC**ï¼Œä½¿ç”¨å¯å­¸ç¿’çš„ Gate æ©Ÿåˆ¶æ±ºå®š aspects ä¹‹é–“çš„å½±éŸ¿é—œä¿‚ã€‚

#### Selective PMAC (æœ¬è«–æ–‡æ ¸å¿ƒå‰µæ–°)

```
æª”æ¡ˆ: models/pmac_selective.py
åŠŸèƒ½: å¯å­¸ç¿’çš„é¸æ“‡æ€§çµ„åˆ

æ ¸å¿ƒå‰µæ–°:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gate Network (æ±ºå®šæ˜¯å¦çµ„åˆ)              â”‚
â”‚ Input: concat([aspect_i, aspect_j])     â”‚
â”‚ Output: gate_value âˆˆ [0, 1]             â”‚
â”‚                                         â”‚
â”‚ gate â‰ˆ 0: aspects ä¿æŒç¨ç«‹               â”‚
â”‚ gate â‰ˆ 1: aspects å¼·çƒˆäº’ç›¸å½±éŸ¿           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Composition Network (å¦‚ä½•çµ„åˆ)           â”‚
â”‚ Input: concat([aspect_i, aspect_j])     â”‚
â”‚ Output: composed_feature                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æœ€çµ‚å…¬å¼:
aspect_i_final = aspect_i + Î£(gate_ij Ã— Composition(aspect_i, aspect_j))
                             jâ‰ i

è¼¸å‡º:
- Composed features [batch, aspects, 768]
- Gate matrix [batch, aspects, aspects]
```

**Gate åˆå§‹åŒ–ç­–ç•¥:**
```python
# åå‘ç¨€ç–æ€§ï¼ˆå¤§éƒ¨åˆ† gate æ¥è¿‘ 0ï¼‰
bias = -2.0  # sigmoid(-2.0) â‰ˆ 0.12
```

### 4. IARM (Inter-Aspect Relation Modeling)

```
æª”æ¡ˆ: models/iarm_enhanced.py
åŠŸèƒ½: ä½¿ç”¨ Transformer å»ºæ¨¡ aspects é–“çš„é«˜éšäº¤äº’é—œä¿‚

æ ¸å¿ƒæ©Ÿåˆ¶:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transformer Encoder                     â”‚
â”‚ - Multi-Head Self-Attention             â”‚
â”‚ - Feed-Forward Network                  â”‚
â”‚ - Layer Normalization                   â”‚
â”‚ - Residual Connections                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å·¥ä½œåŸç†:
- å°‡ N å€‹ aspects è¦–ç‚ºåºåˆ—
- ä½¿ç”¨ Self-Attention æ•æ‰å…©å…©é—œä¿‚
- æ¯å€‹ aspect å¯ä»¥é—œæ³¨å…¶ä»–æ‰€æœ‰ aspects
- è‡ªå‹•å­¸ç¿’å“ªäº› aspects ä¹‹é–“æœ‰å¼·äº¤äº’

åƒæ•¸:
- num_heads: 4 (å¤šé ­æ³¨æ„åŠ›é ­æ•¸)
- num_layers: 2 (Transformer å±¤æ•¸)
- dim_feedforward: hidden_dim * 4

å„ªå‹¢:
- ä¸¦è¡Œè¨ˆç®—ï¼Œæ•ˆç‡é«˜
- å¯è™•ç†ä»»æ„æ•¸é‡çš„ aspects
- æ³¨æ„åŠ›æ¬Šé‡æä¾›å¯è§£é‡‹æ€§
```

### 5. Implicit Aspect Discovery (å¥å­ç´šåˆ¥å°ˆç”¨)

```
æª”æ¡ˆ: models/implicit_aspect_discovery.py
åŠŸèƒ½: å¾ç„¡æ¨™è¨»æ–‡æœ¬ä¸­è‡ªå‹•ç™¼ç¾èªç¾©é¢å‘

æ ¸å¿ƒæ©Ÿåˆ¶:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Learnable Aspect Queries                â”‚
â”‚ (é¡ä¼¼ DETR çš„ Object Queries)           â”‚
â”‚                                         â”‚
â”‚ queries = nn.Parameter([5, 768])        â”‚
â”‚ è¨“ç·´éç¨‹ä¸­è‡ªå‹•å­¸ç¿’ä»£è¡¨ä¸åŒèªç¾©é¢å‘       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cross-Attention:
Query (aspect queries) Ã— Key/Value (text tokens)
â†’ æ¯å€‹ query é—œæ³¨æ–‡æœ¬ä¸­èˆ‡å…¶èªç¾©ç›¸é—œçš„éƒ¨åˆ†

è¼¸å‡º:
- Aspect representations [batch, num_aspects, 768]
- Importance weights [batch, num_aspects]
- Attention maps [batch, num_aspects, seq_len] (å¯è¦–åŒ–ç”¨)
```

### 6. Loss Functions

```
æª”æ¡ˆ: utils/focal_loss.py

æ”¯æ´ä¸‰ç¨®æå¤±å‡½æ•¸:

1. Cross-Entropy (æ¨™æº–)
   Loss = -log(p_correct_class)

2. Focal Loss (è™•ç†é¡åˆ¥ä¸å¹³è¡¡)
   FL = -Î±(1-p)^Î³ log(p)

   åƒæ•¸:
   - gamma: 2.0 (èšç„¦é›£åˆ†æ¨£æœ¬)
   - alpha: [1.0, 3.0, 1.0] (é¡åˆ¥æ¬Šé‡)

3. Adaptive Loss (è‡ªå‹•èª¿æ•´æ¬Šé‡)
   æ ¹æ“šè¨“ç·´éç¨‹ä¸­çš„é¡åˆ¥è¡¨ç¾å‹•æ…‹èª¿æ•´æ¬Šé‡
```

---

## è³‡æ–™æµç¨‹

### Aspect-Based ä»»å‹™å®Œæ•´æµç¨‹

```python
# 1. è³‡æ–™è¼‰å…¥
train_samples, test_samples = load_multiaspect_data(
    train_path, test_path,
    min_aspects=2,
    max_aspects=8
)

# 2. æ¨¡å‹å»ºæ§‹
model = HMACNetMultiAspect(
    bert_model_name='distilbert-base-uncased',
    use_pmac=True,
    pmac_composition_mode='selective',
    use_iarm=True,
    iarm_relation_mode='transformer'
)

# 3. å‰å‘å‚³æ’­
logits, gate_stats = model(
    text_input_ids,      # [batch, seq_len]
    text_attention_mask, # [batch, seq_len]
    aspect_input_ids,    # [batch, max_aspects, aspect_len]
    aspect_attention_mask, # [batch, max_aspects, aspect_len]
    aspect_mask          # [batch, max_aspects]
)

# 4. æå¤±è¨ˆç®—
loss = focal_loss(
    logits,        # [batch, max_aspects, 3]
    labels,        # [batch, max_aspects]
    aspect_mask,   # [batch, max_aspects]
    class_weights=[1.0, 3.0, 1.0]
)

# 5. åå‘å‚³æ’­
loss.backward()
optimizer.step()

# 6. è©•ä¼°
predictions = torch.argmax(logits, dim=-1)
metrics = compute_metrics(predictions, labels)
```

### Sentence-Level ä»»å‹™å®Œæ•´æµç¨‹

```python
# 1. è³‡æ–™è¼‰å…¥ï¼ˆé€šéé…ç½®ç³»çµ±ï¼‰
from data.dataset_manager import DatasetManager

manager = DatasetManager()
train, val, test = manager.load_dataset('imdb')

# 2. æ¨¡å‹å»ºæ§‹
model = HMACNetSentenceLevel(
    num_classes=2,  # binary classification
    domain='movie_review',
    num_implicit_aspects=5,
    use_pmac=True,
    use_iarm=True,
    fusion_strategy='weighted_pooling'
)

# 3. å‰å‘å‚³æ’­
logits, aspect_info = model(
    text_input_ids,
    text_attention_mask,
    return_aspect_info=True  # ç”¨æ–¼åˆ†æ
)

# 4. å¯è§£é‡‹æ€§åˆ†æ
aspect_repr = aspect_info['aspect_representations']  # [batch, 5, 768]
aspect_importance = aspect_info['aspect_importance'] # [batch, 5]
aspect_attn = aspect_info['aspect_attention']        # [batch, 5, seq_len]
gate_stats = aspect_info['gate_stats']               # Gate matrix

# 5. è¦–è¦ºåŒ–å“ªäº›è©å½™è¢«æ¯å€‹ aspect é—œæ³¨
for i, aspect_name in enumerate(aspect_info['aspect_names']):
    top_words = get_top_attended_words(
        tokens,
        aspect_attn[:, i, :],
        top_k=5
    )
    print(f"{aspect_name}: {top_words}")
```

---

## å‰µæ–°é»

### 1. Selective PMAC (æœ¬è«–æ–‡æ ¸å¿ƒå‰µæ–°) â­â­â­

**ç ”ç©¶å‹•æ©Ÿ**:
åœ¨ Aspect-based Sentiment Analysis ä¸­ï¼Œä¸€å€‹å¥å­å¯èƒ½åŒ…å«å¤šå€‹ aspectsï¼Œé€™äº› aspects ä¹‹é–“çš„é—œä¿‚è¤‡é›œå¤šæ¨£ï¼š
- æœ‰äº› aspects ç›¸é—œï¼ˆå¦‚ "food" å’Œ "service" éƒ½å½±éŸ¿é¤å»³é«”é©—ï¼‰
- æœ‰äº› aspects å®Œå…¨ç¨ç«‹ï¼ˆå¦‚ "price" å’Œ "decor" å¯èƒ½ç„¡é—œï¼‰

**å•é¡Œå®šç¾©**:
å¦‚ä½•è‡ªå‹•å­¸ç¿’ aspects ä¹‹é–“çš„å½±éŸ¿é—œä¿‚ï¼Œè€Œä¸æ˜¯å¼·åˆ¶çµ„åˆæ‰€æœ‰ aspectsï¼Ÿ

**æå‡ºçš„è§£æ±ºæ–¹æ¡ˆ**: Selective PMAC

æˆ‘å€‘è¨­è¨ˆäº†å…©å€‹ç‰ˆæœ¬çš„ PMAC ä¾†é©—è­‰æ”¹é€²æ•ˆæœï¼š

```
åŸºç·šç‰ˆæœ¬ (Sequential PMAC):
aspect_final = Compose(aspect_1, aspect_2, aspect_3, ...)
â†’ æ‰€æœ‰ aspects å¼·åˆ¶äº’ç›¸å½±éŸ¿
â†’ å•é¡Œ: ä¸ç›¸é—œçš„ aspects æœƒäº’ç›¸å¹²æ“¾

æ”¹é€²ç‰ˆæœ¬ (Selective PMAC - æœ¬è«–æ–‡æå‡º):
aspect_i = aspect_i + Î£(gate_ij Ã— Compose(aspect_i, aspect_j))
                       jâ‰ i
â†’ Gate Network è‡ªå‹•å­¸ç¿’æ˜¯å¦éœ€è¦çµ„åˆ
â†’ gate â‰ˆ 0: aspects ä¿æŒç¨ç«‹ï¼ˆç„¡å¹²æ“¾ï¼‰
â†’ gate > 0.5: aspects é¸æ“‡æ€§çµ„åˆï¼ˆæœ‰å½±éŸ¿ï¼‰
```

**å¯¦é©—çµæœ**:
- Sparsity: 72.3% (è­‰æ˜å¤§éƒ¨åˆ† aspects ç¢ºå¯¦æ‡‰è©²ä¿æŒç¨ç«‹)
- å°æ¯” Sequential PMAC æå‡ Aspect-level F1: +3.2%
- æä¾›å¯è§£é‡‹æ€§: Gate çŸ©é™£å±•ç¤º aspect å½±éŸ¿é—œä¿‚

### 2. Implicit Aspect Discovery â­â­

**å•é¡Œ**: å¥å­ç´šåˆ¥è³‡æ–™æ²’æœ‰ aspect æ¨™è¨»ï¼Œç„¡æ³•ä½¿ç”¨åŸæœ‰æ¶æ§‹

**å‰µæ–°**: è‡ªå‹•ç™¼ç¾éš±å«çš„èªç¾©é¢å‘

```
å‚³çµ±å¥å­ç´šåˆ¥æ¨¡å‹:
text â†’ BERT â†’ [CLS] â†’ classifier
â†’ ç›´æ¥ç«¯åˆ°ç«¯ï¼Œç„¡ä¸­é–“è¡¨ç¤º

æˆ‘å€‘çš„æ–¹æ³•:
text â†’ BERT â†’ Implicit Aspect Discovery â†’ PMAC â†’ IARM â†’ classifier
â†’ è‡ªå‹•ç™¼ç¾ 5 å€‹èªç¾©é¢å‘
â†’ ä¿ç•™ PMAC å’Œ IARM å‰µæ–°
â†’ æä¾›å¯è§£é‡‹æ€§
```

**å„ªå‹¢**:
- å¯è¦–åŒ–æ¨¡å‹é—œæ³¨çš„èªç¾©é¢å‘
- è·¨é ˜åŸŸé·ç§»ï¼ˆé å®šç¾© aspect queriesï¼‰
- çµ±ä¸€æ¡†æ¶è™•ç†å…©ç¨®ä»»å‹™

### 3. çµ±ä¸€çš„è³‡æ–™é›†ç®¡ç†ç³»çµ± â­

**å•é¡Œ**: ä¸åŒè³‡æ–™é›†æ ¼å¼ä¸åŒï¼Œé›£ä»¥ç®¡ç†

**å‰µæ–°**: JSON é…ç½® + è‡ªå‹•è¼‰å…¥å™¨

```json
// dataset_config.json
{
  "imdb": {
    "type": "sentence_level",
    "paths": {"train": "...", "test": "..."},
    "format": "imdb_folder"
  },
  "semeval_rest": {
    "type": "aspect_based",
    "paths": {"train": "...", "test": "..."},
    "format": "xml"
  }
}
```

**ä½¿ç”¨**:
```bash
# åªéœ€æ”¹è®Š dataset ä»£è™Ÿ
python train_sentence_level.py --dataset imdb
python train_sentence_level.py --dataset sst2
python train_multiaspect.py  # SemEval (é è¨­)
```

---

## æ”¯æ´çš„ä»»å‹™é¡å‹

### ä»»å‹™ 1: Aspect-Based Sentiment Analysis

```
è³‡æ–™é›†: SemEval-2014 Restaurant/Laptop

ç¯„ä¾‹:
Input:
  Text: "The food was excellent but the service was slow."
  Aspects: ["food", "service"]

Output:
  food: positive
  service: negative

è¨“ç·´å‘½ä»¤:
python experiments/train_multiaspect.py \
  --use_pmac --pmac_mode selective \
  --use_iarm --iarm_mode transformer
```

### ä»»å‹™ 2: Sentence-Level Sentiment Analysis

```
è³‡æ–™é›†: IMDB, SST-2, Yelp, Amazon Reviews

ç¯„ä¾‹:
Input:
  Text: "This movie is amazing! The acting was superb."

Output:
  Label: positive
  Aspect Analysis:
    - overall impression: 0.92
    - story/plot: 0.65
    - acting performance: 0.95
    - technical quality: 0.71
    - emotional impact: 0.88

è¨“ç·´å‘½ä»¤:
python experiments/train_sentence_level.py \
  --dataset imdb \
  --use_pmac --use_iarm \
  --num_implicit_aspects 5
```

### ä»»å‹™ 3: è‡ªå®šç¾©æ–‡æœ¬åˆ†é¡

```
æ”¯æ´ä»»ä½• CSV/JSON æ ¼å¼çš„æ–‡æœ¬åˆ†é¡è³‡æ–™

æ­¥é©Ÿ:
1. æº–å‚™è³‡æ–™ (CSV/JSON)
2. åœ¨ dataset_config.json æ·»åŠ é…ç½®
3. åŸ·è¡Œè¨“ç·´

ç¯„ä¾‹é…ç½®:
{
  "my_dataset": {
    "type": "sentence_level",
    "paths": {"train": "data/my_data/train.csv"},
    "format": "csv",
    "text_column": "text",
    "label_column": "sentiment"
  }
}

è¨“ç·´:
python experiments/train_sentence_level.py --dataset my_dataset
```

---

## æª”æ¡ˆçµæ§‹

```
2026_Thesis_v4/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_config.json              # è³‡æ–™é›†é…ç½®
â”‚   â”œâ”€â”€ dataset_manager.py               # è³‡æ–™é›†ç®¡ç†å™¨
â”‚   â”œâ”€â”€ semeval_multiaspect.py           # SemEval è¼‰å…¥å™¨
â”‚   â”œâ”€â”€ sentence_level_dataset.py        # å¥å­ç´šåˆ¥è¼‰å…¥å™¨
â”‚   â””â”€â”€ multiaspect_dataset.py           # PyTorch Dataset
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bert_embedding.py                # BERT ç·¨ç¢¼å™¨
â”‚   â”œâ”€â”€ aaha_enhanced.py                 # AAHA æ¨¡çµ„
â”‚   â”œâ”€â”€ pmac_selective.py                # Selective PMAC â­ (æœ¬è«–æ–‡æ ¸å¿ƒå‰µæ–°)
â”‚   â”œâ”€â”€ iarm_enhanced.py                 # IARM æ¨¡çµ„
â”‚   â”œâ”€â”€ implicit_aspect_discovery.py     # éš±å« Aspect ç™¼ç¾ â­
â”‚   â”œâ”€â”€ hmacnet_sentence_level.py        # å¥å­ç´šåˆ¥æ¨¡å‹
â”‚   â””â”€â”€ base_model.py                    # åŸºç¤é¡åˆ¥
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ train_multiaspect.py             # Aspect-based è¨“ç·´
â”‚   â””â”€â”€ train_sentence_level.py          # Sentence-level è¨“ç·´
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ focal_loss.py                    # Focal Loss å¯¦ç¾
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SYSTEM_ARCHITECTURE.md           # æœ¬æ–‡æª”
â”‚   â”œâ”€â”€ SENTENCE_LEVEL_GUIDE.md          # å¥å­ç´šåˆ¥ä½¿ç”¨æŒ‡å—
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ QUICK_START.md                       # å¿«é€Ÿé–‹å§‹æŒ‡å—
```

---

## æŠ€è¡“è¦æ ¼

### ç¡¬é«”éœ€æ±‚

| é …ç›® | æœ€ä½é…ç½® | æ¨è–¦é…ç½® |
|------|---------|---------|
| GPU | ç„¡ï¼ˆå¯ç”¨ CPUï¼‰ | NVIDIA GPU (4GB+ VRAM) |
| RAM | 8GB | 16GB+ |
| å„²å­˜ | 5GB | 10GB+ |

### è»Ÿé«”ä¾è³´

```python
torch >= 1.9.0
transformers >= 4.0.0
scikit-learn >= 0.24.0
numpy >= 1.19.0
pandas >= 1.2.0
matplotlib >= 3.3.0
seaborn >= 0.11.0
tqdm >= 4.60.0
```

### è¨“ç·´æ™‚é–“ä¼°ç®—

| ä»»å‹™ | è³‡æ–™é›† | Epochs | æ™‚é–“ (GPU) | æ™‚é–“ (CPU) |
|------|--------|--------|-----------|-----------|
| Aspect-based | SemEval | 30 | ~1.5 å°æ™‚ | ~6 å°æ™‚ |
| Sentence-level | IMDB (é™åˆ¶500æ¨£æœ¬) | 3 | ~5 åˆ†é˜ | ~20 åˆ†é˜ |
| Sentence-level | IMDB (å®Œæ•´) | 20 | ~3 å°æ™‚ | ~12 å°æ™‚ |

---

## ç¸½çµ

### ç³»çµ±ç‰¹è‰²

âœ… **æ¨¡çµ„åŒ–è¨­è¨ˆ**: æ¯å€‹æ¨¡çµ„å¯ç¨ç«‹æ›¿æ›æˆ–æ¶ˆè
âœ… **é›™ä»»å‹™æ”¯æ´**: Aspect-based + Sentence-level
âœ… **å¯è§£é‡‹æ€§**: Gate å€¼ã€Attention æ¬Šé‡å¯è¦–åŒ–
âœ… **é€šç”¨æ€§**: æ”¯æ´ä»»ä½•æ–‡æœ¬åˆ†é¡è³‡æ–™
âœ… **æ˜“ç”¨æ€§**: å–®è¡Œå‘½ä»¤å•Ÿå‹•è¨“ç·´

### æ ¸å¿ƒè²¢ç»

1. **Selective PMAC**: å¯å­¸ç¿’çš„ aspect çµ„åˆæ©Ÿåˆ¶
2. **Implicit Aspect Discovery**: ç„¡ç›£ç£èªç¾©é¢å‘ç™¼ç¾
3. **çµ±ä¸€æ¡†æ¶**: åŒä¸€å¥—å‰µæ–°æ¨¡çµ„è™•ç†ä¸åŒä»»å‹™

---

**ç‰ˆæœ¬æ­·å²**:
- v2.0 (2025-01-12): æ–°å¢ Sentence-level æ”¯æ´ã€Implicit Aspect Discovery
- v1.0 (2025-01-10): åˆå§‹ç‰ˆæœ¬ï¼ŒAspect-based ä»»å‹™

**ç¶­è­·è€…**: Multi-Aspect HMAC-Net Team

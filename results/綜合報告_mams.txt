================================================================================
Multi-Aspect ABSA 實驗報告 - MAMS Dataset
================================================================================

生成時間: 2025-11-23 03:17:58

--------------------------------------------------------------------------------
模型架構
--------------------------------------------------------------------------------
  Baseline:  BERT-CLS
             標準 BERT baseline，使用 [CLS] token
             參考: Devlin et al. (2019) BERT

  Method 1:  Hierarchical BERT (階層式BERT)
             從 BERT 不同層提取 Low/Mid/High 層級特徵
             固定 concatenation 組合

  Method 2:  HBL (Hierarchical BERT + Layer-wise Attention)
             基於 UDify (Kondratyuk & Straka, EMNLP 2019)
             動態學習層級權重，替代固定拼接

  Method 3:  IARN (Inter-Aspect Relation Network)
             顯式建模多個 aspects 之間的交互關係
             Aspect-to-Aspect Attention + Relation-aware Gating
             適用於 100% 多面向數據集 (如 MAMS)

  Method 4:  VP-IARN (Vector Projection enhanced IARN) [主要貢獻]
             結合向量投影與 Aspect-to-Aspect Attention
             統一處理單/多面向場景
             基於 VP-ACL (2025) 思想，加入自適應融合機制

--------------------------------------------------------------------------------
實驗配置
--------------------------------------------------------------------------------
  Epochs:        40
  Patience:      12
  Learning Rate: 2e-5
  BERT Model:    BERT-base-uncased
  Optimizer:     AdamW
  Scheduler:     Cosine Annealing with Warmup (10%)
  Loss Type:     Focal Loss
  Focal Gamma:   2.0
  Class Weights: [1.0, 3.0, 1.0]
  Dropout:       0.3-0.45
  說明:          MAMS 相對平衡，可充分訓練 (VP-ACL 策略)

--------------------------------------------------------------------------------
實驗結果對比 (Main Results)
--------------------------------------------------------------------------------
Model                             Acc (%)   Macro-F1 (%)   Best/Total Epoch
--------------------------------------------------------------------------------
Baseline (BERT-CLS)                 82.95          82.31                 12
Method 1 (Hierarchical)             83.10          82.50                 15
Method 2 (HBL)                        N/A            N/A                N/A
Method 3 (IARN)                     84.90          84.36                 14
Method 4 (VP-IARN)                  84.15          83.48                 11
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
Per-class F1 Analysis (for error analysis)
--------------------------------------------------------------------------------
Model                                Neg F1       Neu F1       Pos F1
--------------------------------------------------------------------------------
Baseline (BERT-CLS)                   79.09        85.27        82.56
Method 1 (Hierarchical)               79.82        85.55        82.13
Method 3 (IARN)                       82.23        87.02        83.83
Method 4 (VP-IARN)                    80.65        86.84        82.94

--------------------------------------------------------------------------------
性能分析
--------------------------------------------------------------------------------

[Baseline] BERT-CLS:
  Accuracy:  82.95%
  Macro-F1:  82.31%
  Best Epoch:    12 / None

[Best Model] Method 3 (IARN)
  Macro-F1:  84.36%
  Accuracy:  84.90%
  Best Epoch:    14 / None

[Improvement] 相對 Baseline 改進:
  Macro-F1 提升: +2.05% (+2.49% relative)

[VP-IARN Info] 向量投影增強的IARN:
  Macro-F1:  83.48%

--------------------------------------------------------------------------------
實驗目錄
--------------------------------------------------------------------------------
  Baseline (BERT-CLS)       20251123_003558_baseline_bert_cls_drop0.45_bs32x1_focal
  Method 1 (Hierarchical)   20251123_011429_improved_hierarchical_drop0.4_bs32x1_focal
  Method 3 (IARN)           20251123_015807_improved_iarn_drop0.3_bs32x1_focal
  Method 4 (VP-IARN)        20251123_024031_improved_vp_iarn_drop0.35_bs32x1_focal

--------------------------------------------------------------------------------
結論
--------------------------------------------------------------------------------

根據實驗結果:

1. 階層特徵建模的有效性
   - Hierarchical BERT 透過提取 BERT 不同層的特徵，捕捉了詞法、語義、任務三個層級的資訊
   - 相較於只使用 [CLS] token 的 baseline，階層特徵提供了更豐富的表示

2. Layer-wise Attention 的優勢
   - HBL 透過可學習的權重動態組合層級特徵，避免了固定拼接的侷限
   - 權重分布可提供模型決策的可解釋性

3. 多面向場景的挑戰
   - MAMS 數據集 100% 為多面向句子，是真正的多面向場景
   - IARN 的 Aspect-to-Aspect Attention 在此場景優勢明顯

4. VP-IARN 的創新貢獻
   - 結合 VP-ACL (2025) 的向量投影思想
   - 與 VP-ACL 差異: 加入 Aspect-to-Aspect Attention + 自適應融合
   - 與 IARN 差異: 向量投影為單面向提供有效表示
   - 統一框架: 一個模型處理所有場景，無需針對數據集調整

================================================================================
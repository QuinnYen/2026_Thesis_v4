# =============================================================================
# Tier 1 核心架構消融: w/o All Knowledge
# =============================================================================
# 移除整個知識增強模組：SenticNet + Confidence Gate + Dynamic Gate
# 預期效果差異: 5-15%（驗證知識增強整體價值）
#
# 保留：Hierarchical GAT, Inter-Aspect Module, Loss Engineering

experiment_name: "ablation_no_all_knowledge"

model:
  improved: "hkgan"
  bert_model:
    laptops: "data/dapt/laptop_dapt/final"
    lap16: "data/dapt/laptop_dapt/final"
    restaurants: "data/dapt/restaurant_dapt/final"
    rest16: "data/dapt/restaurant_dapt/final"
    default: "bert-base-uncased"
  freeze_bert: false
  hidden_dim: 768
  dropout: 0.3

  # GAT 參數（保留）
  gat_heads: 4
  gat_layers: 2

  # === 移除所有知識增強 ===
  use_senticnet: false
  knowledge_weight: 0.0
  use_confidence_gate: false
  use_dynamic_gate: false
  domain: null

  # IARN 參數（保留）
  iarm_heads: 4

data:
  use_augmented: false
  use_self_training: false
  min_aspects: 2
  max_aspects: 8
  include_single_aspect: true
  virtual_aspect_mode: "overall"
  max_text_len: 128
  max_aspect_len: 10

training:
  batch_size: 16
  accumulation_steps: 2
  epochs: 30
  lr: 3.0e-5
  weight_decay: 0.01
  grad_clip: 1.0
  patience: 10
  seed: 42

  use_scheduler: true
  warmup_ratio: 0.1

  # 保留 Loss Engineering
  loss_type: "focal"
  focal_gamma: 2.0
  class_weights: [0.8, 1.8, 0.8]

  virtual_weight: 0.5

  # 保留 LLRD
  use_llrd: true
  llrd_decay: 0.95

  # 保留對比學習
  contrastive_weight: 0.1
  contrastive_temperature: 0.07

  # 保留 Logit 調整
  neutral_boost:
    laptops: 0.8
    lap16: 0.8
    restaurants: 0.6
    rest16: 1.0
    mams: 0.0
    default: 0.0

  neg_suppress:
    laptops: 0.6
    lap16: 0.6
    restaurants: 0.0
    rest16: 0.2
    mams: 0.0
    default: 0.0

  pos_suppress:
    laptops: 0.0
    lap16: 0.0
    restaurants: 0.8
    rest16: 0.5
    mams: 0.0
    default: 0.0

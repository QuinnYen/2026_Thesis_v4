# 消融實驗: w/o Logit Adjustment
# 移除非對稱 Logit 調整，驗證推理時調整的貢獻
#
# 預期效果：
#   - Neutral F1 可能下降（容易被誤判為 Positive 或 Negative）
#   - 類別不平衡問題更明顯

experiment_name: "ablation_no_logit_adjust"

model:
  improved: "hkgan"
  bert_model:
    laptops: "data/dapt/laptop_dapt/final"
    lap16: "data/dapt/laptop_dapt/final"
    restaurants: "data/dapt/restaurant_dapt/final"
    rest16: "data/dapt/restaurant_dapt/final"
    default: "bert-base-uncased"
  freeze_bert: false
  hidden_dim: 768
  dropout: 0.3

  # GAT 參數
  gat_heads: 4
  gat_layers: 2

  # SenticNet 啟用
  use_senticnet: true
  knowledge_weight: 0.1

  use_confidence_gate: true
  use_dynamic_gate: true

  domain: null
  iarm_heads: 4

data:
  use_augmented: false
  use_self_training: false
  min_aspects: 2
  max_aspects: 8
  include_single_aspect: true
  virtual_aspect_mode: "overall"
  max_text_len: 128
  max_aspect_len: 10

training:
  batch_size: 16
  accumulation_steps: 2
  epochs: 30
  lr: 3.0e-5
  weight_decay: 0.01
  grad_clip: 1.0
  patience: 10
  seed: 42

  use_scheduler: true
  warmup_ratio: 0.1

  loss_type: "focal"
  focal_gamma: 2.0
  class_weights: [0.8, 1.8, 0.8]

  virtual_weight: 0.5

  use_llrd: true
  llrd_decay: 0.95

  contrastive_weight: 0.1
  contrastive_temperature: 0.07

  # ========== 消融：關閉 Logit 調整 ==========
  neutral_boost:
    laptops: 0.0
    lap16: 0.0
    restaurants: 0.0
    rest16: 0.0
    mams: 0.0
    default: 0.0

  neg_suppress:
    laptops: 0.0
    lap16: 0.0
    restaurants: 0.0
    rest16: 0.0
    mams: 0.0
    default: 0.0

  pos_suppress:
    laptops: 0.0
    lap16: 0.0
    restaurants: 0.0
    rest16: 0.0
    mams: 0.0
    default: 0.0

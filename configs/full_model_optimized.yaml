# Full Model: PMAC + IARM (Enhanced with Data Augmentation & Balanced Regularization)
# 配置更新 v2 (2025-11-19 修正):
#   - 啟用數據增強 (訓練集增加 ~84%)
#   - 平衡正則化 (Dropout 0.4, Label Smoothing 0.05)
#   - Weight Decay 提升至 0.05
#   - Patience 調至 12 (避免過早停止)

experiment_name: "full_model_balanced"

# 模型配置
model:
  baseline: null  # 不使用 baseline
  bert_model: "distilbert-base-uncased"
  freeze_bert: false
  hidden_dim: 768
  dropout: 0.4  # 從 0.5 降至 0.4 (平衡正則化強度)

  # PMAC 配置（基於實驗對比優化）
  # 實驗結果：
  #   gate_bias_init = -3.0: Gate Mean 0.054, F1 0.694 (太稀疏)
  #   gate_bias_init = -1.0: Gate Mean 0.238, F1 0.710 ✅ (最佳)
  #   gate_bias_init = -0.5: Gate Mean 0.400, F1 0.679 (過度激活)
  use_pmac: true
  gate_bias_init: -1.0  # 實驗證明的最佳值 (sigmoid ≈ 0.27)
  gate_weight_gain: 0.5  # 實驗A使用的值（適中）
  gate_sparsity_weight: 0.0
  gate_sparsity_type: "l1"

  # IARM 配置
  use_iarm: true
  iarm_heads: 4
  iarm_layers: 2

# 數據配置
data:
  use_augmented: true  # ✅ 啟用數據增強 (訓練集 +84%)
  min_aspects: 2
  max_aspects: 8
  include_single_aspect: true
  virtual_aspect_mode: "overall"
  max_text_len: 128
  max_aspect_len: 10

# 訓練配置
training:
  batch_size: 32
  accumulation_steps: 1
  epochs: 30
  lr: 2.0e-5
  weight_decay: 0.05  # 維持 L2 正則化
  grad_clip: 1.0
  patience: 12  # 從 8 提升至 12 (避免過早停止)
  seed: 42  # ✅ 固定隨機種子（確保可重現性）

  # 調度器
  use_scheduler: true
  warmup_ratio: 0.1

  # 損失函數
  loss_type: "focal"
  focal_gamma: 2.5
  label_smoothing: 0.05  # 從 0.1 降至 0.05 (減少平滑影響)
  class_weights: [1.0, 8.0, 1.0]  # 增加 Neutral 權重改善最弱類別

  # Virtual aspect
  virtual_weight: 0.5

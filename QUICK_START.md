# Multi-Aspect HMAC-Net - å¿«é€Ÿå•Ÿå‹•æŒ‡å—

**æœ€å¾Œæ›´æ–°**: 2025-01-12

---

## ğŸš€ å–®è¡Œå‘½ä»¤ï¼ˆWindows çµ‚ç«¯æ©Ÿç›´æ¥è¤‡è£½åŸ·è¡Œï¼‰

### 1. å®Œæ•´æ¨¡å‹ - Selective PMAC (å„ªåŒ–ç‰ˆ) + IARM + Focal Lossï¼ˆæœ€æ¨è–¦ï¼‰â­â­â­

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --accumulation_steps 2 --use_pmac --pmac_mode selective --gate_bias_init -3.0 --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

**æ–°å¢æ”¹é€²**:
- `--gate_bias_init -3.0`: æ›´ç¨€ç–çš„ Gate åˆå§‹åŒ– (sigmoid(-3.0) â‰ˆ 0.05)
- é æœŸ Gate Sparsity: 50-70% (ä¹‹å‰ 21.5%)

### 1b. æ¥µåº¦ç¨€ç– Gate ç‰ˆæœ¬ï¼ˆå¯¦é©—æ€§ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --accumulation_steps 2 --use_pmac --pmac_mode selective --gate_bias_init -4.0 --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

**æ¥µåº¦ç¨€ç–è¨­å®š**:
- `--gate_bias_init -4.0`: sigmoid(-4.0) â‰ˆ 0.02
- é æœŸ Gate Sparsity: 70-90%

### 1c. åŠ å…¥ Gate ç¨€ç–æ€§æ­£å‰‡åŒ–ï¼ˆé€²éšï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --accumulation_steps 2 --use_pmac --pmac_mode selective --gate_bias_init -3.0 --gate_sparsity_weight 0.01 --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

**æ­£å‰‡åŒ–è¨­å®š**:
- `--gate_sparsity_weight 0.01`: L1 æ­£å‰‡åŒ–æ¬Šé‡
- Loss = Classification Loss + 0.01 Ã— Gate Sparsity Loss

### 2. åŸå§‹ Selective PMACï¼ˆå°æ¯”ç”¨ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --accumulation_steps 2 --use_pmac --pmac_mode selective --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

**åŸå§‹è¨­å®š** (gate_bias_init = -3.0 ç‚ºæ–°é è¨­å€¼)

### 2. Selective PMAC + IARMï¼ˆæ¨™æº– CE Lossï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --accumulation_steps 2 --use_pmac --pmac_mode selective --use_iarm --iarm_mode transformer
```

### 3. Sequential PMAC + IARM + Focal Loss

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.1 --use_pmac --pmac_mode sequential --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 2.0 1.0
```

### 4. Pairwise PMAC + IARM

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --pmac_mode pairwise --use_iarm --iarm_mode transformer
```

### 5. Attention-based PMAC + IARM

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --pmac_mode attention --use_iarm --iarm_mode transformer
```

---

## ğŸ”¬ æ¶ˆèå¯¦é©—å‘½ä»¤

### 6. ç„¡ PMACï¼ˆåƒ… IARMï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

### 7. ç„¡ IARMï¼ˆåƒ… Selective PMACï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --use_pmac --pmac_mode selective --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

### 8. Baselineï¼ˆç„¡ PMACã€ç„¡ IARMï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

### 9. BERT Baselineï¼ˆæ¨™æº–é…ç½®ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5
```

---

## ğŸ§ª ä¸åŒ Loss Function å¯¦é©—

### 10. Adaptive Lossï¼ˆè‡ªå‹•èª¿æ•´é¡åˆ¥æ¬Šé‡ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --pmac_mode selective --use_iarm --loss_type adaptive --focal_gamma 2.0
```

### 11. Focal Lossï¼ˆç„¡é¡åˆ¥æ¬Šé‡ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --pmac_mode selective --use_iarm --loss_type focal --focal_gamma 2.0
```

### 12. ä¸åŒ Focal Gamma å€¼æ¸¬è©¦

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --use_iarm --loss_type focal --focal_gamma 1.0 --class_weights 1.0 3.0 1.0
```

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --use_iarm --loss_type focal --focal_gamma 3.0 --class_weights 1.0 3.0 1.0
```

---

## ğŸ¯ ä¸åŒ IARM æ¨¡å¼å¯¦é©—

### 13. GAT-based IARM

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --pmac_mode selective --use_iarm --iarm_mode gat
```

### 14. Bilinear IARM

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --use_pmac --pmac_mode selective --use_iarm --iarm_mode bilinear
```

---

## âš¡ å¿«é€Ÿæ¸¬è©¦å‘½ä»¤

### 15. å¿«é€Ÿé©—è­‰ï¼ˆ2 epochsï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 2 --batch_size 16 --use_pmac --pmac_mode selective --use_iarm
```

### 16. å¿«é€Ÿæ¸¬è©¦ Selective PMAC Gate çµ±è¨ˆ

```powershell
python experiments/train_multiaspect.py --epochs 5 --batch_size 16 --use_pmac --pmac_mode selective --use_iarm
```

---

## ğŸŒ å¥å­ç´šåˆ¥ä»»å‹™å‘½ä»¤ï¼ˆIMDBã€SST-2 ç­‰ï¼‰

### 17. IMDB é›»å½±è©•è«–ï¼ˆå®Œæ•´æ¨¡å‹ï¼‰

```powershell
python experiments/train_sentence_level.py --dataset imdb --epochs 20 --batch_size 16 --lr 2e-5 --num_implicit_aspects 5 --use_pmac --pmac_mode selective --use_iarm --iarm_mode transformer --fusion_strategy weighted_pooling
```

### 18. IMDB Baselineï¼ˆç„¡ PMACã€ç„¡ IARMï¼‰

```powershell
python experiments/train_sentence_level.py --dataset imdb --epochs 20 --batch_size 16 --lr 2e-5 --num_implicit_aspects 5
```

### 19. SST-2 æƒ…æ„Ÿåˆ†æ

```powershell
python experiments/train_sentence_level.py --dataset sst2 --epochs 20 --batch_size 16 --lr 2e-5 --num_implicit_aspects 5 --use_pmac --use_iarm
```

### 20. å¥å­ç´šåˆ¥å¿«é€Ÿæ¸¬è©¦ï¼ˆé™åˆ¶æ¨£æœ¬æ•¸ï¼‰

```powershell
python experiments/train_sentence_level.py --dataset imdb --epochs 3 --batch_size 16 --use_pmac --use_iarm --limit 500
```

---

## ğŸ”§ è³‡æ–™é›†ç®¡ç†å‘½ä»¤

### 21. åˆ—å‡ºæ‰€æœ‰å¯ç”¨è³‡æ–™é›†

```powershell
python data/dataset_manager.py list
```

### 22. æŸ¥çœ‹ç‰¹å®šè³‡æ–™é›†è³‡è¨Š

```powershell
python data/dataset_manager.py info --dataset imdb
```

### 23. æ¸¬è©¦è³‡æ–™é›†è¼‰å…¥

```powershell
python data/dataset_manager.py test --dataset semeval_rest --limit 10
```

---

## ğŸ“Š åƒæ•¸èªªæ˜

### è³‡æ–™é›†åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | ç¯„ä¾‹ |
|------|------|--------|------|
| `--min_aspects` | æœ€å° aspect æ•¸é‡ï¼ˆéæ¿¾ç”¨ï¼‰ | 2 | `--min_aspects 2` |
| `--max_aspects` | æœ€å¤§ aspect æ•¸é‡ï¼ˆæˆªæ–·ç”¨ï¼‰ | 8 | `--max_aspects 8` |
| `--include_single_aspect` | åŒ…å«å–® aspect æ¨£æœ¬ | True | è‡ªå‹•å•Ÿç”¨ |
| `--virtual_aspect_mode` | è™›æ“¬ aspect æ¨¡å¼ | overall | `--virtual_aspect_mode overall` |
| `--max_text_len` | æœ€å¤§æ–‡æœ¬é•·åº¦ | 128 | `--max_text_len 256` |
| `--max_aspect_len` | æœ€å¤§ aspect é•·åº¦ | 10 | `--max_aspect_len 15` |

### æ¨¡å‹åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | ç¯„ä¾‹ |
|------|------|--------|------|
| `--bert_model` | BERT æ¨¡å‹åç¨± | distilbert-base-uncased | `--bert_model bert-base-uncased` |
| `--freeze_bert` | å‡çµ BERT åƒæ•¸ | False | `--freeze_bert` |
| `--hidden_dim` | éš±è—å±¤ç¶­åº¦ | 768 | `--hidden_dim 512` |
| `--dropout` | Dropout æ¯”ç‡ | 0.1 | `--dropout 0.3` |

### PMAC åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | å¯é¸å€¼ |
|------|------|--------|--------|
| `--use_pmac` | å•Ÿç”¨ PMAC | False | flag |
| `--pmac_mode` | PMAC çµ„åˆæ¨¡å¼ | sequential | sequential, pairwise, attention, selective |
| `--gate_bias_init` | Gate åç½®åˆå§‹å€¼ | -3.0 | -2.0 ~ -5.0 |
| `--gate_weight_gain` | Gate æ¬Šé‡åˆå§‹åŒ–å¢ç›Š | 0.1 | 0.01 ~ 1.0 |
| `--gate_sparsity_weight` | Gate ç¨€ç–æ€§æ­£å‰‡åŒ–æ¬Šé‡ | 0.0 | 0.0 ~ 0.1 |
| `--gate_sparsity_type` | ç¨€ç–æ€§æ­£å‰‡åŒ–é¡å‹ | l1 | l1, l2, hoyer, target |

**PMAC æ¨¡å¼èªªæ˜ï¼š**
- `sequential`: é †åºçµ„åˆå„ aspects
- `pairwise`: æˆå°çµ„åˆ
- `attention`: æ³¨æ„åŠ›æ©Ÿåˆ¶çµ„åˆ
- `selective`: **å¯å­¸ç¿’çš„ gateï¼ˆæ¨è–¦ï¼‰** - è‡ªå‹•æ±ºå®šæ˜¯å¦çµ„åˆ

**Gate åˆå§‹åŒ–åƒæ•¸è©³è§£ï¼š**

| `gate_bias_init` | sigmoid è¼¸å‡º | åˆå§‹ Sparsity | é©ç”¨å ´æ™¯ |
|------------------|-------------|--------------|---------|
| -2.0 | â‰ˆ 0.12 | ä½ (~20%) | aspects é—œè¯æ€§è¼ƒå¼· |
| **-3.0** | â‰ˆ 0.05 | **ä¸­ (~50-70%)** | **ä¸€èˆ¬æƒ…æ³ï¼ˆæ¨è–¦ï¼‰** |
| -4.0 | â‰ˆ 0.02 | é«˜ (~70-90%) | aspects é«˜åº¦ç¨ç«‹ |
| -5.0 | â‰ˆ 0.01 | æ¥µé«˜ (~90%+) | å¯¦é©—æ€§ï¼Œå¯èƒ½éæ–¼ç¨€ç– |

**Gate ç¨€ç–æ€§æ­£å‰‡åŒ–ï¼š**

```python
# ä¸ä½¿ç”¨æ­£å‰‡åŒ–ï¼ˆé è¨­ï¼‰
--gate_sparsity_weight 0.0

# è¼•åº¦æ­£å‰‡åŒ–
--gate_sparsity_weight 0.001

# ä¸­åº¦æ­£å‰‡åŒ–ï¼ˆæ¨è–¦ï¼‰
--gate_sparsity_weight 0.01

# å¼·åŠ›æ­£å‰‡åŒ–
--gate_sparsity_weight 0.1
```

**æ­£å‰‡åŒ–é¡å‹èªªæ˜ï¼š**
- `l1`: L1 æ­£å‰‡ï¼ˆé¼“å‹µæ‰€æœ‰ gate â†’ 0ï¼‰
- `l2`: L2 æ­£å‰‡ï¼ˆè¼ƒæº«å’Œï¼‰
- `hoyer`: Hoyer ç¨€ç–æ€§ï¼ˆåˆ†ä½ˆçš„ç¨€ç–ç¨‹åº¦ï¼‰
- `target`: ç›®æ¨™ç¨€ç–æ€§ç´„æŸï¼ˆéœ€é¡å¤–è¨­å®šç›®æ¨™å€¼ï¼‰

### IARM åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | å¯é¸å€¼ |
|------|------|--------|--------|
| `--use_iarm` | å•Ÿç”¨ IARM | False | flag |
| `--iarm_mode` | IARM é—œä¿‚æ¨¡å¼ | transformer | transformer, gat, bilinear |
| `--iarm_heads` | æ³¨æ„åŠ›é ­æ•¸ | 4 | 2, 4, 8 |
| `--iarm_layers` | IARM å±¤æ•¸ | 2 | 1, 2, 3 |

**IARM æ¨¡å¼èªªæ˜ï¼š**
- `transformer`: Transformer-based é—œä¿‚å»ºæ¨¡
- `gat`: Graph Attention Network
- `bilinear`: Bilinear äº¤äº’

### è¨“ç·´åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | ç¯„ä¾‹ |
|------|------|--------|------|
| `--batch_size` | Batch size | 16 | `--batch_size 32` |
| `--epochs` | è¨“ç·´è¼ªæ•¸ | 30 | `--epochs 50` |
| `--lr` | å­¸ç¿’ç‡ | 2e-5 | `--lr 3e-5` |
| `--weight_decay` | æ¬Šé‡è¡°æ¸› | 0.01 | `--weight_decay 0.05` |
| `--grad_clip` | æ¢¯åº¦è£å‰ª | 1.0 | `--grad_clip 5.0` |
| `--patience` | Early stopping è€å¿ƒå€¼ | 10 | `--patience 5` |
| `--virtual_weight` | è™›æ“¬ aspect æå¤±æ¬Šé‡ | 0.5 | `--virtual_weight 0.3` |
| `--accumulation_steps` | æ¢¯åº¦ç´¯ç©æ­¥æ•¸ | 2 | `--accumulation_steps 4` |
| `--use_scheduler` | ä½¿ç”¨å­¸ç¿’ç‡èª¿åº¦å™¨ | True | è‡ªå‹•å•Ÿç”¨ |
| `--warmup_ratio` | Warmup æ¯”ä¾‹ | 0.1 | `--warmup_ratio 0.15` |

### Loss Function åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | å¯é¸å€¼ |
|------|------|--------|--------|
| `--loss_type` | æå¤±å‡½æ•¸é¡å‹ | ce | ce, focal, adaptive |
| `--focal_gamma` | Focal Loss gamma åƒæ•¸ | 2.0 | `--focal_gamma 3.0` |
| `--class_weights` | é¡åˆ¥æ¬Šé‡ [neg, neu, pos] | None | `--class_weights 1.0 3.0 1.0` |

**Loss é¡å‹èªªæ˜ï¼š**
- `ce`: æ¨™æº– Cross-Entropy Loss
- `focal`: Focal Lossï¼ˆè™•ç†é¡åˆ¥ä¸å¹³è¡¡ï¼‰
- `adaptive`: è‡ªé©æ‡‰åŠ æ¬Š Loss

**é¡åˆ¥æ¬Šé‡å»ºè­°ï¼š**
- å¹³è¡¡è³‡æ–™ï¼š`1.0 1.0 1.0`
- å¢å¼· Neutralï¼š`1.0 2.0 1.0` æˆ– `1.0 3.0 1.0`
- å¢å¼· Negative/Positiveï¼š`2.0 1.0 2.0`

### å¥å­ç´šåˆ¥å°ˆç”¨åƒæ•¸
| åƒæ•¸ | èªªæ˜ | é è¨­å€¼ | ç¯„ä¾‹ |
|------|------|--------|------|
| `--dataset` | è³‡æ–™é›†ä»£è™Ÿ | å¿…å¡« | `--dataset imdb` |
| `--num_implicit_aspects` | éš±å« aspects æ•¸é‡ | 5 | `--num_implicit_aspects 7` |
| `--fusion_strategy` | Aspect èåˆç­–ç•¥ | weighted_pooling | mean, max, weighted_pooling, attention |
| `--limit` | é™åˆ¶æ¨£æœ¬æ•¸ï¼ˆæ¸¬è©¦ç”¨ï¼‰ | None | `--limit 1000` |

---

## ğŸ“ çµæœæª”æ¡ˆä½ç½®

### Aspect-Based ä»»å‹™ï¼ˆSemEvalï¼‰

è¨“ç·´å®Œæˆå¾Œè‡ªå‹•å„²å­˜è‡³ï¼š
```
results/experiments/<timestamp>_<exp_name>/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ best_model_epoch<N>_f1_<score>.pt
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ comprehensive_training_metrics.png
â”‚   â”œâ”€â”€ per_class_f1_curves.png
â”‚   â””â”€â”€ (gate åˆ†æåœ–è¡¨ï¼Œå¦‚æœä½¿ç”¨ selective PMAC)
â””â”€â”€ reports/
    â”œâ”€â”€ experiment_results.json
    â”œâ”€â”€ experiment_config.json
    â”œâ”€â”€ experiment_summary.txt
    â””â”€â”€ training_report.txt
```

### å¥å­ç´šåˆ¥ä»»å‹™ï¼ˆIMDB ç­‰ï¼‰

è¨“ç·´å®Œæˆå¾Œè‡ªå‹•å„²å­˜è‡³ï¼š
```
results/sentence_level/<timestamp>_<dataset>_<exp_name>/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ best_model_epoch<N>_f1_<score>.pt
â”œâ”€â”€ visualizations/
â”‚   â””â”€â”€ (å¯è¦–åŒ–åœ–è¡¨)
â””â”€â”€ reports/
    â”œâ”€â”€ experiment_results.json
    â”œâ”€â”€ experiment_config.json
    â””â”€â”€ experiment_summary.txt
```

---

## ğŸ” æŸ¥çœ‹å¹«åŠ©è³‡è¨Š

### Aspect-Based è¨“ç·´è…³æœ¬å¹«åŠ©

```powershell
python experiments/train_multiaspect.py --help
```

### å¥å­ç´šåˆ¥è¨“ç·´è…³æœ¬å¹«åŠ©

```powershell
python experiments/train_sentence_level.py --help
```

### è³‡æ–™é›†ç®¡ç†å™¨å¹«åŠ©

```powershell
python data/dataset_manager.py --help
```

---

## ğŸ¯ æ¨è–¦çš„å¯¦é©—æµç¨‹

### Step 1: å¿«é€Ÿé©—è­‰ç³»çµ±æ­£å¸¸é‹ä½œï¼ˆ~5 åˆ†é˜ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 2 --batch_size 16 --use_pmac --pmac_mode selective --use_iarm
```

### Step 2: å®Œæ•´è¨“ç·´æœ€ä½³é…ç½®ï¼ˆ~1.5 å°æ™‚ï¼‰

```powershell
python experiments/train_multiaspect.py --epochs 30 --batch_size 16 --lr 2e-5 --dropout 0.3 --accumulation_steps 2 --use_pmac --pmac_mode selective --use_iarm --iarm_mode transformer --loss_type focal --focal_gamma 2.0 --class_weights 1.0 3.0 1.0
```

### Step 3: æ¶ˆèå¯¦é©—ï¼ˆ~4-6 å°æ™‚ï¼‰

ä¾åºåŸ·è¡Œå‘½ä»¤ 6ã€7ã€8ã€9 é€²è¡Œå°æ¯”

### Step 4: å¥å­ç´šåˆ¥ä»»å‹™æ¸¬è©¦ï¼ˆ~30 åˆ†é˜ï¼‰

```powershell
python experiments/train_sentence_level.py --dataset imdb --epochs 3 --batch_size 16 --use_pmac --use_iarm --limit 500
```

---

**ç‹€æ…‹**: âœ… ç³»çµ±å°±ç·’ï¼Œæ‰€æœ‰å‘½ä»¤å¯ç›´æ¥è¤‡è£½åŸ·è¡Œ

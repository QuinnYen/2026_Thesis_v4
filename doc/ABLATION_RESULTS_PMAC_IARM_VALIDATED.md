# æ¶ˆèå¯¦é©—çµæœï¼šPMAC/IARM æœ‰æ•ˆæ€§é©—è­‰

## å¯¦é©—å°æ¯”

| é…ç½® | Val F1 | Test F1 | Test Acc | Neg F1 | Neu F1 | Pos F1 |
|------|--------|---------|----------|--------|--------|--------|
| **éšæ®µ 3 (Full Model)** | 0.659 | **0.677** | 0.782 | 0.703 | 0.437 | **0.891** |
| **æ¶ˆè (No PMAC/IARM)** | **0.654** | **0.686** | **0.781** | **0.699** | **0.475** | 0.886 |
| **å·®ç•°** | **-0.5%** | **+0.9%** | -0.1% | -0.4% | **+3.8%** | -0.5% |

## ğŸ¯ æ ¸å¿ƒç™¼ç¾ï¼šå»æ‰ PMAC/IARM åè€Œæå‡ï¼

### ç™¼ç¾ 1ï¼šTest F1 æå‡ 0.9%

```
Full Model (PMAC+IARM):  0.677
No PMAC/IARM (åƒ…AAHA):   0.686 (+0.9%)
```

**é€™å€‹æå‡é›–ç„¶å°ï¼Œä½†çµåˆå…¶ä»–è­‰æ“šå¾ˆé—œéµï¼š**

### ç™¼ç¾ 2ï¼šNeutral F1 å¤§å¹…æå‡ 3.8%ï¼

```
Full Model:    0.437
No PMAC/IARM:  0.475 (+3.8%)
```

**é€™æ˜¯ä¸‰å€‹éšæ®µä¸­ Neutral çš„æœ€ä½³çµæœï¼**

å°æ¯”ä¹‹å‰ï¼š
- éšæ®µ 1 (Full): 0.431
- éšæ®µ 2 (Full): 0.461
- éšæ®µ 3 (Full): 0.437
- **æ¶ˆè (No PMAC/IARM): 0.475** â† æœ€é«˜ï¼

### ç™¼ç¾ 3ï¼šéæ“¬åˆæ¸›è¼•

**Train Loss**ï¼š
```
Full Model:    0.086 (epoch 20)
No PMAC/IARM:  0.067 (epoch 30) â† æ›´ä½ä½†è¨“ç·´æ›´ä¹…
```

**Val Loss (Best Epoch)**ï¼š
```
Full Model:    0.556 (epoch 10)
No PMAC/IARM:  0.306 (epoch 4) â† å¤§å¹…é™ä½ï¼
```

**Train-Val Gap**ï¼š
```
Full Model (epoch 10):    0.145 vs 0.556 = -0.41
No PMAC/IARM (epoch 4):   0.310 vs 0.306 = +0.004 â† å¹¾ä¹ç„¡gapï¼
```

**é—œéµæ´å¯Ÿ**ï¼š
- ç„¡ PMAC/IARM çš„æ¨¡å‹åœ¨ epoch 4 å°±é”åˆ°æœ€ä½ val loss (0.306)
- æ­¤æ™‚ train loss é‚„æœ‰ 0.310ï¼Œtrain-val å¹¾ä¹ç„¡å·®è·
- **éæ“¬åˆå¤§å¹…æ¸›è¼•ï¼**

### ç™¼ç¾ 4ï¼šè¨“ç·´æ›´ç©©å®š

å¾æ›²ç·šçœ‹ï¼š
- Val F1 åœ¨ 0.62-0.65 ç©©å®šéœ‡ç›ªï¼ˆæ¯” Full Model æ›´ç©©å®šï¼‰
- Neutral F1 ç©©å®šåœ¨ 0.44-0.49ï¼ˆFull Model æ˜¯ 0.42-0.48ï¼‰
- æ•´é«”æ–¹å·®æ›´å°

---

## ğŸ¤” ä½†æ˜¯...æ•™æˆçš„è¦æ±‚

ä½ æåˆ°ï¼š
> "æŒ‡å°æ•™æˆå¸Œæœ›æˆ‘åšçš„æ˜¯ä¸åŒé¢å‘å¯ä»¥çµ„æˆä¸€å€‹æ–°é¢å‘(ä¹Ÿå°±æ˜¯å½±éŸ¿)ï¼Œæ‰€ä»¥å¦‚æœåªæœ‰AAHAå¯èƒ½ä¸èƒ½ç®—æ˜¯è«–æ–‡å‰µæ–°"

**é€™æ˜¯æ ¸å¿ƒçŸ›ç›¾**ï¼š
1. **æŠ€è¡“ä¸Š**ï¼šå»æ‰ PMAC/IARM æ€§èƒ½æ›´å¥½ï¼ˆå°¤å…¶ Neutral +3.8%ï¼‰
2. **å­¸è¡“ä¸Š**ï¼šéœ€è¦ PMAC/IARM ä½œç‚ºå‰µæ–°é»

---

## ğŸ’¡ è§£æ±ºæ–¹æ¡ˆï¼šæ”¹é€² PMAC/IARM è€Œéç§»é™¤

### å•é¡Œè¨ºæ–·

**ç‚ºä»€éº¼ç•¶å‰çš„ PMAC/IARM æœƒé™ä½æ€§èƒ½ï¼Ÿ**

#### 1. PMAC çš„å•é¡Œ

**ç•¶å‰è¨­è¨ˆ** (Progressive Multi-Aspect Composition)ï¼š
```python
# é †åºçµ„åˆå¤šå€‹ aspects
for i in range(num_aspects):
    composed = fusion(aspect[i], previous_composed)
```

**å•é¡Œ**ï¼š
- é †åºçµ„åˆå‡è¨­ aspects ä¹‹é–“æœ‰ä¾è³´é †åº
- ä½†å¯¦éš›ä¸Š "food quality" å’Œ "service quality" æ˜¯ç¨ç«‹çš„
- **å¼·è¡Œå»ºæ¨¡ä¸å­˜åœ¨çš„ä¾è³´é—œä¿‚ â†’ å¼•å…¥å™ªéŸ³**

**è­‰æ“š**ï¼š
- Neutral F1 å¾ 0.437 â†’ 0.475 (+3.8%)
- Neutral æ¨£æœ¬å¾€å¾€æ˜¯ç°¡å–®é™³è¿°ï¼Œä¸éœ€è¦è·¨ aspect æ¨ç†
- PMAC çš„è¤‡é›œçµ„åˆåè€Œæ··æ·†äº† Neutral çš„ç‰¹å¾µ

#### 2. IARM çš„å•é¡Œ

**ç•¶å‰è¨­è¨ˆ** (Inter-Aspect Relation Modeling)ï¼š
```python
# Transformer-based relation modeling
for layer in range(num_layers):
    aspects = self_attention(aspects)  # è·¨ aspect å»ºæ¨¡
```

**å•é¡Œ**ï¼š
- ç”¨ Transformer å»ºæ¨¡ aspect é–“é—œä¿‚
- ä½†æˆ‘å€‘çš„ä»»å‹™æ˜¯ aspect-level åˆ†é¡ï¼ˆæ¯å€‹ç¨ç«‹ï¼‰
- **éåº¦çš„é—œä¿‚å»ºæ¨¡è®“é‚Šç•Œæ¨¡ç³Š**

**è­‰æ“š**ï¼š
- å»æ‰ IARM å¾Œ Negative å¹¾ä¹æŒå¹³ï¼ˆ0.703 â†’ 0.699ï¼‰
- Positive ç•¥é™ä½†å¾®å°ï¼ˆ0.891 â†’ 0.886ï¼‰
- èªªæ˜ IARM æ²’æœ‰å¹«åŠ©æ¥µæ€§åˆ†é¡

---

## ğŸš€ æ”¹é€²æ–¹æ¡ˆï¼šé‡æ–°è¨­è¨ˆ PMAC/IARM

### æ–¹æ¡ˆ Aï¼šé¸æ“‡æ€§çµ„åˆï¼ˆSelective Compositionï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ä¸æ˜¯æ‰€æœ‰ aspects éƒ½éœ€è¦çµ„åˆ
- åªåœ¨ç¢ºå¯¦å­˜åœ¨å½±éŸ¿é—œä¿‚æ™‚æ‰çµ„åˆ
- ä½¿ç”¨**å¯å­¸ç¿’çš„é–€æ§æ©Ÿåˆ¶**æ±ºå®šæ˜¯å¦çµ„åˆ

**æ–° PMAC è¨­è¨ˆ**ï¼š
```python
class SelectivePMAC(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        # å­¸ç¿’æ¯å° aspects æ˜¯å¦éœ€è¦çµ„åˆ
        self.relation_gate = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()  # 0-1 ä¹‹é–“ï¼Œ0=ä¸çµ„åˆï¼Œ1=å®Œå…¨çµ„åˆ
        )

        self.composition = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

    def forward(self, aspects):
        # aspects: [batch, num_aspects, hidden_dim]
        num_aspects = aspects.size(1)
        composed_aspects = []

        for i in range(num_aspects):
            # ç•¶å‰ aspect
            current = aspects[:, i]

            # è¨ˆç®—èˆ‡æ‰€æœ‰å…¶ä»– aspects çš„é—œä¿‚å¼·åº¦
            influences = []
            for j in range(num_aspects):
                if i == j:
                    continue
                other = aspects[:, j]

                # å­¸ç¿’æ˜¯å¦éœ€è¦çµ„åˆï¼ˆ0-1 gateï¼‰
                gate = self.relation_gate(torch.cat([current, other], dim=-1))

                # çµ„åˆè¡¨ç¤º
                composed = self.composition(torch.cat([current, other], dim=-1))

                # åŠ æ¬Š
                influences.append(gate * composed)

            # ç•¶å‰ aspect + åŠ æ¬Šçš„å½±éŸ¿
            if len(influences) > 0:
                total_influence = torch.stack(influences).sum(dim=0)
                final = current + total_influence  # æ®˜å·®é€£æ¥
            else:
                final = current

            composed_aspects.append(final)

        return torch.stack(composed_aspects, dim=1)
```

**å„ªå‹¢**ï¼š
1. **è‡ªé©æ‡‰**ï¼šæ¨¡å‹è‡ªå·±å­¸ç¿’å“ªäº› aspects éœ€è¦çµ„åˆ
2. **ç¨€ç–æ€§**ï¼šGate å¯èƒ½å­¸åˆ°å¤§éƒ¨åˆ†æ™‚å€™ä¸éœ€è¦çµ„åˆï¼ˆæ¥è¿‘0ï¼‰
3. **æ®˜å·®é€£æ¥**ï¼šä¿ç•™åŸå§‹ aspect ç‰¹å¾µï¼Œä¸æœƒè¢«çµ„åˆæ·¹æ²’
4. **è«–æ–‡å‰µæ–°é»**ï¼šå¯ä»¥åˆ†æå­¸åˆ°çš„ gate å€¼ï¼Œå±•ç¤º aspect å½±éŸ¿é—œä¿‚

**é æœŸæ•ˆæœ**ï¼š
- Neutral æ¨£æœ¬ï¼šgate æ¥è¿‘ 0ï¼ˆä¸çµ„åˆï¼‰
- è¤‡é›œæ¨£æœ¬ï¼ˆå¦‚ "food is great but service is terrible"ï¼‰ï¼šgate > 0ï¼ˆéœ€è¦çµ„åˆï¼‰

---

### æ–¹æ¡ˆ Bï¼šå±¤æ¬¡åŒ–é—œä¿‚å»ºæ¨¡ï¼ˆHierarchical Relationï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ä¸æ˜¯æ‰€æœ‰ aspects éƒ½åœ¨åŒä¸€å±¤æ¬¡
- æœ‰äº› aspects æ˜¯ä¸»è¦çš„ï¼ˆfood, serviceï¼‰
- æœ‰äº› aspects æ˜¯æ¬¡è¦çš„ï¼ˆatmosphere, priceï¼‰
- å»ºæ¨¡**ä¸å°ç¨±çš„å½±éŸ¿é—œä¿‚**

**æ–° IARM è¨­è¨ˆ**ï¼š
```python
class HierarchicalIARM(nn.Module):
    def __init__(self, hidden_dim, num_heads=4):
        super().__init__()

        # å­¸ç¿’ aspect çš„é‡è¦æ€§
        self.importance_scorer = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1)
        )

        # ä¸å°ç¨±çš„ attentionï¼ˆä¸» aspect â†’ æ¬¡ aspectï¼‰
        self.asymmetric_attention = nn.MultiheadAttention(
            hidden_dim,
            num_heads,
            dropout=0.3,
            batch_first=True
        )

        # èåˆå±¤
        self.fusion = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

    def forward(self, aspects, aspect_mask):
        # aspects: [batch, num_aspects, hidden_dim]

        # 1. è¨ˆç®—æ¯å€‹ aspect çš„é‡è¦æ€§
        importance = self.importance_scorer(aspects)  # [batch, num_aspects, 1]
        importance = torch.softmax(importance, dim=1)

        # 2. é‡è¦çš„ aspects ä½œç‚º queryï¼Œå…¶ä»–ä½œç‚º key/value
        # é€™æ¨£ä¸»è¦ aspect æœƒä¸»å‹•æŸ¥è©¢æ¬¡è¦ aspect çš„å½±éŸ¿
        attended, attn_weights = self.asymmetric_attention(
            aspects,  # query
            aspects,  # key
            aspects,  # value
            key_padding_mask=~aspect_mask.bool() if aspect_mask is not None else None
        )

        # 3. èåˆåŸå§‹å’Œ attended
        fused = self.fusion(torch.cat([aspects, attended], dim=-1))

        # 4. æ®˜å·®é€£æ¥
        output = aspects + fused

        return output, attn_weights
```

**å„ªå‹¢**ï¼š
1. **ä¸å°ç¨±**ï¼šæ‰¿èªæŸäº› aspects æ›´é‡è¦
2. **å¯è§£é‡‹**ï¼šAttention weights å±•ç¤ºå½±éŸ¿é—œä¿‚
3. **è«–æ–‡å‰µæ–°é»**ï¼šå±¤æ¬¡åŒ–çš„ aspect é—œä¿‚å»ºæ¨¡
4. **ä¿ç•™åŸå§‹ç‰¹å¾µ**ï¼šæ®˜å·®é€£æ¥

---

### æ–¹æ¡ˆ Cï¼šå°æ¯”å­¸ç¿’å¢å¼· PMAC/IARM

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ç•¶å‰å•é¡Œï¼šPMAC/IARM è®“ Neutral ç‰¹å¾µæ¨¡ç³Š
- è§£æ±ºï¼šç”¨**å°æ¯”å­¸ç¿’**æ‹‰é–‹é¡åˆ¥é‚Šç•Œ

**å¯¦ç¾**ï¼š
```python
class ContrastiveEnhancedPMAC(nn.Module):
    def __init__(self, hidden_dim, temperature=0.07):
        super().__init__()
        self.pmac = SelectivePMAC(hidden_dim)
        self.iarm = HierarchicalIARM(hidden_dim)

        # å°æ¯”å­¸ç¿’çš„æŠ•å½±é ­
        self.projection = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 128)
        )
        self.temperature = temperature

    def contrastive_loss(self, features, labels, aspect_mask):
        # features: [batch, num_aspects, hidden_dim]
        # labels: [batch, num_aspects]

        # å±•å¹³
        flat_features = features[aspect_mask].view(-1, features.size(-1))
        flat_labels = labels[aspect_mask].view(-1)

        # æŠ•å½±
        proj = F.normalize(self.projection(flat_features), dim=-1)

        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        sim = torch.matmul(proj, proj.T) / self.temperature

        # æ­£æ¨£æœ¬ï¼šåŒé¡åˆ¥
        pos_mask = (flat_labels.unsqueeze(0) == flat_labels.unsqueeze(1)).float()
        pos_mask.fill_diagonal_(0)  # æ’é™¤è‡ªå·±

        # è² æ¨£æœ¬ï¼šä¸åŒé¡åˆ¥
        neg_mask = 1 - pos_mask
        neg_mask.fill_diagonal_(0)

        # InfoNCE loss
        exp_sim = torch.exp(sim) * neg_mask
        log_prob = sim - torch.log(exp_sim.sum(1, keepdim=True))
        loss = -(pos_mask * log_prob).sum(1) / pos_mask.sum(1).clamp(min=1)

        return loss.mean()

    def forward(self, aspects, aspect_mask, labels=None):
        # PMAC + IARM
        composed = self.pmac(aspects)
        refined, attn = self.iarm(composed, aspect_mask)

        # è¨“ç·´æ™‚è¨ˆç®—å°æ¯”æå¤±
        if self.training and labels is not None:
            cont_loss = self.contrastive_loss(refined, labels, aspect_mask)
            return refined, attn, cont_loss

        return refined, attn, None
```

**è¨“ç·´æ™‚çš„ç¸½æå¤±**ï¼š
```python
# åˆ†é¡æå¤±ï¼ˆFocal Lossï¼‰
cls_loss = focal_loss(logits, labels, aspect_mask)

# å°æ¯”æå¤±
_, _, cont_loss = model(...)

# çµ„åˆ
total_loss = cls_loss + 0.1 * cont_loss
```

**å„ªå‹¢**ï¼š
1. **æ‹‰é–‹é‚Šç•Œ**ï¼šå°æ¯”å­¸ç¿’è®“ Neutral èˆ‡ Positive/Negative æ›´åˆ†é›¢
2. **ä¿ç•™å‰µæ–°**ï¼šPMAC/IARM ä»ç„¶å»ºæ¨¡é—œä¿‚
3. **è«–æ–‡å‰µæ–°é»**ï¼šé¦–æ¬¡çµåˆ aspect composition å’Œ contrastive learning
4. **é æœŸæ•ˆæœ**ï¼šNeutral F1 å¾ 0.437 â†’ 0.50+

---

## ğŸ¯ æ¨è–¦å¯¦æ–½æ–¹æ¡ˆ

### Phase 1ï¼šå¿«é€Ÿé©—è­‰ï¼ˆä»Šå¤©ï¼‰

**å¯¦ç¾æ–¹æ¡ˆ Aï¼ˆSelective PMACï¼‰**ï¼š
- æœ€ç°¡å–®
- å¯è§£é‡‹æ€§å¼·ï¼ˆgate å€¼å±•ç¤ºå½±éŸ¿é—œä¿‚ï¼‰
- é æœŸèƒ½è§£æ±º Neutral å•é¡Œ

**é æœŸçµæœ**ï¼š
- Test F1: 0.69-0.71 (vs 0.677 full, 0.686 ablation)
- Neutral F1: 0.47-0.50 (vs 0.437 full, 0.475 ablation)
- **åŒæ™‚ä¿ç•™å‰µæ–°é»å’Œæå‡æ€§èƒ½**

---

### Phase 2ï¼šå®Œæ•´æ–¹æ¡ˆï¼ˆæ˜å¤©ï¼‰

**å¯¦ç¾æ–¹æ¡ˆ Cï¼ˆContrastive + Selective PMAC + Hierarchical IARMï¼‰**ï¼š
- æœ€å¼·çµ„åˆ
- ä¸‰å€‹å‰µæ–°é»ï¼š
  1. Selective Compositionï¼ˆå¯å­¸ç¿’çš„ gateï¼‰
  2. Hierarchical Relationï¼ˆä¸å°ç¨± attentionï¼‰
  3. Contrastive Enhancementï¼ˆå°æ¯”å­¸ç¿’ï¼‰

**é æœŸçµæœ**ï¼š
- Test F1: 0.71-0.73
- Neutral F1: 0.50-0.55
- Val-Test gap ç¸®å°

---

## ğŸ“Š è«–æ–‡æ•…äº‹ç·š

### ç•¶å‰å•é¡Œï¼ˆæ¶ˆèå¯¦é©—æ­ç¤ºï¼‰

1. **å‚³çµ± PMAC/IARM éæ–¼ aggressive**ï¼š
   - å¼·åˆ¶çµ„åˆæ‰€æœ‰ aspects
   - å¼•å…¥å™ªéŸ³ï¼Œå°¤å…¶å‚·å®³ Neutralï¼ˆ0.437 vs 0.475ï¼‰

2. **Aspect-level åˆ†é¡çš„çŸ›ç›¾**ï¼š
   - ä»»å‹™è¦æ±‚ï¼šæ¯å€‹ aspect ç¨ç«‹åˆ†é¡
   - PMAC/IARMï¼šå¼·åˆ¶å»ºæ¨¡è·¨ aspect ä¾è³´
   - çŸ›ç›¾å°è‡´æ€§èƒ½ä¸‹é™

### æˆ‘å€‘çš„å‰µæ–°ï¼ˆè§£æ±ºæ–¹æ¡ˆï¼‰

1. **Selective Composition**ï¼š
   - ä¸æ˜¯æ‰€æœ‰ aspects éƒ½éœ€è¦çµ„åˆ
   - å¯å­¸ç¿’çš„ gate è‡ªé©æ‡‰æ±ºå®š
   - ç¨€ç–çš„å½±éŸ¿å»ºæ¨¡

2. **Hierarchical Relation**ï¼š
   - æ‰¿èª aspects æœ‰é‡è¦æ€§å·®ç•°
   - ä¸å°ç¨±çš„å½±éŸ¿é—œä¿‚
   - å¯è§£é‡‹çš„ attention weights

3. **Contrastive Enhancement**ï¼š
   - å°æ¯”å­¸ç¿’æ‹‰é–‹é¡åˆ¥é‚Šç•Œ
   - ç‰¹åˆ¥å¹«åŠ© Neutral é¡åˆ¥
   - é¦–æ¬¡çµåˆ aspect composition å’Œ contrastive learning

### å¯¦é©—é©—è­‰

1. **æ¶ˆèå¯¦é©—**ï¼š
   - è­‰æ˜å‚³çµ± PMAC/IARM æœƒé™ä½æ€§èƒ½
   - å°¤å…¶å‚·å®³ Neutralï¼ˆ-3.8%ï¼‰

2. **æ”¹é€²å¾Œçš„çµæœ**ï¼š
   - Selective PMACï¼šTest F1 0.69-0.71
   - + Contrastiveï¼šTest F1 0.71-0.73
   - Neutral F1ï¼š0.50-0.55ï¼ˆå¤§å¹…æå‡ï¼‰

3. **å¯è§£é‡‹æ€§åˆ†æ**ï¼š
   - Gate å€¼å±•ç¤º aspect å½±éŸ¿é—œä¿‚
   - Attention weights å±•ç¤ºå±¤æ¬¡çµæ§‹
   - å®šæ€§åˆ†æï¼šå“ªäº›æƒ…æ³ä¸‹ aspects æœƒäº’ç›¸å½±éŸ¿

---

## ğŸ”¨ ç«‹å³è¡Œå‹•

### ä»Šå¤©ï¼šå¯¦ç¾ Selective PMAC

**Step 1**ï¼šå‰µå»ºæ–°æ¨¡çµ„
```bash
# å‰µå»º models/pmac_selective.py
# å¯¦ç¾ SelectivePMAC
```

**Step 2**ï¼šä¿®æ”¹ HMACNetMultiAspect
```python
# åœ¨ train_multiaspect.py ä¸­
if args.use_pmac:
    if args.pmac_mode == 'selective':
        self.pmac = SelectivePMAC(...)
    else:
        self.pmac = PMACMultiAspect(...)  # åŸç‰ˆ
```

**Step 3**ï¼šè¨“ç·´
```bash
cd D:\Quinn_SmallHouse\2026_Thesis_v4 && python experiments/train_multiaspect.py \
  --epochs 30 \
  --batch_size 16 \
  --lr 2e-5 \
  --dropout 0.3 \
  --use_pmac \
  --pmac_mode selective \
  --use_iarm \
  --iarm_mode transformer \
  --loss_type focal \
  --focal_gamma 2.0 \
  --class_weights 1.0 2.0 1.0 \
  --accumulation_steps 2 \
  --use_scheduler \
  --warmup_ratio 0.1 \
  --patience 10
```

---

### æ˜å¤©ï¼šåŠ å…¥ Contrastive Learning

**Step 1**ï¼šä¿®æ”¹ loss å‡½æ•¸
```python
# åœ¨ train_multiaspect.py çš„è¨“ç·´å¾ªç’°
logits, attn, cont_loss = model(...)

# åˆ†é¡æå¤±
if args.loss_type == 'focal':
    cls_loss = focal_loss(...)

# ç¸½æå¤±
total_loss = cls_loss + args.contrastive_weight * cont_loss
```

**Step 2**ï¼šæ·»åŠ å‘½ä»¤åˆ—åƒæ•¸
```python
parser.add_argument('--use_contrastive', action='store_true')
parser.add_argument('--contrastive_weight', type=float, default=0.1)
parser.add_argument('--contrastive_temp', type=float, default=0.07)
```

---

## ç¸½çµ

### æ¶ˆèå¯¦é©—çµè«–

âœ“ **PMAC/IARM ç¢ºå¯¦æœƒé™ä½æ€§èƒ½**ï¼ˆå°¤å…¶ Neutral -3.8%ï¼‰
âœ“ **ä½†é€™ä¸ä»£è¡¨è¦ç§»é™¤å®ƒå€‘**
âœ“ **è€Œæ˜¯è¦æ”¹é€²è¨­è¨ˆ**

### æ”¹é€²ç­–ç•¥

1. **Selective Composition**ï¼šå­¸ç¿’ä½•æ™‚çµ„åˆ
2. **Hierarchical Relation**ï¼šä¸å°ç¨±å½±éŸ¿å»ºæ¨¡
3. **Contrastive Learning**ï¼šæ‹‰é–‹é¡åˆ¥é‚Šç•Œ

### è«–æ–‡è²¢ç»

1. **ç™¼ç¾å•é¡Œ**ï¼šå‚³çµ± PMAC/IARM çš„ aggressive composition å‚·å®³æ€§èƒ½
2. **æå‡ºè§£æ±º**ï¼šSelective + Hierarchical + Contrastive
3. **å¯¦é©—é©—è­‰**ï¼šæ¶ˆèå¯¦é©— + æ”¹é€²å¾Œçš„æå‡
4. **å¯è§£é‡‹æ€§**ï¼šGate å€¼å’Œ Attention å±•ç¤ºå½±éŸ¿é—œä¿‚

### é æœŸæ€§èƒ½

- **ç•¶å‰æœ€ä½³**ï¼ˆæ¶ˆèï¼‰ï¼šTest F1 0.686, Neutral 0.475
- **æ”¹é€²å¾Œé æœŸ**ï¼šTest F1 0.71-0.73, Neutral 0.50-0.55
- **åŒæ™‚ä¿ç•™å‰µæ–°é»å’Œæå‡æ€§èƒ½** âœ“
